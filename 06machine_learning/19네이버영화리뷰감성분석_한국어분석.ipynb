{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03d5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d3884a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ablearn/main/ratings_train.txt\", sep=\"\\t\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ce067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecfe4d11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>4608761</td>\n",
       "      <td>오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>5308387</td>\n",
       "      <td>의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>9072549</td>\n",
       "      <td>그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>5802125</td>\n",
       "      <td>절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>6070594</td>\n",
       "      <td>마무리는 또 왜이래</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           document  label\n",
       "0      6270596                                                굳 ㅋ      1\n",
       "1      9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2      8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3      6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4      6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n",
       "...        ...                                                ...    ...\n",
       "49995  4608761          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
       "49996  5308387       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n",
       "49997  9072549                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n",
       "49998  5802125     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n",
       "49999  6070594                                         마무리는 또 왜이래      0\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"./data/ratings_test.txt\", sep=\"\\t\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d04300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        150000 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     150000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972249f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        50000 non-null  int64 \n",
      " 1   document  49997 non-null  object\n",
      " 2   label     50000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa157507",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "644eadfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 149995 entries, 0 to 149999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        149995 non-null  int64 \n",
      " 1   document  149995 non-null  object\n",
      " 2   label     149995 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49997 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        49997 non-null  int64 \n",
      " 1   document  49997 non-null  object\n",
      " 2   label     49997 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4026ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       아 더빙.. 진짜 짜증나네요 목소리\n",
       "1                         흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
       "2                                         너무재밓었다그래서보는것을추천한다\n",
       "3                             교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
       "4         사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
       "                                ...                        \n",
       "149995                                  인간이 문제지.. 소는 뭔죄인가..\n",
       "149996                                        평점이 너무 낮아서...\n",
       "149997                      이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?\n",
       "149998                          청춘 영화의 최고봉.방황과 우울했던 날들의 자화상\n",
       "149999                             한국 영화 최초로 수간하는 내용이 담긴 영화\n",
       "Name: document, Length: 149995, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861e4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5496293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c00b22f",
   "metadata": {},
   "source": [
    "# 정규표현식 re\n",
    "* import re\n",
    "* pattern = r'[가-힣0-9a-zA-Z]+'  한글, 숫자, 영어 대소문자만 추출\n",
    "* matches = re.findall(pattern, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92373049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "283bb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(x):\n",
    "    pattern = r'[가-힣0-9a-zA-Z]+'\n",
    "    matches = re.findall(pattern, x)\n",
    "    matches = \" \".join(matches)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2343096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['document'] = train_df['document'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa6a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['document'] = test_df['document'].apply(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b45d1b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    굳\n",
       "1                                 GDNTOPCLASSINTHECLUB\n",
       "2                   뭐야 이 평점들은 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
       "3                            지루하지는 않은데 완전 막장임 돈주고 보기에는\n",
       "4        3D만 아니었어도 별 다섯 개 줬을텐데 왜 3D로 나와서 제 심기를 불편하게 하죠\n",
       "                             ...                      \n",
       "49995          오랜만에 평점 로긴했네 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함\n",
       "49996     의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO\n",
       "49997                  그림도 좋고 완성도도 높았지만 보는 내내 불안하게 만든다\n",
       "49998       절대 봐서는 안 될 영화 재미도 없고 기분만 잡치고 한 세트장에서 다 해먹네\n",
       "49999                                       마무리는 또 왜이래\n",
       "Name: document, Length: 49997, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55125d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df['document']\n",
    "test_X = test_df['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d0f6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y =  train_df['label']\n",
    "test_y = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b84ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccae0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "train_X_cv = cv.fit_transform(train_X)\n",
    "test_X_cv = cv.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d533fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb6cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X_cv, train_y, test_size=0.4, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbbac856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a8f3e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8213773792459749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82     30158\n",
      "           1       0.80      0.86      0.83     29840\n",
      "\n",
      "    accuracy                           0.82     59998\n",
      "   macro avg       0.82      0.82      0.82     59998\n",
      "weighted avg       0.82      0.82      0.82     59998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "pred = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "492b8ee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8183691021461288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82     24826\n",
      "           1       0.83      0.81      0.82     25171\n",
      "\n",
      "    accuracy                           0.82     49997\n",
      "   macro avg       0.82      0.82      0.82     49997\n",
      "weighted avg       0.82      0.82      0.82     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = mnb.predict(test_X_cv)\n",
    "print(accuracy_score(test_y, test_pred))\n",
    "print(classification_report(test_y , test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5442ed8",
   "metadata": {},
   "source": [
    "# Konlpy의 Mecab을 이용해 형태소 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31841f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4acea50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokens = mecab.morphs(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffc71167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['document'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44ac3cea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['사이몬페그',\n",
       " '의',\n",
       " '익살',\n",
       " '스런',\n",
       " '연기',\n",
       " '가',\n",
       " '돋보였',\n",
       " '던',\n",
       " '영화',\n",
       " '스파이더맨',\n",
       " '에서',\n",
       " '늙',\n",
       " '어',\n",
       " '보이',\n",
       " '기',\n",
       " '만',\n",
       " '했',\n",
       " '던',\n",
       " '커스틴',\n",
       " '던스트',\n",
       " '가',\n",
       " '너무나',\n",
       " '도',\n",
       " '이뻐',\n",
       " '보였',\n",
       " '다']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(train_df['document'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f284531b",
   "metadata": {},
   "source": [
    "## countvectorizer 설명\n",
    "* tokenizer:\n",
    "설명: 텍스트 데이터를 단어(token) 단위로 나누는 역할을 합니다. tokenizer=tokenizer는 사용자가 정의한 tokenizer 함수를 사용한다는 의미입니다.\n",
    "예시: 이 tokenizer가 형태소 분석기일 수 있으며, 한국어 데이터를 처리할 때 주로 사용됩니다. 형태소 분석기를 사용하면 문장을 형태소 단위로 분리하여 보다 세밀한 단어 처리 및 분석을 할 수 있습니다.\n",
    "기본값: None일 경우, 기본적으로 CountVectorizer는 공백이나 기호를 기준으로 텍스트를 나누고, token_pattern='\\b\\w+\\b'을 사용해 단어를 추출합니다.\n",
    "* ngram_range=(1,2):\n",
    "설명: ngram_range는 벡터화할 때 단어 단위의 범위를 지정합니다. (1,2)로 설정된 경우, 1-gram과 2-gram을 모두 포함합니다. 즉, 단일 단어와 단어 2개의 조합(예: \"좋다\", \"영화 좋다\")을 모두 벡터화에 포함합니다.\n",
    "n-gram의 장점: 단어 간의 관계를 더 잘 반영할 수 있습니다. 예를 들어, \"좋다\"와 \"영화 좋다\"는 서로 다른 맥락에서 사용될 수 있으므로, 이를 별도로 처리할 수 있습니다. <br>\n",
    "예시: \"이 영화는 정말 좋다\"라는 문장이 있을 경우, ngram_range=(1,2)를 적용하면 다음과 같은 n-gram이 생성됩니다: <br>\n",
    "1-gram: ['이', '영화는', '정말', '좋다']<br>\n",
    "2-gram: ['이 영화는', '영화는 정말', '정말 좋다']<br>\n",
    "* min_df=3:<br>\n",
    "설명: min_df는 단어가 등장하는 최소 문서 수를 설정하는 하이퍼파라미터입니다. min_df=3은 단어가 최소 3개 이상의 문서에 등장해야 해당 단어를 벡터화 과정에 포함시키는 것을 의미합니다.\n",
    "목적: 너무 드물게 등장하는 단어는 의미가 없거나, 오히려 성능을 저해할 수 있기 때문에 이를 제거하기 위해 사용합니다. 일반적으로 자주 등장하지 않는 단어는 데이터에 노이즈를 추가하는 경향이 있습니다.\n",
    "예시: \"사자성어\" 같은 단어가 데이터셋 내에서 단 1~2회만 등장한다면, min_df=3으로 설정된 경우 이 단어는 벡터화에 포함되지 않습니다.\n",
    "* max_df=0.9:<br>\n",
    "설명: max_df는 단어가 등장하는 문서 비율의 최대치를 설정하는 하이퍼파라미터입니다. max_df=0.9는 단어가 전체 문서의 90% 이하에서 등장할 때만 벡터화에 포함시킵니다. 즉, 너무 자주 등장하는 단어(예: 불용어)는 제외됩니다.\n",
    "목적: 모든 문서에서 지나치게 자주 등장하는 단어(예: \"이\", \"그리고\" 등)는 의미를 거의 제공하지 않기 때문에 이를 제거하기 위해 사용됩니다. 이처럼 너무 빈번하게 등장하는 단어는 일반적으로 텍스트의 구분에 유용하지 않다고 여겨집니다.\n",
    "예시: 만약 \"영화\"라는 단어가 거의 모든 문서에서 등장한다면, max_df=0.9로 설정된 경우 이 단어는 벡터화 과정에서 제외됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6400390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b9cc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(tokenizer=tokenizer, max_df=0.8, min_df=3, ngram_range=(1, 2))\n",
    "train_X_cv = cv.fit_transform(train_X)\n",
    "test_X_cv = cv.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa10bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install koreanize-matplotlib\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92948546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55b74767",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X_cv, train_y, test_size=0.4, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "674cdeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08103981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8581952731757725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86     30158\n",
      "           1       0.86      0.85      0.86     29840\n",
      "\n",
      "    accuracy                           0.86     59998\n",
      "   macro avg       0.86      0.86      0.86     59998\n",
      "weighted avg       0.86      0.86      0.86     59998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "pred = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab928dca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856471388283297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86     24826\n",
      "           1       0.86      0.85      0.86     25171\n",
      "\n",
      "    accuracy                           0.86     49997\n",
      "   macro avg       0.86      0.86      0.86     49997\n",
      "weighted avg       0.86      0.86      0.86     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = mnb.predict(test_X_cv)\n",
    "print(accuracy_score(test_y, test_pred))\n",
    "print(classification_report(test_y , test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e79aa3",
   "metadata": {},
   "source": [
    "# TfidfVectorizer : 단어의 중요도를 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09b6e5",
   "metadata": {},
   "source": [
    "2) TfidfVectorizer: TF-IDF (Term Frequency-Inverse Document Frequency) 기반 벡터화\n",
    "작동 방식: TfidfVectorizer는 단어의 빈도뿐만 아니라, 단어의 중요도를 계산합니다. 여기서는 TF-IDF 값을 사용하여 문서 간 차별성을 강조합니다.\n",
    "* TF (Term Frequency): 단어가 문서에서 얼마나 자주 등장했는지를 나타냅니다.\n",
    "* IDF (Inverse Document Frequency): 단어가 다른 문서에 얼마나 자주 등장하지 않았는지를 나타냅니다. 자주 등장하지 않는 단어는 더 중요한 단어로 간주합니다.\n",
    "* 특징:\n",
    "TF-IDF는 문서 전체에서 자주 등장하는 흔한 단어들(예: \"그리고\", \"이다\" 등)의 중요도를 낮추고, 문서에서만 중요한 단어들의 중요도를 높입니다.\n",
    "단순히 빈도가 높은 단어보다 특정 문서에서 더 특징적인 단어에 더 높은 가중치를 부여합니다.\n",
    "* 예시:\n",
    "위의 문서 1과 문서 2에 대해 TfidfVectorizer로 변환하면, 공통 단어들(예: \"있다\", \"고양이\")의 중요도는 낮아지고, 차별적인 단어(예: \"위에\", \"아래에\")의 중요도는 상대적으로 높아집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de7e382",
   "metadata": {},
   "source": [
    "### CountVectorizer와 TfidfVectorizer 비교\n",
    "\n",
    "| **특성**             | **CountVectorizer**                                     | **TfidfVectorizer**                                               |\n",
    "|----------------------|--------------------------------------------------------|-------------------------------------------------------------------|\n",
    "| **기반**             | 단어의 단순 빈도                                        | 단어 빈도 + 문서 내에서의 상대적 중요도(TF-IDF)                     |\n",
    "| **단어 빈도 계산**    | 문서에서 등장한 단어의 단순한 등장 횟수를 셈            | 단어의 등장 횟수(TF)와 해당 단어가 문서들에서 얼마나 자주 등장하지 않았는지를 함께 고려(IDF) |\n",
    "| **빈번한 단어 처리**  | 문서에서 자주 등장하는 단어일수록 높은 가중치를 부여    | 문서에서 흔한 단어는 가중치를 낮추고, 드문 단어는 높은 가중치를 부여   |\n",
    "| **주요 용도**        | 단순한 단어 빈도 기반 분석이 필요할 때 사용             | 문서 간 차별적인 단어를 구별할 때 유용                                |\n",
    "| **계산 비용**         | 상대적으로 적음                                         | 상대적으로 더 복잡하고 계산 비용이 높음                                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6a55bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70b1ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['고양이가' '나무' '아래에' '위에' '있다']\n",
      "[[1 1 0 1 1]\n",
      " [1 1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "documents = [\"고양이가 나무 위에 있다\", \"나무 아래에 고양이가 있다\"]\n",
    "c_vec = CountVectorizer()\n",
    "sample = c_vec.fit_transform(documents)\n",
    "print(c_vec.get_feature_names_out())\n",
    "print(sample.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1485aa98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['고양이가' '나무' '아래에' '위에' '있다']\n",
      "[[0.44832087 0.44832087 0.         0.63009934 0.44832087]\n",
      " [0.44832087 0.44832087 0.63009934 0.         0.44832087]]\n"
     ]
    }
   ],
   "source": [
    "documents = [\"고양이가 나무 위에 있다\", \"나무 아래에 고양이가 있다\"]\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "sample = tfidf_vec.fit_transform(documents)\n",
    "print(tfidf_vec.get_feature_names_out())\n",
    "print(sample.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e0e4019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(tokenizer=tokenizer, max_df=0.8, min_df=3, ngram_range=(1, 2))\n",
    "train_X_cv = tfidf_vec.fit_transform(train_X)\n",
    "test_X_cv = tfidf_vec.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c54502bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install koreanize-matplotlib\n",
    "import koreanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95c6b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71b890d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X_cv, train_y, test_size=0.4, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "305ad858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d0be270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8614787159571986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86     30158\n",
      "           1       0.87      0.85      0.86     29840\n",
      "\n",
      "    accuracy                           0.86     59998\n",
      "   macro avg       0.86      0.86      0.86     59998\n",
      "weighted avg       0.86      0.86      0.86     59998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "pred = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e0168cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8601916114966898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86     24826\n",
      "           1       0.87      0.85      0.86     25171\n",
      "\n",
      "    accuracy                           0.86     49997\n",
      "   macro avg       0.86      0.86      0.86     49997\n",
      "weighted avg       0.86      0.86      0.86     49997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred = mnb.predict(test_X_cv)\n",
    "print(accuracy_score(test_y, test_pred))\n",
    "print(classification_report(test_y , test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3485849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3700f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b8b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62151e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f7b5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
