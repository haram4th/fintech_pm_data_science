{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f8586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395851eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/iris3.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ff80ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39a94cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f17ae72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e7a92b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ec4ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"species\", axis=1)\n",
    "y = data['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68878267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36098625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0        0.222222     0.625000      0.067797     0.041667\n",
       "1        0.166667     0.416667      0.067797     0.041667\n",
       "2        0.111111     0.500000      0.050847     0.041667\n",
       "3        0.083333     0.458333      0.084746     0.041667\n",
       "4        0.194444     0.666667      0.067797     0.041667\n",
       "..            ...          ...           ...          ...\n",
       "145      0.666667     0.416667      0.711864     0.916667\n",
       "146      0.555556     0.208333      0.677966     0.750000\n",
       "147      0.611111     0.416667      0.711864     0.791667\n",
       "148      0.527778     0.583333      0.745763     0.916667\n",
       "149      0.444444     0.416667      0.694915     0.708333\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mms = MinMaxScaler()\n",
    "X_scaled = mms.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "267d110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3193c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_labeled = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ae0c2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87a5963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72a213d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ec57c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_scaled, y_labeled, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2eb19c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=3, random_state=10)\n",
    "dtc.fit(X_train2, y_train2)\n",
    "pred2 = dtc.predict(X_test2)\n",
    "print(classification_report(y_test2, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15076de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38d55bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0           True            False           False\n",
       "1           True            False           False\n",
       "2           True            False           False\n",
       "3           True            False           False\n",
       "4           True            False           False\n",
       "..           ...              ...             ...\n",
       "145        False            False            True\n",
       "146        False            False            True\n",
       "147        False            False            True\n",
       "148        False            False            True\n",
       "149        False            False            True\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1214ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size= 0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2cd3f1",
   "metadata": {},
   "source": [
    "# Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1724f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aa4c950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fd1ea12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                60        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159\n",
      "Trainable params: 159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 16:19:43.821420: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 16:19:43.823794: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (AMD Radeon(TM) RX Vega 11 Graphics)\n",
      "2024-09-09 16:19:43.937879: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 16:19:43.937949: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2024-09-09 16:19:43.937976: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax' ))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "744056d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 16:33:44.051784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 16:33:44.122274: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 16:33:44.122376: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 825ms/step - loss: 0.0647 - accuracy: 0.9619 - val_loss: 0.0328 - val_accuracy: 0.9778\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0645 - accuracy: 0.9810 - val_loss: 0.0337 - val_accuracy: 0.9778\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 16:33:44.394589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 16:33:44.432227: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 16:33:44.432307: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0643 - accuracy: 0.9619 - val_loss: 0.0342 - val_accuracy: 0.9778\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0642 - accuracy: 0.9619 - val_loss: 0.0343 - val_accuracy: 0.9778\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0640 - accuracy: 0.9714 - val_loss: 0.0344 - val_accuracy: 0.9778\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0639 - accuracy: 0.9714 - val_loss: 0.0342 - val_accuracy: 0.9778\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0638 - accuracy: 0.9714 - val_loss: 0.0341 - val_accuracy: 0.9778\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0637 - accuracy: 0.9714 - val_loss: 0.0340 - val_accuracy: 0.9778\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0636 - accuracy: 0.9714 - val_loss: 0.0341 - val_accuracy: 0.9778\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0636 - accuracy: 0.9714 - val_loss: 0.0340 - val_accuracy: 0.9778\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0635 - accuracy: 0.9714 - val_loss: 0.0339 - val_accuracy: 0.9778\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0635 - accuracy: 0.9714 - val_loss: 0.0337 - val_accuracy: 0.9778\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0634 - accuracy: 0.9714 - val_loss: 0.0335 - val_accuracy: 0.9778\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0633 - accuracy: 0.9714 - val_loss: 0.0333 - val_accuracy: 0.9778\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0632 - accuracy: 0.9714 - val_loss: 0.0332 - val_accuracy: 0.9778\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0630 - accuracy: 0.9714 - val_loss: 0.0331 - val_accuracy: 0.9778\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0630 - accuracy: 0.9714 - val_loss: 0.0330 - val_accuracy: 0.9778\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0629 - accuracy: 0.9714 - val_loss: 0.0329 - val_accuracy: 0.9778\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0628 - accuracy: 0.9714 - val_loss: 0.0328 - val_accuracy: 0.9778\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0628 - accuracy: 0.9810 - val_loss: 0.0327 - val_accuracy: 0.9778\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0627 - accuracy: 0.9810 - val_loss: 0.0325 - val_accuracy: 0.9778\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0626 - accuracy: 0.9810 - val_loss: 0.0324 - val_accuracy: 0.9778\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0625 - accuracy: 0.9810 - val_loss: 0.0322 - val_accuracy: 0.9778\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 0.0321 - val_accuracy: 0.9778\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0623 - accuracy: 0.9810 - val_loss: 0.0320 - val_accuracy: 0.9778\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0622 - accuracy: 0.9810 - val_loss: 0.0319 - val_accuracy: 0.9778\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0622 - accuracy: 0.9810 - val_loss: 0.0318 - val_accuracy: 0.9778\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0621 - accuracy: 0.9810 - val_loss: 0.0317 - val_accuracy: 0.9778\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0620 - accuracy: 0.9810 - val_loss: 0.0316 - val_accuracy: 0.9778\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0619 - accuracy: 0.9810 - val_loss: 0.0314 - val_accuracy: 0.9778\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0619 - accuracy: 0.9810 - val_loss: 0.0313 - val_accuracy: 0.9778\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0618 - accuracy: 0.9810 - val_loss: 0.0312 - val_accuracy: 0.9778\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0617 - accuracy: 0.9810 - val_loss: 0.0311 - val_accuracy: 0.9778\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0616 - accuracy: 0.9810 - val_loss: 0.0309 - val_accuracy: 0.9778\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0616 - accuracy: 0.9810 - val_loss: 0.0308 - val_accuracy: 0.9778\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0615 - accuracy: 0.9810 - val_loss: 0.0307 - val_accuracy: 0.9778\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0614 - accuracy: 0.9810 - val_loss: 0.0307 - val_accuracy: 0.9778\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0613 - accuracy: 0.9810 - val_loss: 0.0307 - val_accuracy: 0.9778\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0613 - accuracy: 0.9810 - val_loss: 0.0306 - val_accuracy: 0.9778\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0612 - accuracy: 0.9810 - val_loss: 0.0305 - val_accuracy: 0.9778\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 0.0303 - val_accuracy: 0.9778\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 0.0302 - val_accuracy: 0.9778\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.0300 - val_accuracy: 0.9778\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0609 - accuracy: 0.9810 - val_loss: 0.0300 - val_accuracy: 0.9778\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0609 - accuracy: 0.9810 - val_loss: 0.0300 - val_accuracy: 0.9778\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0608 - accuracy: 0.9810 - val_loss: 0.0300 - val_accuracy: 0.9778\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0607 - accuracy: 0.9810 - val_loss: 0.0299 - val_accuracy: 0.9778\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0607 - accuracy: 0.9810 - val_loss: 0.0297 - val_accuracy: 0.9778\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0606 - accuracy: 0.9810 - val_loss: 0.0296 - val_accuracy: 0.9778\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.0295 - val_accuracy: 0.9778\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.0295 - val_accuracy: 0.9778\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0604 - accuracy: 0.9810 - val_loss: 0.0295 - val_accuracy: 0.9778\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0603 - accuracy: 0.9810 - val_loss: 0.0295 - val_accuracy: 0.9778\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0603 - accuracy: 0.9810 - val_loss: 0.0293 - val_accuracy: 0.9778\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0602 - accuracy: 0.9810 - val_loss: 0.0292 - val_accuracy: 0.9778\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0602 - accuracy: 0.9810 - val_loss: 0.0291 - val_accuracy: 0.9778\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0601 - accuracy: 0.9810 - val_loss: 0.0291 - val_accuracy: 0.9778\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.0291 - val_accuracy: 0.9778\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.0290 - val_accuracy: 0.9778\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0599 - accuracy: 0.9810 - val_loss: 0.0289 - val_accuracy: 0.9778\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0599 - accuracy: 0.9810 - val_loss: 0.0289 - val_accuracy: 0.9778\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.0289 - val_accuracy: 0.9778\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0597 - accuracy: 0.9810 - val_loss: 0.0288 - val_accuracy: 0.9778\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0597 - accuracy: 0.9810 - val_loss: 0.0287 - val_accuracy: 0.9778\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 0.0286 - val_accuracy: 0.9778\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 0.0286 - val_accuracy: 0.9778\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 0.0286 - val_accuracy: 0.9778\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 0.0286 - val_accuracy: 0.9778\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0594 - accuracy: 0.9810 - val_loss: 0.0286 - val_accuracy: 0.9778\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0594 - accuracy: 0.9810 - val_loss: 0.0284 - val_accuracy: 0.9778\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.0283 - val_accuracy: 0.9778\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.0282 - val_accuracy: 0.9778\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.0282 - val_accuracy: 0.9778\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.0283 - val_accuracy: 0.9778\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.0283 - val_accuracy: 0.9778\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.0282 - val_accuracy: 0.9778\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.0280 - val_accuracy: 0.9778\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0589 - accuracy: 0.9810 - val_loss: 0.0279 - val_accuracy: 0.9778\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0589 - accuracy: 0.9810 - val_loss: 0.0280 - val_accuracy: 0.9778\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0280 - val_accuracy: 0.9778\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0280 - val_accuracy: 0.9778\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 0.0279 - val_accuracy: 0.9778\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 0.0278 - val_accuracy: 0.9778\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0586 - accuracy: 0.9810 - val_loss: 0.0277 - val_accuracy: 0.9778\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0586 - accuracy: 0.9810 - val_loss: 0.0277 - val_accuracy: 0.9778\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0585 - accuracy: 0.9810 - val_loss: 0.0278 - val_accuracy: 0.9778\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0585 - accuracy: 0.9810 - val_loss: 0.0278 - val_accuracy: 0.9778\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0584 - accuracy: 0.9810 - val_loss: 0.0277 - val_accuracy: 0.9778\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0584 - accuracy: 0.9810 - val_loss: 0.0276 - val_accuracy: 0.9778\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0583 - accuracy: 0.9810 - val_loss: 0.0275 - val_accuracy: 0.9778\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0583 - accuracy: 0.9810 - val_loss: 0.0275 - val_accuracy: 0.9778\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0582 - accuracy: 0.9810 - val_loss: 0.0276 - val_accuracy: 0.9778\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0582 - accuracy: 0.9810 - val_loss: 0.0275 - val_accuracy: 0.9778\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0581 - accuracy: 0.9810 - val_loss: 0.0274 - val_accuracy: 0.9778\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0581 - accuracy: 0.9810 - val_loss: 0.0273 - val_accuracy: 0.9778\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.0273 - val_accuracy: 0.9778\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.0273 - val_accuracy: 0.9778\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.0274 - val_accuracy: 0.9778\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.0273 - val_accuracy: 0.9778\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.0272 - val_accuracy: 0.9778\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0578 - accuracy: 0.9810 - val_loss: 0.0271 - val_accuracy: 0.9778\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0578 - accuracy: 0.9810 - val_loss: 0.0271 - val_accuracy: 0.9778\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.0271 - val_accuracy: 0.9778\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.0271 - val_accuracy: 0.9778\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0270 - val_accuracy: 0.9778\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0270 - val_accuracy: 0.9778\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0269 - val_accuracy: 0.9778\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0269 - val_accuracy: 0.9778\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0269 - val_accuracy: 0.9778\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0574 - accuracy: 0.9810 - val_loss: 0.0268 - val_accuracy: 0.9778\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0574 - accuracy: 0.9810 - val_loss: 0.0268 - val_accuracy: 0.9778\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0573 - accuracy: 0.9810 - val_loss: 0.0267 - val_accuracy: 0.9778\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0573 - accuracy: 0.9810 - val_loss: 0.0267 - val_accuracy: 0.9778\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0573 - accuracy: 0.9810 - val_loss: 0.0267 - val_accuracy: 0.9778\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.0267 - val_accuracy: 0.9778\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.0267 - val_accuracy: 0.9778\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0571 - accuracy: 0.9810 - val_loss: 0.0266 - val_accuracy: 0.9778\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0571 - accuracy: 0.9810 - val_loss: 0.0265 - val_accuracy: 0.9778\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0571 - accuracy: 0.9810 - val_loss: 0.0264 - val_accuracy: 0.9778\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0570 - accuracy: 0.9810 - val_loss: 0.0264 - val_accuracy: 0.9778\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0570 - accuracy: 0.9810 - val_loss: 0.0265 - val_accuracy: 0.9778\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.0265 - val_accuracy: 0.9778\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.0265 - val_accuracy: 0.9778\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.0263 - val_accuracy: 0.9778\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0568 - accuracy: 0.9810 - val_loss: 0.0262 - val_accuracy: 0.9778\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0568 - accuracy: 0.9810 - val_loss: 0.0262 - val_accuracy: 0.9778\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0568 - accuracy: 0.9810 - val_loss: 0.0263 - val_accuracy: 0.9778\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0567 - accuracy: 0.9810 - val_loss: 0.0263 - val_accuracy: 0.9778\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0567 - accuracy: 0.9810 - val_loss: 0.0262 - val_accuracy: 0.9778\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0566 - accuracy: 0.9810 - val_loss: 0.0261 - val_accuracy: 0.9778\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0566 - accuracy: 0.9810 - val_loss: 0.0260 - val_accuracy: 0.9778\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0566 - accuracy: 0.9810 - val_loss: 0.0260 - val_accuracy: 0.9778\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.0261 - val_accuracy: 0.9778\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.0261 - val_accuracy: 0.9778\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.0260 - val_accuracy: 0.9778\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0564 - accuracy: 0.9810 - val_loss: 0.0259 - val_accuracy: 0.9778\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0564 - accuracy: 0.9810 - val_loss: 0.0258 - val_accuracy: 0.9778\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0564 - accuracy: 0.9810 - val_loss: 0.0259 - val_accuracy: 0.9778\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0563 - accuracy: 0.9810 - val_loss: 0.0259 - val_accuracy: 0.9778\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0563 - accuracy: 0.9810 - val_loss: 0.0259 - val_accuracy: 0.9778\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0563 - accuracy: 0.9810 - val_loss: 0.0258 - val_accuracy: 0.9778\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0562 - accuracy: 0.9810 - val_loss: 0.0257 - val_accuracy: 0.9778\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0562 - accuracy: 0.9810 - val_loss: 0.0257 - val_accuracy: 0.9778\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0562 - accuracy: 0.9810 - val_loss: 0.0257 - val_accuracy: 0.9778\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0561 - accuracy: 0.9810 - val_loss: 0.0258 - val_accuracy: 0.9778\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0561 - accuracy: 0.9810 - val_loss: 0.0257 - val_accuracy: 0.9778\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0561 - accuracy: 0.9810 - val_loss: 0.0256 - val_accuracy: 0.9778\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0560 - accuracy: 0.9810 - val_loss: 0.0255 - val_accuracy: 0.9778\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0560 - accuracy: 0.9810 - val_loss: 0.0256 - val_accuracy: 0.9778\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0560 - accuracy: 0.9810 - val_loss: 0.0256 - val_accuracy: 0.9778\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0559 - accuracy: 0.9810 - val_loss: 0.0255 - val_accuracy: 0.9778\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0559 - accuracy: 0.9810 - val_loss: 0.0255 - val_accuracy: 0.9778\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0559 - accuracy: 0.9810 - val_loss: 0.0254 - val_accuracy: 0.9778\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0559 - accuracy: 0.9810 - val_loss: 0.0254 - val_accuracy: 0.9778\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0558 - accuracy: 0.9810 - val_loss: 0.0254 - val_accuracy: 0.9778\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0558 - accuracy: 0.9810 - val_loss: 0.0254 - val_accuracy: 0.9778\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0558 - accuracy: 0.9810 - val_loss: 0.0253 - val_accuracy: 0.9778\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0557 - accuracy: 0.9810 - val_loss: 0.0253 - val_accuracy: 0.9778\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0557 - accuracy: 0.9810 - val_loss: 0.0253 - val_accuracy: 0.9778\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0557 - accuracy: 0.9810 - val_loss: 0.0253 - val_accuracy: 0.9778\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0556 - accuracy: 0.9810 - val_loss: 0.0253 - val_accuracy: 0.9778\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0556 - accuracy: 0.9810 - val_loss: 0.0252 - val_accuracy: 0.9778\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0556 - accuracy: 0.9810 - val_loss: 0.0252 - val_accuracy: 0.9778\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0556 - accuracy: 0.9810 - val_loss: 0.0251 - val_accuracy: 0.9778\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0555 - accuracy: 0.9810 - val_loss: 0.0251 - val_accuracy: 0.9778\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0555 - accuracy: 0.9810 - val_loss: 0.0251 - val_accuracy: 0.9778\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0555 - accuracy: 0.9810 - val_loss: 0.0251 - val_accuracy: 0.9778\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0555 - accuracy: 0.9810 - val_loss: 0.0251 - val_accuracy: 0.9778\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0554 - accuracy: 0.9810 - val_loss: 0.0250 - val_accuracy: 0.9778\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0554 - accuracy: 0.9810 - val_loss: 0.0250 - val_accuracy: 0.9778\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0554 - accuracy: 0.9810 - val_loss: 0.0250 - val_accuracy: 0.9778\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0553 - accuracy: 0.9810 - val_loss: 0.0250 - val_accuracy: 0.9778\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0553 - accuracy: 0.9810 - val_loss: 0.0250 - val_accuracy: 0.9778\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0553 - accuracy: 0.9810 - val_loss: 0.0249 - val_accuracy: 0.9778\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0553 - accuracy: 0.9810 - val_loss: 0.0249 - val_accuracy: 0.9778\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.0248 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.0249 - val_accuracy: 0.9778\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.0249 - val_accuracy: 0.9778\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.0248 - val_accuracy: 0.9778\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0248 - val_accuracy: 0.9778\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0247 - val_accuracy: 0.9778\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0247 - val_accuracy: 0.9778\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0551 - accuracy: 0.9810 - val_loss: 0.0247 - val_accuracy: 0.9778\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0550 - accuracy: 0.9810 - val_loss: 0.0247 - val_accuracy: 0.9778\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0550 - accuracy: 0.9810 - val_loss: 0.0246 - val_accuracy: 0.9778\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0550 - accuracy: 0.9810 - val_loss: 0.0246 - val_accuracy: 0.9778\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0550 - accuracy: 0.9810 - val_loss: 0.0246 - val_accuracy: 0.9778\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0549 - accuracy: 0.9810 - val_loss: 0.0246 - val_accuracy: 0.9778\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0549 - accuracy: 0.9810 - val_loss: 0.0246 - val_accuracy: 0.9778\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0549 - accuracy: 0.9810 - val_loss: 0.0245 - val_accuracy: 0.9778\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0549 - accuracy: 0.9810 - val_loss: 0.0245 - val_accuracy: 0.9778\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0548 - accuracy: 0.9810 - val_loss: 0.0245 - val_accuracy: 0.9778\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0548 - accuracy: 0.9810 - val_loss: 0.0246 - val_accuracy: 0.9778\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0548 - accuracy: 0.9810 - val_loss: 0.0245 - val_accuracy: 0.9778\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0548 - accuracy: 0.9810 - val_loss: 0.0244 - val_accuracy: 0.9778\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0548 - accuracy: 0.9810 - val_loss: 0.0244 - val_accuracy: 0.9778\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0547 - accuracy: 0.9810 - val_loss: 0.0244 - val_accuracy: 0.9778\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0547 - accuracy: 0.9810 - val_loss: 0.0244 - val_accuracy: 0.9778\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0547 - accuracy: 0.9810 - val_loss: 0.0244 - val_accuracy: 0.9778\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0547 - accuracy: 0.9810 - val_loss: 0.0244 - val_accuracy: 0.9778\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.0243 - val_accuracy: 0.9778\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.0243 - val_accuracy: 0.9778\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.0243 - val_accuracy: 0.9778\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.0243 - val_accuracy: 0.9778\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.0243 - val_accuracy: 0.9778\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 0.0242 - val_accuracy: 0.9778\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 0.0242 - val_accuracy: 0.9778\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 0.0242 - val_accuracy: 0.9778\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 0.0242 - val_accuracy: 0.9778\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 0.0242 - val_accuracy: 0.9778\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 0.0241 - val_accuracy: 0.9778\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 0.0241 - val_accuracy: 0.9778\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 0.0241 - val_accuracy: 0.9778\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 0.0241 - val_accuracy: 0.9778\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 0.0241 - val_accuracy: 0.9778\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.0240 - val_accuracy: 0.9778\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.0240 - val_accuracy: 0.9778\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.0240 - val_accuracy: 0.9778\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.0240 - val_accuracy: 0.9778\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.0240 - val_accuracy: 0.9778\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0543 - accuracy: 0.9810 - val_loss: 0.0240 - val_accuracy: 0.9778\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.0239 - val_accuracy: 0.9778\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.0239 - val_accuracy: 0.9778\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.0239 - val_accuracy: 0.9778\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.0239 - val_accuracy: 0.9778\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.0239 - val_accuracy: 0.9778\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0239 - val_accuracy: 0.9778\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0238 - val_accuracy: 0.9778\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0238 - val_accuracy: 0.9778\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0238 - val_accuracy: 0.9778\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0238 - val_accuracy: 0.9778\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.0238 - val_accuracy: 0.9778\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0540 - accuracy: 0.9810 - val_loss: 0.0238 - val_accuracy: 0.9778\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0540 - accuracy: 0.9810 - val_loss: 0.0238 - val_accuracy: 0.9778\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0540 - accuracy: 0.9810 - val_loss: 0.0237 - val_accuracy: 0.9778\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0540 - accuracy: 0.9810 - val_loss: 0.0237 - val_accuracy: 0.9778\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0540 - accuracy: 0.9810 - val_loss: 0.0237 - val_accuracy: 0.9778\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0540 - accuracy: 0.9810 - val_loss: 0.0237 - val_accuracy: 0.9778\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0236 - val_accuracy: 0.9778\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0237 - val_accuracy: 0.9778\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0237 - val_accuracy: 0.9778\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0236 - val_accuracy: 0.9778\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0236 - val_accuracy: 0.9778\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0236 - val_accuracy: 0.9778\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.0236 - val_accuracy: 0.9778\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0236 - val_accuracy: 0.9778\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0236 - val_accuracy: 0.9778\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0235 - val_accuracy: 0.9778\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0235 - val_accuracy: 0.9778\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0235 - val_accuracy: 0.9778\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0538 - accuracy: 0.9810 - val_loss: 0.0235 - val_accuracy: 0.9778\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.0235 - val_accuracy: 0.9778\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.0234 - val_accuracy: 0.9778\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.0235 - val_accuracy: 0.9778\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.0235 - val_accuracy: 0.9778\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.0235 - val_accuracy: 0.9778\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.0234 - val_accuracy: 0.9778\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.0234 - val_accuracy: 0.9778\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0537 - accuracy: 0.9810 - val_loss: 0.0234 - val_accuracy: 0.9778\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0234 - val_accuracy: 0.9778\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0234 - val_accuracy: 0.9778\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0234 - val_accuracy: 0.9778\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0233 - val_accuracy: 0.9778\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0233 - val_accuracy: 0.9778\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0233 - val_accuracy: 0.9778\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.0234 - val_accuracy: 0.9778\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0233 - val_accuracy: 0.9778\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0232 - val_accuracy: 0.9778\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0232 - val_accuracy: 0.9778\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0233 - val_accuracy: 0.9778\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0233 - val_accuracy: 0.9778\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0233 - val_accuracy: 0.9778\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0232 - val_accuracy: 0.9778\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0232 - val_accuracy: 0.9778\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0535 - accuracy: 0.9810 - val_loss: 0.0232 - val_accuracy: 0.9778\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0232 - val_accuracy: 0.9778\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0232 - val_accuracy: 0.9778\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0231 - val_accuracy: 0.9778\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0231 - val_accuracy: 0.9778\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0232 - val_accuracy: 0.9778\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0231 - val_accuracy: 0.9778\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0231 - val_accuracy: 0.9778\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0231 - val_accuracy: 0.9778\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0231 - val_accuracy: 0.9778\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0231 - val_accuracy: 0.9778\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0231 - val_accuracy: 0.9778\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0230 - val_accuracy: 0.9778\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0230 - val_accuracy: 0.9778\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0230 - val_accuracy: 0.9778\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0230 - val_accuracy: 0.9778\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0230 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0230 - val_accuracy: 0.9778\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0533 - accuracy: 0.9810 - val_loss: 0.0230 - val_accuracy: 0.9778\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0230 - val_accuracy: 0.9778\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0230 - val_accuracy: 0.9778\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0229 - val_accuracy: 0.9778\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0229 - val_accuracy: 0.9778\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0229 - val_accuracy: 0.9778\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0229 - val_accuracy: 0.9778\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0229 - val_accuracy: 0.9778\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0229 - val_accuracy: 0.9778\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0229 - val_accuracy: 0.9778\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 0.0229 - val_accuracy: 0.9778\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0229 - val_accuracy: 0.9778\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0229 - val_accuracy: 0.9778\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0228 - val_accuracy: 0.9778\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0228 - val_accuracy: 0.9778\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0228 - val_accuracy: 0.9778\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0228 - val_accuracy: 0.9778\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0228 - val_accuracy: 0.9778\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0228 - val_accuracy: 0.9778\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0228 - val_accuracy: 0.9778\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0228 - val_accuracy: 0.9778\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0228 - val_accuracy: 0.9778\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.0228 - val_accuracy: 0.9778\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0227 - val_accuracy: 0.9778\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0227 - val_accuracy: 0.9778\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0227 - val_accuracy: 0.9778\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0227 - val_accuracy: 0.9778\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0227 - val_accuracy: 0.9778\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0227 - val_accuracy: 0.9778\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0227 - val_accuracy: 0.9778\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0226 - val_accuracy: 0.9778\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0226 - val_accuracy: 0.9778\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0226 - val_accuracy: 0.9778\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0226 - val_accuracy: 0.9778\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.0226 - val_accuracy: 0.9778\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0226 - val_accuracy: 0.9778\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0226 - val_accuracy: 0.9778\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0225 - val_accuracy: 0.9778\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0225 - val_accuracy: 0.9778\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0225 - val_accuracy: 0.9778\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0225 - val_accuracy: 0.9778\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0225 - val_accuracy: 0.9778\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0224 - val_accuracy: 0.9778\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0224 - val_accuracy: 0.9778\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0224 - val_accuracy: 0.9778\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0224 - val_accuracy: 0.9778\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0224 - val_accuracy: 0.9778\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.0223 - val_accuracy: 0.9778\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0223 - val_accuracy: 0.9778\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0223 - val_accuracy: 0.9778\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0527 - accuracy: 0.9810 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0210 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0525 - accuracy: 0.9810 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0201 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9de042a5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 16:34:31.336426: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=150, validation_data=(X_test, y_test))\n",
    "pred = model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9435a832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d549b630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60686749",
   "metadata": {},
   "source": [
    "# 함수형 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0f8daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ade405a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc23c0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cb749a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(16, activation='relu')(inputs)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e9ff3ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                80        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243\n",
      "Trainable params: 243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs, x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f884b35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1581 - accuracy: 0.3143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 17:22:35.014087: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 17:22:35.080965: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 17:22:35.081049: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 811ms/step - loss: 1.1581 - accuracy: 0.3143 - val_loss: 1.1085 - val_accuracy: 0.3778\n",
      "Epoch 2/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1534 - accuracy: 0.3143 - val_loss: 1.1049 - val_accuracy: 0.3778\n",
      "Epoch 3/400\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1488 - accuracy: 0.3143"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 17:22:35.315886: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 17:22:35.349469: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 17:22:35.349575: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1488 - accuracy: 0.3143 - val_loss: 1.1014 - val_accuracy: 0.3778\n",
      "Epoch 4/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.1442 - accuracy: 0.3143 - val_loss: 1.0978 - val_accuracy: 0.3778\n",
      "Epoch 5/400\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.1397 - accuracy: 0.3143 - val_loss: 1.0942 - val_accuracy: 0.3778\n",
      "Epoch 6/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.1352 - accuracy: 0.3143 - val_loss: 1.0907 - val_accuracy: 0.3778\n",
      "Epoch 7/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.1308 - accuracy: 0.3143 - val_loss: 1.0873 - val_accuracy: 0.3778\n",
      "Epoch 8/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.1264 - accuracy: 0.3143 - val_loss: 1.0839 - val_accuracy: 0.3778\n",
      "Epoch 9/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.1220 - accuracy: 0.3143 - val_loss: 1.0805 - val_accuracy: 0.3778\n",
      "Epoch 10/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 1.1177 - accuracy: 0.3143 - val_loss: 1.0772 - val_accuracy: 0.3778\n",
      "Epoch 11/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.1135 - accuracy: 0.3143 - val_loss: 1.0739 - val_accuracy: 0.3778\n",
      "Epoch 12/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.1092 - accuracy: 0.3143 - val_loss: 1.0706 - val_accuracy: 0.3778\n",
      "Epoch 13/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 1.1051 - accuracy: 0.3143 - val_loss: 1.0674 - val_accuracy: 0.3778\n",
      "Epoch 14/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.1010 - accuracy: 0.3143 - val_loss: 1.0641 - val_accuracy: 0.3778\n",
      "Epoch 15/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0969 - accuracy: 0.3143 - val_loss: 1.0609 - val_accuracy: 0.3778\n",
      "Epoch 16/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.0928 - accuracy: 0.3143 - val_loss: 1.0576 - val_accuracy: 0.3778\n",
      "Epoch 17/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0888 - accuracy: 0.3143 - val_loss: 1.0544 - val_accuracy: 0.3778\n",
      "Epoch 18/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.0848 - accuracy: 0.3143 - val_loss: 1.0511 - val_accuracy: 0.3778\n",
      "Epoch 19/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0809 - accuracy: 0.3143 - val_loss: 1.0479 - val_accuracy: 0.3778\n",
      "Epoch 20/400\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.0770 - accuracy: 0.3143 - val_loss: 1.0447 - val_accuracy: 0.3778\n",
      "Epoch 21/400\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 1.0732 - accuracy: 0.3143 - val_loss: 1.0415 - val_accuracy: 0.3778\n",
      "Epoch 22/400\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 1.0695 - accuracy: 0.3143 - val_loss: 1.0384 - val_accuracy: 0.3778\n",
      "Epoch 23/400\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.0657 - accuracy: 0.3143 - val_loss: 1.0353 - val_accuracy: 0.3778\n",
      "Epoch 24/400\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.0620 - accuracy: 0.3143 - val_loss: 1.0323 - val_accuracy: 0.3778\n",
      "Epoch 25/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 1.0584 - accuracy: 0.3143 - val_loss: 1.0293 - val_accuracy: 0.3778\n",
      "Epoch 26/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0548 - accuracy: 0.3143 - val_loss: 1.0264 - val_accuracy: 0.3778\n",
      "Epoch 27/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0513 - accuracy: 0.3143 - val_loss: 1.0236 - val_accuracy: 0.3778\n",
      "Epoch 28/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 1.0479 - accuracy: 0.3143 - val_loss: 1.0208 - val_accuracy: 0.3778\n",
      "Epoch 29/400\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.0445 - accuracy: 0.3143 - val_loss: 1.0180 - val_accuracy: 0.3778\n",
      "Epoch 30/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.0412 - accuracy: 0.3143 - val_loss: 1.0152 - val_accuracy: 0.3778\n",
      "Epoch 31/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.0379 - accuracy: 0.3143 - val_loss: 1.0126 - val_accuracy: 0.3778\n",
      "Epoch 32/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 1.0347 - accuracy: 0.3143 - val_loss: 1.0099 - val_accuracy: 0.3778\n",
      "Epoch 33/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 1.0315 - accuracy: 0.3143 - val_loss: 1.0073 - val_accuracy: 0.3778\n",
      "Epoch 34/400\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0283 - accuracy: 0.3143 - val_loss: 1.0047 - val_accuracy: 0.3778\n",
      "Epoch 35/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.0252 - accuracy: 0.3048 - val_loss: 1.0022 - val_accuracy: 0.3778\n",
      "Epoch 36/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 1.0221 - accuracy: 0.3048 - val_loss: 0.9997 - val_accuracy: 0.3778\n",
      "Epoch 37/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0190 - accuracy: 0.3048 - val_loss: 0.9973 - val_accuracy: 0.3778\n",
      "Epoch 38/400\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.0160 - accuracy: 0.3048 - val_loss: 0.9950 - val_accuracy: 0.3333\n",
      "Epoch 39/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0130 - accuracy: 0.2952 - val_loss: 0.9928 - val_accuracy: 0.3333\n",
      "Epoch 40/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 1.0101 - accuracy: 0.2857 - val_loss: 0.9905 - val_accuracy: 0.3111\n",
      "Epoch 41/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.0072 - accuracy: 0.2476 - val_loss: 0.9882 - val_accuracy: 0.3111\n",
      "Epoch 42/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 1.0043 - accuracy: 0.2381 - val_loss: 0.9859 - val_accuracy: 0.3333\n",
      "Epoch 43/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 1.0015 - accuracy: 0.2190 - val_loss: 0.9836 - val_accuracy: 0.2889\n",
      "Epoch 44/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9986 - accuracy: 0.2190 - val_loss: 0.9813 - val_accuracy: 0.2889\n",
      "Epoch 45/400\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.9959 - accuracy: 0.2190 - val_loss: 0.9791 - val_accuracy: 0.3333\n",
      "Epoch 46/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9931 - accuracy: 0.2000 - val_loss: 0.9768 - val_accuracy: 0.3333\n",
      "Epoch 47/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.9903 - accuracy: 0.2095 - val_loss: 0.9746 - val_accuracy: 0.3333\n",
      "Epoch 48/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.9876 - accuracy: 0.2095 - val_loss: 0.9723 - val_accuracy: 0.3556\n",
      "Epoch 49/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9849 - accuracy: 0.2190 - val_loss: 0.9701 - val_accuracy: 0.3778\n",
      "Epoch 50/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9822 - accuracy: 0.2381 - val_loss: 0.9680 - val_accuracy: 0.3556\n",
      "Epoch 51/400\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9795 - accuracy: 0.2571 - val_loss: 0.9658 - val_accuracy: 0.3556\n",
      "Epoch 52/400\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.9769 - accuracy: 0.2857 - val_loss: 0.9636 - val_accuracy: 0.3556\n",
      "Epoch 53/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.9742 - accuracy: 0.2857 - val_loss: 0.9614 - val_accuracy: 0.3778\n",
      "Epoch 54/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9717 - accuracy: 0.3048 - val_loss: 0.9593 - val_accuracy: 0.3556\n",
      "Epoch 55/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9691 - accuracy: 0.3238 - val_loss: 0.9571 - val_accuracy: 0.3556\n",
      "Epoch 56/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9665 - accuracy: 0.3524 - val_loss: 0.9549 - val_accuracy: 0.3778\n",
      "Epoch 57/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.9640 - accuracy: 0.3714 - val_loss: 0.9527 - val_accuracy: 0.4444\n",
      "Epoch 58/400\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9614 - accuracy: 0.3810 - val_loss: 0.9504 - val_accuracy: 0.4889\n",
      "Epoch 59/400\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.9588 - accuracy: 0.4190 - val_loss: 0.9482 - val_accuracy: 0.4889\n",
      "Epoch 60/400\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9563 - accuracy: 0.4190 - val_loss: 0.9461 - val_accuracy: 0.4667\n",
      "Epoch 61/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step - loss: 0.9538 - accuracy: 0.4381 - val_loss: 0.9438 - val_accuracy: 0.4667\n",
      "Epoch 62/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9512 - accuracy: 0.4476 - val_loss: 0.9416 - val_accuracy: 0.5111\n",
      "Epoch 63/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9487 - accuracy: 0.4571 - val_loss: 0.9394 - val_accuracy: 0.5111\n",
      "Epoch 64/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9462 - accuracy: 0.4952 - val_loss: 0.9371 - val_accuracy: 0.5111\n",
      "Epoch 65/400\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.9437 - accuracy: 0.5333 - val_loss: 0.9349 - val_accuracy: 0.5111\n",
      "Epoch 66/400\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.9412 - accuracy: 0.5524 - val_loss: 0.9327 - val_accuracy: 0.5111\n",
      "Epoch 67/400\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.9387 - accuracy: 0.5524 - val_loss: 0.9305 - val_accuracy: 0.5111\n",
      "Epoch 68/400\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.9362 - accuracy: 0.5524 - val_loss: 0.9283 - val_accuracy: 0.5111\n",
      "Epoch 69/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9336 - accuracy: 0.5619 - val_loss: 0.9261 - val_accuracy: 0.5111\n",
      "Epoch 70/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9311 - accuracy: 0.5714 - val_loss: 0.9239 - val_accuracy: 0.5111\n",
      "Epoch 71/400\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9286 - accuracy: 0.5714 - val_loss: 0.9217 - val_accuracy: 0.5333\n",
      "Epoch 72/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9261 - accuracy: 0.5810 - val_loss: 0.9195 - val_accuracy: 0.5333\n",
      "Epoch 73/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9235 - accuracy: 0.5810 - val_loss: 0.9173 - val_accuracy: 0.5333\n",
      "Epoch 74/400\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.9209 - accuracy: 0.6000 - val_loss: 0.9150 - val_accuracy: 0.5333\n",
      "Epoch 75/400\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9183 - accuracy: 0.6000 - val_loss: 0.9126 - val_accuracy: 0.5778\n",
      "Epoch 76/400\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.9158 - accuracy: 0.6095 - val_loss: 0.9103 - val_accuracy: 0.6000\n",
      "Epoch 77/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9132 - accuracy: 0.6095 - val_loss: 0.9080 - val_accuracy: 0.6000\n",
      "Epoch 78/400\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9106 - accuracy: 0.6190 - val_loss: 0.9056 - val_accuracy: 0.6000\n",
      "Epoch 79/400\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.9080 - accuracy: 0.6190 - val_loss: 0.9033 - val_accuracy: 0.6000\n",
      "Epoch 80/400\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.9055 - accuracy: 0.6381 - val_loss: 0.9009 - val_accuracy: 0.6000\n",
      "Epoch 81/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9029 - accuracy: 0.6381 - val_loss: 0.8986 - val_accuracy: 0.6222\n",
      "Epoch 82/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9004 - accuracy: 0.6476 - val_loss: 0.8963 - val_accuracy: 0.6222\n",
      "Epoch 83/400\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.8979 - accuracy: 0.6381 - val_loss: 0.8938 - val_accuracy: 0.6222\n",
      "Epoch 84/400\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8954 - accuracy: 0.6381 - val_loss: 0.8913 - val_accuracy: 0.6222\n",
      "Epoch 85/400\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.8929 - accuracy: 0.6381 - val_loss: 0.8889 - val_accuracy: 0.6222\n",
      "Epoch 86/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8904 - accuracy: 0.6381 - val_loss: 0.8865 - val_accuracy: 0.6222\n",
      "Epoch 87/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8880 - accuracy: 0.6381 - val_loss: 0.8844 - val_accuracy: 0.6222\n",
      "Epoch 88/400\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8856 - accuracy: 0.6381 - val_loss: 0.8823 - val_accuracy: 0.6222\n",
      "Epoch 89/400\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8833 - accuracy: 0.6381 - val_loss: 0.8803 - val_accuracy: 0.6222\n",
      "Epoch 90/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.8810 - accuracy: 0.6476 - val_loss: 0.8782 - val_accuracy: 0.6222\n",
      "Epoch 91/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8788 - accuracy: 0.6476 - val_loss: 0.8762 - val_accuracy: 0.6222\n",
      "Epoch 92/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8766 - accuracy: 0.6476 - val_loss: 0.8743 - val_accuracy: 0.6222\n",
      "Epoch 93/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8745 - accuracy: 0.6571 - val_loss: 0.8723 - val_accuracy: 0.6222\n",
      "Epoch 94/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8724 - accuracy: 0.6571 - val_loss: 0.8704 - val_accuracy: 0.6222\n",
      "Epoch 95/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8703 - accuracy: 0.6571 - val_loss: 0.8685 - val_accuracy: 0.6222\n",
      "Epoch 96/400\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8682 - accuracy: 0.6571 - val_loss: 0.8666 - val_accuracy: 0.6222\n",
      "Epoch 97/400\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8662 - accuracy: 0.6571 - val_loss: 0.8648 - val_accuracy: 0.6222\n",
      "Epoch 98/400\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8641 - accuracy: 0.6571 - val_loss: 0.8630 - val_accuracy: 0.6222\n",
      "Epoch 99/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8621 - accuracy: 0.6667 - val_loss: 0.8611 - val_accuracy: 0.6222\n",
      "Epoch 100/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8601 - accuracy: 0.6667 - val_loss: 0.8594 - val_accuracy: 0.6222\n",
      "Epoch 101/400\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.8581 - accuracy: 0.6667 - val_loss: 0.8576 - val_accuracy: 0.6222\n",
      "Epoch 102/400\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.8562 - accuracy: 0.6667 - val_loss: 0.8558 - val_accuracy: 0.6222\n",
      "Epoch 103/400\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8542 - accuracy: 0.6667 - val_loss: 0.8540 - val_accuracy: 0.6222\n",
      "Epoch 104/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.8522 - accuracy: 0.6667 - val_loss: 0.8523 - val_accuracy: 0.6222\n",
      "Epoch 105/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8503 - accuracy: 0.6667 - val_loss: 0.8505 - val_accuracy: 0.6222\n",
      "Epoch 106/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8483 - accuracy: 0.6667 - val_loss: 0.8488 - val_accuracy: 0.6222\n",
      "Epoch 107/400\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.8464 - accuracy: 0.6667 - val_loss: 0.8470 - val_accuracy: 0.6222\n",
      "Epoch 108/400\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.8444 - accuracy: 0.6667 - val_loss: 0.8453 - val_accuracy: 0.6222\n",
      "Epoch 109/400\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8425 - accuracy: 0.6667 - val_loss: 0.8436 - val_accuracy: 0.6222\n",
      "Epoch 110/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.8406 - accuracy: 0.6667 - val_loss: 0.8419 - val_accuracy: 0.6222\n",
      "Epoch 111/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8387 - accuracy: 0.6667 - val_loss: 0.8401 - val_accuracy: 0.6222\n",
      "Epoch 112/400\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8367 - accuracy: 0.6667 - val_loss: 0.8384 - val_accuracy: 0.6222\n",
      "Epoch 113/400\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.8348 - accuracy: 0.6667 - val_loss: 0.8367 - val_accuracy: 0.6222\n",
      "Epoch 114/400\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.8329 - accuracy: 0.6667 - val_loss: 0.8350 - val_accuracy: 0.6222\n",
      "Epoch 115/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8310 - accuracy: 0.6667 - val_loss: 0.8333 - val_accuracy: 0.6222\n",
      "Epoch 116/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.8291 - accuracy: 0.6667 - val_loss: 0.8316 - val_accuracy: 0.6222\n",
      "Epoch 117/400\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.8272 - accuracy: 0.6667 - val_loss: 0.8299 - val_accuracy: 0.6222\n",
      "Epoch 118/400\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8253 - accuracy: 0.6667 - val_loss: 0.8282 - val_accuracy: 0.6222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/400\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.8233 - accuracy: 0.6667 - val_loss: 0.8265 - val_accuracy: 0.6222\n",
      "Epoch 120/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8214 - accuracy: 0.6762 - val_loss: 0.8248 - val_accuracy: 0.6222\n",
      "Epoch 121/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8195 - accuracy: 0.6762 - val_loss: 0.8231 - val_accuracy: 0.6222\n",
      "Epoch 122/400\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8176 - accuracy: 0.6762 - val_loss: 0.8213 - val_accuracy: 0.6222\n",
      "Epoch 123/400\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8157 - accuracy: 0.6762 - val_loss: 0.8196 - val_accuracy: 0.6222\n",
      "Epoch 124/400\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.8138 - accuracy: 0.6762 - val_loss: 0.8179 - val_accuracy: 0.6222\n",
      "Epoch 125/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.8118 - accuracy: 0.6762 - val_loss: 0.8162 - val_accuracy: 0.6222\n",
      "Epoch 126/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8099 - accuracy: 0.6762 - val_loss: 0.8145 - val_accuracy: 0.6222\n",
      "Epoch 127/400\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.8080 - accuracy: 0.6762 - val_loss: 0.8128 - val_accuracy: 0.6222\n",
      "Epoch 128/400\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.8061 - accuracy: 0.6762 - val_loss: 0.8110 - val_accuracy: 0.6222\n",
      "Epoch 129/400\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.8042 - accuracy: 0.6762 - val_loss: 0.8093 - val_accuracy: 0.6222\n",
      "Epoch 130/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8023 - accuracy: 0.6762 - val_loss: 0.8076 - val_accuracy: 0.6222\n",
      "Epoch 131/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8004 - accuracy: 0.6762 - val_loss: 0.8059 - val_accuracy: 0.6222\n",
      "Epoch 132/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7985 - accuracy: 0.6762 - val_loss: 0.8041 - val_accuracy: 0.6444\n",
      "Epoch 133/400\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7966 - accuracy: 0.6762 - val_loss: 0.8023 - val_accuracy: 0.6444\n",
      "Epoch 134/400\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7947 - accuracy: 0.6762 - val_loss: 0.8006 - val_accuracy: 0.6444\n",
      "Epoch 135/400\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.7928 - accuracy: 0.6762 - val_loss: 0.7988 - val_accuracy: 0.6444\n",
      "Epoch 136/400\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7908 - accuracy: 0.6762 - val_loss: 0.7970 - val_accuracy: 0.6444\n",
      "Epoch 137/400\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7889 - accuracy: 0.6857 - val_loss: 0.7952 - val_accuracy: 0.6444\n",
      "Epoch 138/400\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7870 - accuracy: 0.6857 - val_loss: 0.7935 - val_accuracy: 0.6444\n",
      "Epoch 139/400\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7850 - accuracy: 0.6857 - val_loss: 0.7916 - val_accuracy: 0.6444\n",
      "Epoch 140/400\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.7831 - accuracy: 0.6857 - val_loss: 0.7898 - val_accuracy: 0.6444\n",
      "Epoch 141/400\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7811 - accuracy: 0.6857 - val_loss: 0.7880 - val_accuracy: 0.6444\n",
      "Epoch 142/400\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7792 - accuracy: 0.6857 - val_loss: 0.7861 - val_accuracy: 0.6444\n",
      "Epoch 143/400\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7772 - accuracy: 0.6857 - val_loss: 0.7843 - val_accuracy: 0.6444\n",
      "Epoch 144/400\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7752 - accuracy: 0.6857 - val_loss: 0.7824 - val_accuracy: 0.6444\n",
      "Epoch 145/400\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7732 - accuracy: 0.6857 - val_loss: 0.7805 - val_accuracy: 0.6444\n",
      "Epoch 146/400\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.7713 - accuracy: 0.6857 - val_loss: 0.7787 - val_accuracy: 0.6444\n",
      "Epoch 147/400\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.7693 - accuracy: 0.6857 - val_loss: 0.7768 - val_accuracy: 0.6444\n",
      "Epoch 148/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7673 - accuracy: 0.6857 - val_loss: 0.7749 - val_accuracy: 0.6444\n",
      "Epoch 149/400\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.7653 - accuracy: 0.6857 - val_loss: 0.7730 - val_accuracy: 0.6444\n",
      "Epoch 150/400\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.7633 - accuracy: 0.6857 - val_loss: 0.7711 - val_accuracy: 0.6444\n",
      "Epoch 151/400\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7612 - accuracy: 0.6857 - val_loss: 0.7692 - val_accuracy: 0.6444\n",
      "Epoch 152/400\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7592 - accuracy: 0.6857 - val_loss: 0.7673 - val_accuracy: 0.6444\n",
      "Epoch 153/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7572 - accuracy: 0.6857 - val_loss: 0.7654 - val_accuracy: 0.6444\n",
      "Epoch 154/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7551 - accuracy: 0.6857 - val_loss: 0.7635 - val_accuracy: 0.6444\n",
      "Epoch 155/400\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.7531 - accuracy: 0.6857 - val_loss: 0.7616 - val_accuracy: 0.6444\n",
      "Epoch 156/400\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7510 - accuracy: 0.6857 - val_loss: 0.7597 - val_accuracy: 0.6444\n",
      "Epoch 157/400\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7490 - accuracy: 0.6857 - val_loss: 0.7578 - val_accuracy: 0.6444\n",
      "Epoch 158/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7469 - accuracy: 0.6857 - val_loss: 0.7559 - val_accuracy: 0.6444\n",
      "Epoch 159/400\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.7448 - accuracy: 0.6857 - val_loss: 0.7540 - val_accuracy: 0.6444\n",
      "Epoch 160/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7427 - accuracy: 0.6952 - val_loss: 0.7521 - val_accuracy: 0.6444\n",
      "Epoch 161/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7406 - accuracy: 0.6952 - val_loss: 0.7501 - val_accuracy: 0.6444\n",
      "Epoch 162/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.7385 - accuracy: 0.6952 - val_loss: 0.7482 - val_accuracy: 0.6444\n",
      "Epoch 163/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.7364 - accuracy: 0.7048 - val_loss: 0.7463 - val_accuracy: 0.6444\n",
      "Epoch 164/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7342 - accuracy: 0.7048 - val_loss: 0.7443 - val_accuracy: 0.6444\n",
      "Epoch 165/400\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.7321 - accuracy: 0.7048 - val_loss: 0.7424 - val_accuracy: 0.6444\n",
      "Epoch 166/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7299 - accuracy: 0.7048 - val_loss: 0.7404 - val_accuracy: 0.6444\n",
      "Epoch 167/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7278 - accuracy: 0.7048 - val_loss: 0.7384 - val_accuracy: 0.6444\n",
      "Epoch 168/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7256 - accuracy: 0.7048 - val_loss: 0.7365 - val_accuracy: 0.6444\n",
      "Epoch 169/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7234 - accuracy: 0.7048 - val_loss: 0.7345 - val_accuracy: 0.6444\n",
      "Epoch 170/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7212 - accuracy: 0.7048 - val_loss: 0.7325 - val_accuracy: 0.6444\n",
      "Epoch 171/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7190 - accuracy: 0.7048 - val_loss: 0.7305 - val_accuracy: 0.6444\n",
      "Epoch 172/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7168 - accuracy: 0.7048 - val_loss: 0.7285 - val_accuracy: 0.6444\n",
      "Epoch 173/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7146 - accuracy: 0.7048 - val_loss: 0.7265 - val_accuracy: 0.6444\n",
      "Epoch 174/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7124 - accuracy: 0.7048 - val_loss: 0.7244 - val_accuracy: 0.6444\n",
      "Epoch 175/400\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7101 - accuracy: 0.7048 - val_loss: 0.7224 - val_accuracy: 0.6444\n",
      "Epoch 176/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step - loss: 0.7078 - accuracy: 0.7048 - val_loss: 0.7204 - val_accuracy: 0.6444\n",
      "Epoch 177/400\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.7056 - accuracy: 0.7048 - val_loss: 0.7183 - val_accuracy: 0.6444\n",
      "Epoch 178/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7033 - accuracy: 0.7048 - val_loss: 0.7162 - val_accuracy: 0.6444\n",
      "Epoch 179/400\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.7010 - accuracy: 0.7048 - val_loss: 0.7141 - val_accuracy: 0.6444\n",
      "Epoch 180/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6987 - accuracy: 0.7048 - val_loss: 0.7120 - val_accuracy: 0.6444\n",
      "Epoch 181/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6964 - accuracy: 0.7048 - val_loss: 0.7099 - val_accuracy: 0.6444\n",
      "Epoch 182/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6941 - accuracy: 0.7048 - val_loss: 0.7078 - val_accuracy: 0.6444\n",
      "Epoch 183/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6918 - accuracy: 0.7048 - val_loss: 0.7056 - val_accuracy: 0.6444\n",
      "Epoch 184/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6895 - accuracy: 0.7048 - val_loss: 0.7035 - val_accuracy: 0.6444\n",
      "Epoch 185/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6871 - accuracy: 0.7048 - val_loss: 0.7013 - val_accuracy: 0.6444\n",
      "Epoch 186/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6848 - accuracy: 0.7048 - val_loss: 0.6992 - val_accuracy: 0.6444\n",
      "Epoch 187/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6824 - accuracy: 0.7143 - val_loss: 0.6970 - val_accuracy: 0.6444\n",
      "Epoch 188/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6801 - accuracy: 0.7143 - val_loss: 0.6948 - val_accuracy: 0.6444\n",
      "Epoch 189/400\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6777 - accuracy: 0.7143 - val_loss: 0.6927 - val_accuracy: 0.6444\n",
      "Epoch 190/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6753 - accuracy: 0.7143 - val_loss: 0.6905 - val_accuracy: 0.6444\n",
      "Epoch 191/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6729 - accuracy: 0.7143 - val_loss: 0.6883 - val_accuracy: 0.6444\n",
      "Epoch 192/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6705 - accuracy: 0.7143 - val_loss: 0.6861 - val_accuracy: 0.6444\n",
      "Epoch 193/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6681 - accuracy: 0.7143 - val_loss: 0.6839 - val_accuracy: 0.6444\n",
      "Epoch 194/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6657 - accuracy: 0.7143 - val_loss: 0.6818 - val_accuracy: 0.6444\n",
      "Epoch 195/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6633 - accuracy: 0.7143 - val_loss: 0.6796 - val_accuracy: 0.6444\n",
      "Epoch 196/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6608 - accuracy: 0.7143 - val_loss: 0.6774 - val_accuracy: 0.6444\n",
      "Epoch 197/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6584 - accuracy: 0.7143 - val_loss: 0.6752 - val_accuracy: 0.6444\n",
      "Epoch 198/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6560 - accuracy: 0.7143 - val_loss: 0.6730 - val_accuracy: 0.6444\n",
      "Epoch 199/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6535 - accuracy: 0.7143 - val_loss: 0.6708 - val_accuracy: 0.6444\n",
      "Epoch 200/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6511 - accuracy: 0.7143 - val_loss: 0.6685 - val_accuracy: 0.6444\n",
      "Epoch 201/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6486 - accuracy: 0.7143 - val_loss: 0.6663 - val_accuracy: 0.6444\n",
      "Epoch 202/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6461 - accuracy: 0.7143 - val_loss: 0.6641 - val_accuracy: 0.6444\n",
      "Epoch 203/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6437 - accuracy: 0.7143 - val_loss: 0.6619 - val_accuracy: 0.6444\n",
      "Epoch 204/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6412 - accuracy: 0.7143 - val_loss: 0.6596 - val_accuracy: 0.6444\n",
      "Epoch 205/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6387 - accuracy: 0.7143 - val_loss: 0.6573 - val_accuracy: 0.6444\n",
      "Epoch 206/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6362 - accuracy: 0.7143 - val_loss: 0.6550 - val_accuracy: 0.6444\n",
      "Epoch 207/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6337 - accuracy: 0.7238 - val_loss: 0.6527 - val_accuracy: 0.6444\n",
      "Epoch 208/400\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.6312 - accuracy: 0.7238 - val_loss: 0.6504 - val_accuracy: 0.6444\n",
      "Epoch 209/400\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.6287 - accuracy: 0.7238 - val_loss: 0.6480 - val_accuracy: 0.6444\n",
      "Epoch 210/400\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.6262 - accuracy: 0.7238 - val_loss: 0.6457 - val_accuracy: 0.6444\n",
      "Epoch 211/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6237 - accuracy: 0.7238 - val_loss: 0.6433 - val_accuracy: 0.6444\n",
      "Epoch 212/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6212 - accuracy: 0.7238 - val_loss: 0.6409 - val_accuracy: 0.6444\n",
      "Epoch 213/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6187 - accuracy: 0.7238 - val_loss: 0.6386 - val_accuracy: 0.6444\n",
      "Epoch 214/400\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6162 - accuracy: 0.7238 - val_loss: 0.6362 - val_accuracy: 0.6444\n",
      "Epoch 215/400\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.6136 - accuracy: 0.7238 - val_loss: 0.6338 - val_accuracy: 0.6444\n",
      "Epoch 216/400\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.6111 - accuracy: 0.7238 - val_loss: 0.6314 - val_accuracy: 0.6667\n",
      "Epoch 217/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6086 - accuracy: 0.7238 - val_loss: 0.6291 - val_accuracy: 0.6667\n",
      "Epoch 218/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6060 - accuracy: 0.7333 - val_loss: 0.6267 - val_accuracy: 0.6667\n",
      "Epoch 219/400\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.6035 - accuracy: 0.7333 - val_loss: 0.6244 - val_accuracy: 0.6667\n",
      "Epoch 220/400\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.6010 - accuracy: 0.7333 - val_loss: 0.6220 - val_accuracy: 0.6667\n",
      "Epoch 221/400\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.5984 - accuracy: 0.7333 - val_loss: 0.6196 - val_accuracy: 0.6667\n",
      "Epoch 222/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5959 - accuracy: 0.7333 - val_loss: 0.6173 - val_accuracy: 0.6667\n",
      "Epoch 223/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5934 - accuracy: 0.7333 - val_loss: 0.6150 - val_accuracy: 0.6667\n",
      "Epoch 224/400\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.5908 - accuracy: 0.7429 - val_loss: 0.6126 - val_accuracy: 0.6667\n",
      "Epoch 225/400\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5883 - accuracy: 0.7429 - val_loss: 0.6103 - val_accuracy: 0.6667\n",
      "Epoch 226/400\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.5857 - accuracy: 0.7429 - val_loss: 0.6079 - val_accuracy: 0.6667\n",
      "Epoch 227/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5832 - accuracy: 0.7524 - val_loss: 0.6056 - val_accuracy: 0.6667\n",
      "Epoch 228/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5807 - accuracy: 0.7524 - val_loss: 0.6033 - val_accuracy: 0.6667\n",
      "Epoch 229/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5781 - accuracy: 0.7524 - val_loss: 0.6009 - val_accuracy: 0.6667\n",
      "Epoch 230/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5756 - accuracy: 0.7524 - val_loss: 0.5986 - val_accuracy: 0.6667\n",
      "Epoch 231/400\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5731 - accuracy: 0.7524 - val_loss: 0.5963 - val_accuracy: 0.6667\n",
      "Epoch 232/400\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.5706 - accuracy: 0.7524 - val_loss: 0.5939 - val_accuracy: 0.6667\n",
      "Epoch 233/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5681 - accuracy: 0.7524 - val_loss: 0.5916 - val_accuracy: 0.6889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5656 - accuracy: 0.7524 - val_loss: 0.5893 - val_accuracy: 0.6889\n",
      "Epoch 235/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5631 - accuracy: 0.7524 - val_loss: 0.5869 - val_accuracy: 0.6889\n",
      "Epoch 236/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5606 - accuracy: 0.7524 - val_loss: 0.5846 - val_accuracy: 0.6889\n",
      "Epoch 237/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5581 - accuracy: 0.7524 - val_loss: 0.5822 - val_accuracy: 0.6889\n",
      "Epoch 238/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5557 - accuracy: 0.7524 - val_loss: 0.5799 - val_accuracy: 0.7111\n",
      "Epoch 239/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5532 - accuracy: 0.7524 - val_loss: 0.5775 - val_accuracy: 0.7111\n",
      "Epoch 240/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5508 - accuracy: 0.7524 - val_loss: 0.5752 - val_accuracy: 0.7111\n",
      "Epoch 241/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5483 - accuracy: 0.7524 - val_loss: 0.5728 - val_accuracy: 0.7111\n",
      "Epoch 242/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5459 - accuracy: 0.7524 - val_loss: 0.5704 - val_accuracy: 0.7111\n",
      "Epoch 243/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5434 - accuracy: 0.7524 - val_loss: 0.5681 - val_accuracy: 0.7111\n",
      "Epoch 244/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5410 - accuracy: 0.7524 - val_loss: 0.5657 - val_accuracy: 0.7111\n",
      "Epoch 245/400\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.5386 - accuracy: 0.7714 - val_loss: 0.5633 - val_accuracy: 0.7333\n",
      "Epoch 246/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5362 - accuracy: 0.7714 - val_loss: 0.5610 - val_accuracy: 0.7333\n",
      "Epoch 247/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5338 - accuracy: 0.7714 - val_loss: 0.5586 - val_accuracy: 0.7333\n",
      "Epoch 248/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5314 - accuracy: 0.7810 - val_loss: 0.5563 - val_accuracy: 0.7333\n",
      "Epoch 249/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5290 - accuracy: 0.7810 - val_loss: 0.5540 - val_accuracy: 0.7333\n",
      "Epoch 250/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5266 - accuracy: 0.7810 - val_loss: 0.5517 - val_accuracy: 0.7333\n",
      "Epoch 251/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5242 - accuracy: 0.7905 - val_loss: 0.5493 - val_accuracy: 0.7333\n",
      "Epoch 252/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5218 - accuracy: 0.8000 - val_loss: 0.5470 - val_accuracy: 0.7333\n",
      "Epoch 253/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5195 - accuracy: 0.8000 - val_loss: 0.5448 - val_accuracy: 0.7333\n",
      "Epoch 254/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5171 - accuracy: 0.8000 - val_loss: 0.5425 - val_accuracy: 0.7333\n",
      "Epoch 255/400\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.5148 - accuracy: 0.8190 - val_loss: 0.5402 - val_accuracy: 0.7333\n",
      "Epoch 256/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5125 - accuracy: 0.8286 - val_loss: 0.5379 - val_accuracy: 0.7333\n",
      "Epoch 257/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5101 - accuracy: 0.8286 - val_loss: 0.5357 - val_accuracy: 0.7333\n",
      "Epoch 258/400\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.5078 - accuracy: 0.8286 - val_loss: 0.5334 - val_accuracy: 0.7333\n",
      "Epoch 259/400\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5055 - accuracy: 0.8286 - val_loss: 0.5312 - val_accuracy: 0.7333\n",
      "Epoch 260/400\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.5032 - accuracy: 0.8381 - val_loss: 0.5289 - val_accuracy: 0.7333\n",
      "Epoch 261/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5010 - accuracy: 0.8381 - val_loss: 0.5267 - val_accuracy: 0.7333\n",
      "Epoch 262/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4987 - accuracy: 0.8381 - val_loss: 0.5245 - val_accuracy: 0.7556\n",
      "Epoch 263/400\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4964 - accuracy: 0.8476 - val_loss: 0.5222 - val_accuracy: 0.7556\n",
      "Epoch 264/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4942 - accuracy: 0.8476 - val_loss: 0.5200 - val_accuracy: 0.7778\n",
      "Epoch 265/400\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4919 - accuracy: 0.8476 - val_loss: 0.5178 - val_accuracy: 0.7778\n",
      "Epoch 266/400\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4897 - accuracy: 0.8476 - val_loss: 0.5156 - val_accuracy: 0.7778\n",
      "Epoch 267/400\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4875 - accuracy: 0.8476 - val_loss: 0.5133 - val_accuracy: 0.7778\n",
      "Epoch 268/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4852 - accuracy: 0.8476 - val_loss: 0.5111 - val_accuracy: 0.7778\n",
      "Epoch 269/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4830 - accuracy: 0.8476 - val_loss: 0.5089 - val_accuracy: 0.7778\n",
      "Epoch 270/400\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.4808 - accuracy: 0.8476 - val_loss: 0.5067 - val_accuracy: 0.7778\n",
      "Epoch 271/400\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4786 - accuracy: 0.8476 - val_loss: 0.5045 - val_accuracy: 0.7778\n",
      "Epoch 272/400\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.4765 - accuracy: 0.8476 - val_loss: 0.5023 - val_accuracy: 0.7778\n",
      "Epoch 273/400\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4743 - accuracy: 0.8476 - val_loss: 0.5001 - val_accuracy: 0.7778\n",
      "Epoch 274/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.4721 - accuracy: 0.8476 - val_loss: 0.4979 - val_accuracy: 0.7778\n",
      "Epoch 275/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4700 - accuracy: 0.8476 - val_loss: 0.4957 - val_accuracy: 0.7778\n",
      "Epoch 276/400\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.4678 - accuracy: 0.8476 - val_loss: 0.4936 - val_accuracy: 0.7778\n",
      "Epoch 277/400\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4657 - accuracy: 0.8476 - val_loss: 0.4914 - val_accuracy: 0.8000\n",
      "Epoch 278/400\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4636 - accuracy: 0.8476 - val_loss: 0.4893 - val_accuracy: 0.8000\n",
      "Epoch 279/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4615 - accuracy: 0.8476 - val_loss: 0.4871 - val_accuracy: 0.8000\n",
      "Epoch 280/400\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4594 - accuracy: 0.8571 - val_loss: 0.4850 - val_accuracy: 0.8000\n",
      "Epoch 281/400\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.4573 - accuracy: 0.8571 - val_loss: 0.4828 - val_accuracy: 0.8000\n",
      "Epoch 282/400\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4552 - accuracy: 0.8571 - val_loss: 0.4807 - val_accuracy: 0.8000\n",
      "Epoch 283/400\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.4531 - accuracy: 0.8571 - val_loss: 0.4786 - val_accuracy: 0.8000\n",
      "Epoch 284/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4510 - accuracy: 0.8571 - val_loss: 0.4765 - val_accuracy: 0.8000\n",
      "Epoch 285/400\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.4490 - accuracy: 0.8571 - val_loss: 0.4744 - val_accuracy: 0.8000\n",
      "Epoch 286/400\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4469 - accuracy: 0.8667 - val_loss: 0.4723 - val_accuracy: 0.8000\n",
      "Epoch 287/400\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4449 - accuracy: 0.8667 - val_loss: 0.4702 - val_accuracy: 0.8000\n",
      "Epoch 288/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4429 - accuracy: 0.8667 - val_loss: 0.4681 - val_accuracy: 0.8222\n",
      "Epoch 289/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4409 - accuracy: 0.8667 - val_loss: 0.4660 - val_accuracy: 0.8444\n",
      "Epoch 290/400\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4388 - accuracy: 0.8667 - val_loss: 0.4640 - val_accuracy: 0.8444\n",
      "Epoch 291/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step - loss: 0.4368 - accuracy: 0.8667 - val_loss: 0.4619 - val_accuracy: 0.8444\n",
      "Epoch 292/400\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4348 - accuracy: 0.8667 - val_loss: 0.4598 - val_accuracy: 0.8444\n",
      "Epoch 293/400\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4328 - accuracy: 0.8667 - val_loss: 0.4578 - val_accuracy: 0.8444\n",
      "Epoch 294/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4309 - accuracy: 0.8667 - val_loss: 0.4557 - val_accuracy: 0.8444\n",
      "Epoch 295/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4289 - accuracy: 0.8667 - val_loss: 0.4537 - val_accuracy: 0.8444\n",
      "Epoch 296/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4269 - accuracy: 0.8667 - val_loss: 0.4517 - val_accuracy: 0.8444\n",
      "Epoch 297/400\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.4250 - accuracy: 0.8667 - val_loss: 0.4496 - val_accuracy: 0.8444\n",
      "Epoch 298/400\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4230 - accuracy: 0.8667 - val_loss: 0.4476 - val_accuracy: 0.8667\n",
      "Epoch 299/400\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.4211 - accuracy: 0.8762 - val_loss: 0.4456 - val_accuracy: 0.8889\n",
      "Epoch 300/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4191 - accuracy: 0.8762 - val_loss: 0.4436 - val_accuracy: 0.8889\n",
      "Epoch 301/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4172 - accuracy: 0.8762 - val_loss: 0.4416 - val_accuracy: 0.8889\n",
      "Epoch 302/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4153 - accuracy: 0.8762 - val_loss: 0.4397 - val_accuracy: 0.8889\n",
      "Epoch 303/400\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.4133 - accuracy: 0.8762 - val_loss: 0.4377 - val_accuracy: 0.8889\n",
      "Epoch 304/400\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4114 - accuracy: 0.8762 - val_loss: 0.4357 - val_accuracy: 0.8889\n",
      "Epoch 305/400\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4095 - accuracy: 0.8762 - val_loss: 0.4338 - val_accuracy: 0.8889\n",
      "Epoch 306/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4076 - accuracy: 0.8762 - val_loss: 0.4319 - val_accuracy: 0.8889\n",
      "Epoch 307/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.4057 - accuracy: 0.8762 - val_loss: 0.4299 - val_accuracy: 0.8889\n",
      "Epoch 308/400\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4039 - accuracy: 0.8762 - val_loss: 0.4280 - val_accuracy: 0.8889\n",
      "Epoch 309/400\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.4020 - accuracy: 0.8762 - val_loss: 0.4261 - val_accuracy: 0.8889\n",
      "Epoch 310/400\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4001 - accuracy: 0.8762 - val_loss: 0.4242 - val_accuracy: 0.8889\n",
      "Epoch 311/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3982 - accuracy: 0.8762 - val_loss: 0.4223 - val_accuracy: 0.8889\n",
      "Epoch 312/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3964 - accuracy: 0.8857 - val_loss: 0.4204 - val_accuracy: 0.8889\n",
      "Epoch 313/400\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3945 - accuracy: 0.8857 - val_loss: 0.4184 - val_accuracy: 0.8889\n",
      "Epoch 314/400\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.3927 - accuracy: 0.8952 - val_loss: 0.4164 - val_accuracy: 0.8889\n",
      "Epoch 315/400\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.3908 - accuracy: 0.8952 - val_loss: 0.4144 - val_accuracy: 0.8889\n",
      "Epoch 316/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3890 - accuracy: 0.9143 - val_loss: 0.4124 - val_accuracy: 0.9111\n",
      "Epoch 317/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3871 - accuracy: 0.9143 - val_loss: 0.4104 - val_accuracy: 0.9111\n",
      "Epoch 318/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3853 - accuracy: 0.9238 - val_loss: 0.4084 - val_accuracy: 0.9111\n",
      "Epoch 319/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3835 - accuracy: 0.9238 - val_loss: 0.4064 - val_accuracy: 0.9111\n",
      "Epoch 320/400\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3817 - accuracy: 0.9238 - val_loss: 0.4045 - val_accuracy: 0.9111\n",
      "Epoch 321/400\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.3798 - accuracy: 0.9238 - val_loss: 0.4027 - val_accuracy: 0.9111\n",
      "Epoch 322/400\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3780 - accuracy: 0.9238 - val_loss: 0.4009 - val_accuracy: 0.9333\n",
      "Epoch 323/400\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.3762 - accuracy: 0.9238 - val_loss: 0.3991 - val_accuracy: 0.9333\n",
      "Epoch 324/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3744 - accuracy: 0.9238 - val_loss: 0.3973 - val_accuracy: 0.9333\n",
      "Epoch 325/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3726 - accuracy: 0.9238 - val_loss: 0.3955 - val_accuracy: 0.9333\n",
      "Epoch 326/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3708 - accuracy: 0.9238 - val_loss: 0.3937 - val_accuracy: 0.9333\n",
      "Epoch 327/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3690 - accuracy: 0.9238 - val_loss: 0.3919 - val_accuracy: 0.9333\n",
      "Epoch 328/400\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.3672 - accuracy: 0.9238 - val_loss: 0.3901 - val_accuracy: 0.9333\n",
      "Epoch 329/400\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.3654 - accuracy: 0.9238 - val_loss: 0.3882 - val_accuracy: 0.9333\n",
      "Epoch 330/400\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3637 - accuracy: 0.9333 - val_loss: 0.3863 - val_accuracy: 0.9333\n",
      "Epoch 331/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3619 - accuracy: 0.9333 - val_loss: 0.3844 - val_accuracy: 0.9333\n",
      "Epoch 332/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3601 - accuracy: 0.9333 - val_loss: 0.3825 - val_accuracy: 0.9333\n",
      "Epoch 333/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3584 - accuracy: 0.9333 - val_loss: 0.3806 - val_accuracy: 0.9333\n",
      "Epoch 334/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3566 - accuracy: 0.9333 - val_loss: 0.3788 - val_accuracy: 0.9333\n",
      "Epoch 335/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3548 - accuracy: 0.9333 - val_loss: 0.3769 - val_accuracy: 0.9333\n",
      "Epoch 336/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3531 - accuracy: 0.9333 - val_loss: 0.3750 - val_accuracy: 0.9333\n",
      "Epoch 337/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3513 - accuracy: 0.9333 - val_loss: 0.3732 - val_accuracy: 0.9333\n",
      "Epoch 338/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3496 - accuracy: 0.9333 - val_loss: 0.3713 - val_accuracy: 0.9333\n",
      "Epoch 339/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3478 - accuracy: 0.9333 - val_loss: 0.3695 - val_accuracy: 0.9333\n",
      "Epoch 340/400\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.3461 - accuracy: 0.9333 - val_loss: 0.3677 - val_accuracy: 0.9333\n",
      "Epoch 341/400\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3443 - accuracy: 0.9429 - val_loss: 0.3659 - val_accuracy: 0.9333\n",
      "Epoch 342/400\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.3426 - accuracy: 0.9429 - val_loss: 0.3641 - val_accuracy: 0.9333\n",
      "Epoch 343/400\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3408 - accuracy: 0.9429 - val_loss: 0.3623 - val_accuracy: 0.9333\n",
      "Epoch 344/400\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3391 - accuracy: 0.9429 - val_loss: 0.3605 - val_accuracy: 0.9333\n",
      "Epoch 345/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3373 - accuracy: 0.9429 - val_loss: 0.3587 - val_accuracy: 0.9333\n",
      "Epoch 346/400\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.3356 - accuracy: 0.9429 - val_loss: 0.3569 - val_accuracy: 0.9333\n",
      "Epoch 347/400\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.3339 - accuracy: 0.9429 - val_loss: 0.3550 - val_accuracy: 0.9333\n",
      "Epoch 348/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 117ms/step - loss: 0.3321 - accuracy: 0.9429 - val_loss: 0.3532 - val_accuracy: 0.9333\n",
      "Epoch 349/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3304 - accuracy: 0.9429 - val_loss: 0.3513 - val_accuracy: 0.9333\n",
      "Epoch 350/400\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3287 - accuracy: 0.9429 - val_loss: 0.3494 - val_accuracy: 0.9333\n",
      "Epoch 351/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3269 - accuracy: 0.9429 - val_loss: 0.3476 - val_accuracy: 0.9333\n",
      "Epoch 352/400\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3252 - accuracy: 0.9429 - val_loss: 0.3457 - val_accuracy: 0.9333\n",
      "Epoch 353/400\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3235 - accuracy: 0.9429 - val_loss: 0.3439 - val_accuracy: 0.9333\n",
      "Epoch 354/400\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.3219 - accuracy: 0.9429 - val_loss: 0.3421 - val_accuracy: 0.9333\n",
      "Epoch 355/400\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.3202 - accuracy: 0.9429 - val_loss: 0.3403 - val_accuracy: 0.9333\n",
      "Epoch 356/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3185 - accuracy: 0.9524 - val_loss: 0.3386 - val_accuracy: 0.9333\n",
      "Epoch 357/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3169 - accuracy: 0.9524 - val_loss: 0.3368 - val_accuracy: 0.9333\n",
      "Epoch 358/400\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.3153 - accuracy: 0.9524 - val_loss: 0.3351 - val_accuracy: 0.9333\n",
      "Epoch 359/400\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.3136 - accuracy: 0.9524 - val_loss: 0.3334 - val_accuracy: 0.9556\n",
      "Epoch 360/400\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3120 - accuracy: 0.9524 - val_loss: 0.3317 - val_accuracy: 0.9556\n",
      "Epoch 361/400\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3104 - accuracy: 0.9524 - val_loss: 0.3300 - val_accuracy: 0.9556\n",
      "Epoch 362/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3088 - accuracy: 0.9524 - val_loss: 0.3283 - val_accuracy: 0.9556\n",
      "Epoch 363/400\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.3072 - accuracy: 0.9524 - val_loss: 0.3267 - val_accuracy: 0.9556\n",
      "Epoch 364/400\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.3056 - accuracy: 0.9524 - val_loss: 0.3250 - val_accuracy: 0.9556\n",
      "Epoch 365/400\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.3040 - accuracy: 0.9619 - val_loss: 0.3233 - val_accuracy: 0.9556\n",
      "Epoch 366/400\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3025 - accuracy: 0.9619 - val_loss: 0.3216 - val_accuracy: 0.9556\n",
      "Epoch 367/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3009 - accuracy: 0.9619 - val_loss: 0.3199 - val_accuracy: 0.9556\n",
      "Epoch 368/400\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2993 - accuracy: 0.9619 - val_loss: 0.3183 - val_accuracy: 0.9556\n",
      "Epoch 369/400\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.2978 - accuracy: 0.9619 - val_loss: 0.3167 - val_accuracy: 0.9556\n",
      "Epoch 370/400\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.2962 - accuracy: 0.9619 - val_loss: 0.3151 - val_accuracy: 0.9556\n",
      "Epoch 371/400\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2947 - accuracy: 0.9619 - val_loss: 0.3135 - val_accuracy: 0.9556\n",
      "Epoch 372/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2931 - accuracy: 0.9619 - val_loss: 0.3119 - val_accuracy: 0.9556\n",
      "Epoch 373/400\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2916 - accuracy: 0.9619 - val_loss: 0.3103 - val_accuracy: 0.9556\n",
      "Epoch 374/400\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2900 - accuracy: 0.9619 - val_loss: 0.3088 - val_accuracy: 0.9556\n",
      "Epoch 375/400\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.2885 - accuracy: 0.9619 - val_loss: 0.3073 - val_accuracy: 0.9556\n",
      "Epoch 376/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2870 - accuracy: 0.9619 - val_loss: 0.3057 - val_accuracy: 0.9556\n",
      "Epoch 377/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2855 - accuracy: 0.9619 - val_loss: 0.3042 - val_accuracy: 0.9556\n",
      "Epoch 378/400\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2840 - accuracy: 0.9619 - val_loss: 0.3027 - val_accuracy: 0.9556\n",
      "Epoch 379/400\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2825 - accuracy: 0.9619 - val_loss: 0.3011 - val_accuracy: 0.9556\n",
      "Epoch 380/400\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2810 - accuracy: 0.9619 - val_loss: 0.2996 - val_accuracy: 0.9556\n",
      "Epoch 381/400\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2796 - accuracy: 0.9619 - val_loss: 0.2981 - val_accuracy: 0.9556\n",
      "Epoch 382/400\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2781 - accuracy: 0.9619 - val_loss: 0.2966 - val_accuracy: 0.9556\n",
      "Epoch 383/400\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2767 - accuracy: 0.9619 - val_loss: 0.2952 - val_accuracy: 0.9778\n",
      "Epoch 384/400\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2752 - accuracy: 0.9619 - val_loss: 0.2937 - val_accuracy: 0.9778\n",
      "Epoch 385/400\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.2738 - accuracy: 0.9619 - val_loss: 0.2922 - val_accuracy: 0.9778\n",
      "Epoch 386/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2724 - accuracy: 0.9619 - val_loss: 0.2907 - val_accuracy: 0.9778\n",
      "Epoch 387/400\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2710 - accuracy: 0.9619 - val_loss: 0.2893 - val_accuracy: 0.9778\n",
      "Epoch 388/400\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2696 - accuracy: 0.9619 - val_loss: 0.2879 - val_accuracy: 0.9778\n",
      "Epoch 389/400\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2683 - accuracy: 0.9619 - val_loss: 0.2865 - val_accuracy: 0.9778\n",
      "Epoch 390/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2669 - accuracy: 0.9619 - val_loss: 0.2851 - val_accuracy: 0.9778\n",
      "Epoch 391/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2655 - accuracy: 0.9619 - val_loss: 0.2836 - val_accuracy: 0.9778\n",
      "Epoch 392/400\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2642 - accuracy: 0.9619 - val_loss: 0.2822 - val_accuracy: 0.9778\n",
      "Epoch 393/400\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2629 - accuracy: 0.9619 - val_loss: 0.2808 - val_accuracy: 0.9778\n",
      "Epoch 394/400\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2615 - accuracy: 0.9619 - val_loss: 0.2793 - val_accuracy: 0.9778\n",
      "Epoch 395/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2602 - accuracy: 0.9619 - val_loss: 0.2779 - val_accuracy: 0.9778\n",
      "Epoch 396/400\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2589 - accuracy: 0.9619 - val_loss: 0.2765 - val_accuracy: 0.9778\n",
      "Epoch 397/400\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.2576 - accuracy: 0.9619 - val_loss: 0.2750 - val_accuracy: 0.9778\n",
      "Epoch 398/400\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2563 - accuracy: 0.9619 - val_loss: 0.2736 - val_accuracy: 0.9778\n",
      "Epoch 399/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2550 - accuracy: 0.9619 - val_loss: 0.2722 - val_accuracy: 0.9778\n",
      "Epoch 400/400\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.2537 - accuracy: 0.9619 - val_loss: 0.2708 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=400, batch_size=150, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6415242f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eca403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b56d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e84e47a",
   "metadata": {},
   "source": [
    "# 클래스형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55340069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfee9bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iris(Model):\n",
    "    def __init__(self):\n",
    "        super(Iris, self).__init__()\n",
    "        self.dense1 = Dense(16, activation='relu')\n",
    "        self.dense2 = Dense(8, activation='relu')\n",
    "        self.classifier = Dense(3, activation='softmax')\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "827764f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "32          True            False           False\n",
       "52         False             True           False\n",
       "70         False             True           False\n",
       "121        False            False            True\n",
       "144        False            False            True\n",
       "..           ...              ...             ...\n",
       "113        False            False            True\n",
       "64         False             True           False\n",
       "15          True            False           False\n",
       "125        False            False            True\n",
       "9           True            False           False\n",
       "\n",
       "[105 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06c5ba5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0174 - accuracy: 0.4095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 17:31:58.826863: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 17:31:58.900938: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 17:31:58.901083: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 845ms/step - loss: 1.0174 - accuracy: 0.4095 - val_loss: 0.9890 - val_accuracy: 0.5111\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 1.0127 - accuracy: 0.4000 - val_loss: 0.9861 - val_accuracy: 0.5333\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0080 - accuracy: 0.3714"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 17:31:59.152957: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 17:31:59.191578: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 17:31:59.191657: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15603 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step - loss: 1.0080 - accuracy: 0.3714 - val_loss: 0.9832 - val_accuracy: 0.4889\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0035 - accuracy: 0.3810 - val_loss: 0.9807 - val_accuracy: 0.4222\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.9993 - accuracy: 0.3905 - val_loss: 0.9782 - val_accuracy: 0.3778\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.9952 - accuracy: 0.3619 - val_loss: 0.9759 - val_accuracy: 0.3111\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.9912 - accuracy: 0.3524 - val_loss: 0.9736 - val_accuracy: 0.3111\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9875 - accuracy: 0.3429 - val_loss: 0.9714 - val_accuracy: 0.3111\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.9838 - accuracy: 0.3429 - val_loss: 0.9693 - val_accuracy: 0.3111\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9803 - accuracy: 0.3429 - val_loss: 0.9672 - val_accuracy: 0.3111\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9769 - accuracy: 0.3429 - val_loss: 0.9652 - val_accuracy: 0.3111\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9735 - accuracy: 0.3429 - val_loss: 0.9632 - val_accuracy: 0.3111\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.9703 - accuracy: 0.3429 - val_loss: 0.9613 - val_accuracy: 0.3111\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.9671 - accuracy: 0.3429 - val_loss: 0.9593 - val_accuracy: 0.3111\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.9639 - accuracy: 0.3429 - val_loss: 0.9574 - val_accuracy: 0.3111\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9608 - accuracy: 0.3429 - val_loss: 0.9554 - val_accuracy: 0.3111\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.9578 - accuracy: 0.3429 - val_loss: 0.9534 - val_accuracy: 0.3111\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.9548 - accuracy: 0.3429 - val_loss: 0.9514 - val_accuracy: 0.3111\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9518 - accuracy: 0.3429 - val_loss: 0.9494 - val_accuracy: 0.3111\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9489 - accuracy: 0.3429 - val_loss: 0.9473 - val_accuracy: 0.3111\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.9460 - accuracy: 0.3524 - val_loss: 0.9451 - val_accuracy: 0.3111\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.9430 - accuracy: 0.3524 - val_loss: 0.9430 - val_accuracy: 0.3111\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.9402 - accuracy: 0.3524 - val_loss: 0.9408 - val_accuracy: 0.3111\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.9373 - accuracy: 0.3524 - val_loss: 0.9386 - val_accuracy: 0.3333\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9345 - accuracy: 0.3619 - val_loss: 0.9364 - val_accuracy: 0.3333\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.9316 - accuracy: 0.3619 - val_loss: 0.9342 - val_accuracy: 0.3333\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9288 - accuracy: 0.3714 - val_loss: 0.9319 - val_accuracy: 0.3333\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.9260 - accuracy: 0.3810 - val_loss: 0.9296 - val_accuracy: 0.3778\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9232 - accuracy: 0.3905 - val_loss: 0.9273 - val_accuracy: 0.4000\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.9204 - accuracy: 0.4000 - val_loss: 0.9249 - val_accuracy: 0.4222\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.9176 - accuracy: 0.4381 - val_loss: 0.9225 - val_accuracy: 0.4444\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.9148 - accuracy: 0.4571 - val_loss: 0.9201 - val_accuracy: 0.4667\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.9120 - accuracy: 0.4667 - val_loss: 0.9177 - val_accuracy: 0.4667\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.9092 - accuracy: 0.4857 - val_loss: 0.9152 - val_accuracy: 0.4889\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.9063 - accuracy: 0.5238 - val_loss: 0.9128 - val_accuracy: 0.4889\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.9034 - accuracy: 0.5333 - val_loss: 0.9103 - val_accuracy: 0.4889\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.9006 - accuracy: 0.5524 - val_loss: 0.9078 - val_accuracy: 0.5333\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8977 - accuracy: 0.5810 - val_loss: 0.9053 - val_accuracy: 0.6000\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8949 - accuracy: 0.5810 - val_loss: 0.9028 - val_accuracy: 0.6000\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.8920 - accuracy: 0.6190 - val_loss: 0.9002 - val_accuracy: 0.6000\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.8892 - accuracy: 0.6190 - val_loss: 0.8976 - val_accuracy: 0.6000\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8863 - accuracy: 0.6190 - val_loss: 0.8949 - val_accuracy: 0.6000\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8834 - accuracy: 0.6286 - val_loss: 0.8922 - val_accuracy: 0.6222\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8804 - accuracy: 0.6381 - val_loss: 0.8895 - val_accuracy: 0.6222\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8775 - accuracy: 0.6571 - val_loss: 0.8868 - val_accuracy: 0.6222\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8745 - accuracy: 0.6762 - val_loss: 0.8840 - val_accuracy: 0.6222\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.8715 - accuracy: 0.6762 - val_loss: 0.8812 - val_accuracy: 0.6222\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.8685 - accuracy: 0.6857 - val_loss: 0.8784 - val_accuracy: 0.6222\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8656 - accuracy: 0.6857 - val_loss: 0.8756 - val_accuracy: 0.6222\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8626 - accuracy: 0.6857 - val_loss: 0.8729 - val_accuracy: 0.6222\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.8595 - accuracy: 0.6857 - val_loss: 0.8701 - val_accuracy: 0.6222\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8565 - accuracy: 0.6857 - val_loss: 0.8673 - val_accuracy: 0.6222\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8535 - accuracy: 0.6857 - val_loss: 0.8645 - val_accuracy: 0.6222\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8504 - accuracy: 0.6857 - val_loss: 0.8617 - val_accuracy: 0.6222\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8473 - accuracy: 0.6857 - val_loss: 0.8589 - val_accuracy: 0.6222\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.8443 - accuracy: 0.6857 - val_loss: 0.8561 - val_accuracy: 0.6222\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.8412 - accuracy: 0.6857 - val_loss: 0.8532 - val_accuracy: 0.6222\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8381 - accuracy: 0.6857 - val_loss: 0.8503 - val_accuracy: 0.6222\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8349 - accuracy: 0.6857 - val_loss: 0.8475 - val_accuracy: 0.6222\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.8318 - accuracy: 0.6857 - val_loss: 0.8447 - val_accuracy: 0.6222\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step - loss: 0.8287 - accuracy: 0.6857 - val_loss: 0.8418 - val_accuracy: 0.6222\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8256 - accuracy: 0.6857 - val_loss: 0.8390 - val_accuracy: 0.6222\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.8225 - accuracy: 0.6857 - val_loss: 0.8362 - val_accuracy: 0.6222\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.8194 - accuracy: 0.6857 - val_loss: 0.8334 - val_accuracy: 0.6222\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8163 - accuracy: 0.6857 - val_loss: 0.8305 - val_accuracy: 0.6222\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.8132 - accuracy: 0.6857 - val_loss: 0.8276 - val_accuracy: 0.6222\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.8101 - accuracy: 0.6857 - val_loss: 0.8247 - val_accuracy: 0.6222\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8071 - accuracy: 0.6857 - val_loss: 0.8219 - val_accuracy: 0.6222\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.8040 - accuracy: 0.6857 - val_loss: 0.8190 - val_accuracy: 0.6222\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.8010 - accuracy: 0.6857 - val_loss: 0.8162 - val_accuracy: 0.6222\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7980 - accuracy: 0.6857 - val_loss: 0.8133 - val_accuracy: 0.6222\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7948 - accuracy: 0.6857 - val_loss: 0.8104 - val_accuracy: 0.6222\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.7917 - accuracy: 0.6857 - val_loss: 0.8075 - val_accuracy: 0.6222\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7885 - accuracy: 0.6857 - val_loss: 0.8045 - val_accuracy: 0.6222\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.7853 - accuracy: 0.6857 - val_loss: 0.8015 - val_accuracy: 0.6222\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7820 - accuracy: 0.6857 - val_loss: 0.7984 - val_accuracy: 0.6222\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7787 - accuracy: 0.6857 - val_loss: 0.7953 - val_accuracy: 0.6222\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.7753 - accuracy: 0.6857 - val_loss: 0.7920 - val_accuracy: 0.6222\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7719 - accuracy: 0.6857 - val_loss: 0.7886 - val_accuracy: 0.6222\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.7683 - accuracy: 0.6857 - val_loss: 0.7850 - val_accuracy: 0.6222\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7647 - accuracy: 0.6857 - val_loss: 0.7814 - val_accuracy: 0.6222\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7611 - accuracy: 0.6857 - val_loss: 0.7777 - val_accuracy: 0.6222\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7574 - accuracy: 0.6857 - val_loss: 0.7740 - val_accuracy: 0.6222\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.7535 - accuracy: 0.6857 - val_loss: 0.7704 - val_accuracy: 0.6222\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7496 - accuracy: 0.6857 - val_loss: 0.7666 - val_accuracy: 0.6222\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7457 - accuracy: 0.6857 - val_loss: 0.7628 - val_accuracy: 0.6222\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.7417 - accuracy: 0.6857 - val_loss: 0.7588 - val_accuracy: 0.6222\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.7377 - accuracy: 0.6857 - val_loss: 0.7548 - val_accuracy: 0.6222\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7335 - accuracy: 0.6857 - val_loss: 0.7508 - val_accuracy: 0.6222\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.7293 - accuracy: 0.6857 - val_loss: 0.7468 - val_accuracy: 0.6222\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.7250 - accuracy: 0.6857 - val_loss: 0.7427 - val_accuracy: 0.6222\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.7209 - accuracy: 0.6857 - val_loss: 0.7385 - val_accuracy: 0.6222\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7170 - accuracy: 0.6857 - val_loss: 0.7343 - val_accuracy: 0.6222\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7132 - accuracy: 0.6857 - val_loss: 0.7300 - val_accuracy: 0.6222\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.7095 - accuracy: 0.6952 - val_loss: 0.7259 - val_accuracy: 0.6444\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7059 - accuracy: 0.6952 - val_loss: 0.7220 - val_accuracy: 0.6667\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.7022 - accuracy: 0.6952 - val_loss: 0.7181 - val_accuracy: 0.6667\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6985 - accuracy: 0.6952 - val_loss: 0.7143 - val_accuracy: 0.6667\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6948 - accuracy: 0.6952 - val_loss: 0.7106 - val_accuracy: 0.6667\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6910 - accuracy: 0.6952 - val_loss: 0.7069 - val_accuracy: 0.6667\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6872 - accuracy: 0.7048 - val_loss: 0.7033 - val_accuracy: 0.6667\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6834 - accuracy: 0.7048 - val_loss: 0.6996 - val_accuracy: 0.6667\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6797 - accuracy: 0.7143 - val_loss: 0.6960 - val_accuracy: 0.6667\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6759 - accuracy: 0.7143 - val_loss: 0.6924 - val_accuracy: 0.6667\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6721 - accuracy: 0.7143 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6683 - accuracy: 0.7143 - val_loss: 0.6851 - val_accuracy: 0.6667\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.6645 - accuracy: 0.7143 - val_loss: 0.6815 - val_accuracy: 0.6667\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.6607 - accuracy: 0.7143 - val_loss: 0.6780 - val_accuracy: 0.6667\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6569 - accuracy: 0.7143 - val_loss: 0.6744 - val_accuracy: 0.6667\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6531 - accuracy: 0.7238 - val_loss: 0.6708 - val_accuracy: 0.6667\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6494 - accuracy: 0.7238 - val_loss: 0.6672 - val_accuracy: 0.6667\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6456 - accuracy: 0.7333 - val_loss: 0.6636 - val_accuracy: 0.6667\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6419 - accuracy: 0.7429 - val_loss: 0.6601 - val_accuracy: 0.6667\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6382 - accuracy: 0.7429 - val_loss: 0.6565 - val_accuracy: 0.6667\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.6344 - accuracy: 0.7429 - val_loss: 0.6530 - val_accuracy: 0.6667\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6307 - accuracy: 0.7429 - val_loss: 0.6494 - val_accuracy: 0.6667\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.6270 - accuracy: 0.7429 - val_loss: 0.6458 - val_accuracy: 0.6667\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6233 - accuracy: 0.7429 - val_loss: 0.6423 - val_accuracy: 0.6667\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step - loss: 0.6196 - accuracy: 0.7429 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6160 - accuracy: 0.7429 - val_loss: 0.6352 - val_accuracy: 0.6667\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6123 - accuracy: 0.7429 - val_loss: 0.6317 - val_accuracy: 0.6667\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6087 - accuracy: 0.7429 - val_loss: 0.6282 - val_accuracy: 0.6667\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6051 - accuracy: 0.7524 - val_loss: 0.6247 - val_accuracy: 0.6889\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6015 - accuracy: 0.7619 - val_loss: 0.6213 - val_accuracy: 0.6889\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5979 - accuracy: 0.7619 - val_loss: 0.6178 - val_accuracy: 0.6889\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5943 - accuracy: 0.7714 - val_loss: 0.6143 - val_accuracy: 0.6889\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5907 - accuracy: 0.7810 - val_loss: 0.6108 - val_accuracy: 0.6889\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.5872 - accuracy: 0.7810 - val_loss: 0.6073 - val_accuracy: 0.6889\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5836 - accuracy: 0.7810 - val_loss: 0.6038 - val_accuracy: 0.7111\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.5800 - accuracy: 0.7905 - val_loss: 0.6003 - val_accuracy: 0.7111\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5765 - accuracy: 0.7905 - val_loss: 0.5968 - val_accuracy: 0.7111\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5730 - accuracy: 0.8000 - val_loss: 0.5933 - val_accuracy: 0.7111\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5695 - accuracy: 0.8095 - val_loss: 0.5899 - val_accuracy: 0.7111\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5660 - accuracy: 0.8095 - val_loss: 0.5864 - val_accuracy: 0.7111\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5625 - accuracy: 0.8095 - val_loss: 0.5830 - val_accuracy: 0.7111\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5590 - accuracy: 0.8095 - val_loss: 0.5795 - val_accuracy: 0.7111\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5556 - accuracy: 0.8095 - val_loss: 0.5760 - val_accuracy: 0.7111\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5522 - accuracy: 0.8286 - val_loss: 0.5726 - val_accuracy: 0.7333\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5487 - accuracy: 0.8286 - val_loss: 0.5692 - val_accuracy: 0.7333\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.5454 - accuracy: 0.8381 - val_loss: 0.5658 - val_accuracy: 0.7556\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5420 - accuracy: 0.8381 - val_loss: 0.5624 - val_accuracy: 0.7556\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5386 - accuracy: 0.8381 - val_loss: 0.5591 - val_accuracy: 0.7778\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5353 - accuracy: 0.8381 - val_loss: 0.5557 - val_accuracy: 0.7778\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.5319 - accuracy: 0.8381 - val_loss: 0.5524 - val_accuracy: 0.8000\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5286 - accuracy: 0.8381 - val_loss: 0.5491 - val_accuracy: 0.8000\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5253 - accuracy: 0.8381 - val_loss: 0.5457 - val_accuracy: 0.8444\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.5220 - accuracy: 0.8571 - val_loss: 0.5424 - val_accuracy: 0.8444\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.5188 - accuracy: 0.8571 - val_loss: 0.5392 - val_accuracy: 0.8444\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.5155 - accuracy: 0.8571 - val_loss: 0.5359 - val_accuracy: 0.8444\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.5123 - accuracy: 0.8571 - val_loss: 0.5326 - val_accuracy: 0.8444\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.5091 - accuracy: 0.8571 - val_loss: 0.5294 - val_accuracy: 0.8444\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.5059 - accuracy: 0.8571 - val_loss: 0.5262 - val_accuracy: 0.8444\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5027 - accuracy: 0.8571 - val_loss: 0.5229 - val_accuracy: 0.8444\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.4996 - accuracy: 0.8667 - val_loss: 0.5197 - val_accuracy: 0.8444\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4964 - accuracy: 0.8667 - val_loss: 0.5165 - val_accuracy: 0.8667\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.4933 - accuracy: 0.8667 - val_loss: 0.5133 - val_accuracy: 0.8667\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.4903 - accuracy: 0.8857 - val_loss: 0.5102 - val_accuracy: 0.8667\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.4872 - accuracy: 0.8952 - val_loss: 0.5071 - val_accuracy: 0.9111\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4841 - accuracy: 0.8952 - val_loss: 0.5039 - val_accuracy: 0.9111\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4811 - accuracy: 0.8952 - val_loss: 0.5009 - val_accuracy: 0.9111\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4781 - accuracy: 0.8952 - val_loss: 0.4978 - val_accuracy: 0.9111\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4751 - accuracy: 0.9048 - val_loss: 0.4948 - val_accuracy: 0.9111\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.4722 - accuracy: 0.9048 - val_loss: 0.4917 - val_accuracy: 0.9111\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.4693 - accuracy: 0.9143 - val_loss: 0.4888 - val_accuracy: 0.9111\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.4664 - accuracy: 0.9143 - val_loss: 0.4858 - val_accuracy: 0.9111\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4635 - accuracy: 0.9143 - val_loss: 0.4828 - val_accuracy: 0.9111\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4606 - accuracy: 0.9238 - val_loss: 0.4799 - val_accuracy: 0.9111\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4578 - accuracy: 0.9238 - val_loss: 0.4770 - val_accuracy: 0.9111\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4549 - accuracy: 0.9238 - val_loss: 0.4741 - val_accuracy: 0.9111\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4521 - accuracy: 0.9238 - val_loss: 0.4713 - val_accuracy: 0.9111\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4493 - accuracy: 0.9238 - val_loss: 0.4684 - val_accuracy: 0.9111\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4466 - accuracy: 0.9238 - val_loss: 0.4656 - val_accuracy: 0.9111\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4438 - accuracy: 0.9238 - val_loss: 0.4628 - val_accuracy: 0.9111\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4411 - accuracy: 0.9238 - val_loss: 0.4600 - val_accuracy: 0.9111\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.4384 - accuracy: 0.9238 - val_loss: 0.4572 - val_accuracy: 0.9111\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4358 - accuracy: 0.9238 - val_loss: 0.4545 - val_accuracy: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4331 - accuracy: 0.9238 - val_loss: 0.4517 - val_accuracy: 0.9111\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4305 - accuracy: 0.9238 - val_loss: 0.4490 - val_accuracy: 0.9111\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.4279 - accuracy: 0.9333 - val_loss: 0.4463 - val_accuracy: 0.9111\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.4253 - accuracy: 0.9333 - val_loss: 0.4436 - val_accuracy: 0.9111\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4227 - accuracy: 0.9429 - val_loss: 0.4409 - val_accuracy: 0.9111\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4202 - accuracy: 0.9429 - val_loss: 0.4382 - val_accuracy: 0.9111\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4177 - accuracy: 0.9429 - val_loss: 0.4356 - val_accuracy: 0.9111\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.4152 - accuracy: 0.9429 - val_loss: 0.4330 - val_accuracy: 0.9111\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4128 - accuracy: 0.9429 - val_loss: 0.4305 - val_accuracy: 0.9111\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4103 - accuracy: 0.9429 - val_loss: 0.4279 - val_accuracy: 0.9111\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.4079 - accuracy: 0.9429 - val_loss: 0.4254 - val_accuracy: 0.9111\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4055 - accuracy: 0.9429 - val_loss: 0.4229 - val_accuracy: 0.9111\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4032 - accuracy: 0.9429 - val_loss: 0.4205 - val_accuracy: 0.9111\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.4008 - accuracy: 0.9429 - val_loss: 0.4181 - val_accuracy: 0.9111\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.3985 - accuracy: 0.9429 - val_loss: 0.4157 - val_accuracy: 0.9111\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.3962 - accuracy: 0.9429 - val_loss: 0.4133 - val_accuracy: 0.9111\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3940 - accuracy: 0.9429 - val_loss: 0.4109 - val_accuracy: 0.9111\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3917 - accuracy: 0.9524 - val_loss: 0.4086 - val_accuracy: 0.9111\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3895 - accuracy: 0.9524 - val_loss: 0.4063 - val_accuracy: 0.9111\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3873 - accuracy: 0.9524 - val_loss: 0.4039 - val_accuracy: 0.9111\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.3851 - accuracy: 0.9524 - val_loss: 0.4016 - val_accuracy: 0.9111\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3829 - accuracy: 0.9524 - val_loss: 0.3993 - val_accuracy: 0.9111\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3808 - accuracy: 0.9524 - val_loss: 0.3970 - val_accuracy: 0.9111\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3786 - accuracy: 0.9524 - val_loss: 0.3948 - val_accuracy: 0.9111\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3765 - accuracy: 0.9524 - val_loss: 0.3925 - val_accuracy: 0.9111\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.3744 - accuracy: 0.9524 - val_loss: 0.3903 - val_accuracy: 0.9111\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 0.3723 - accuracy: 0.9524 - val_loss: 0.3881 - val_accuracy: 0.9111\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.3703 - accuracy: 0.9524 - val_loss: 0.3859 - val_accuracy: 0.9111\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3682 - accuracy: 0.9524 - val_loss: 0.3837 - val_accuracy: 0.9111\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3662 - accuracy: 0.9524 - val_loss: 0.3815 - val_accuracy: 0.9111\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.3642 - accuracy: 0.9524 - val_loss: 0.3793 - val_accuracy: 0.9111\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.3622 - accuracy: 0.9524 - val_loss: 0.3772 - val_accuracy: 0.9111\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3602 - accuracy: 0.9524 - val_loss: 0.3751 - val_accuracy: 0.9111\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3582 - accuracy: 0.9524 - val_loss: 0.3729 - val_accuracy: 0.9111\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3562 - accuracy: 0.9524 - val_loss: 0.3708 - val_accuracy: 0.9111\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3543 - accuracy: 0.9524 - val_loss: 0.3687 - val_accuracy: 0.9111\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.3523 - accuracy: 0.9524 - val_loss: 0.3666 - val_accuracy: 0.9111\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.3504 - accuracy: 0.9524 - val_loss: 0.3645 - val_accuracy: 0.9111\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3485 - accuracy: 0.9524 - val_loss: 0.3625 - val_accuracy: 0.9111\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3467 - accuracy: 0.9524 - val_loss: 0.3604 - val_accuracy: 0.9111\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3448 - accuracy: 0.9524 - val_loss: 0.3584 - val_accuracy: 0.9111\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3429 - accuracy: 0.9524 - val_loss: 0.3563 - val_accuracy: 0.9111\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.3411 - accuracy: 0.9524 - val_loss: 0.3544 - val_accuracy: 0.9111\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3393 - accuracy: 0.9524 - val_loss: 0.3524 - val_accuracy: 0.9111\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.3375 - accuracy: 0.9524 - val_loss: 0.3504 - val_accuracy: 0.9111\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3357 - accuracy: 0.9524 - val_loss: 0.3485 - val_accuracy: 0.9111\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3339 - accuracy: 0.9524 - val_loss: 0.3466 - val_accuracy: 0.9111\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.3321 - accuracy: 0.9524 - val_loss: 0.3448 - val_accuracy: 0.9111\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.3303 - accuracy: 0.9524 - val_loss: 0.3429 - val_accuracy: 0.9111\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3286 - accuracy: 0.9524 - val_loss: 0.3410 - val_accuracy: 0.9111\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3268 - accuracy: 0.9524 - val_loss: 0.3392 - val_accuracy: 0.9111\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3251 - accuracy: 0.9524 - val_loss: 0.3373 - val_accuracy: 0.9556\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.3234 - accuracy: 0.9524 - val_loss: 0.3354 - val_accuracy: 0.9556\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.3217 - accuracy: 0.9524 - val_loss: 0.3335 - val_accuracy: 0.9556\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.3200 - accuracy: 0.9524 - val_loss: 0.3316 - val_accuracy: 0.9556\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3184 - accuracy: 0.9524 - val_loss: 0.3297 - val_accuracy: 0.9556\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.3167 - accuracy: 0.9524 - val_loss: 0.3278 - val_accuracy: 0.9556\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step - loss: 0.3151 - accuracy: 0.9524 - val_loss: 0.3260 - val_accuracy: 0.9556\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.3134 - accuracy: 0.9524 - val_loss: 0.3241 - val_accuracy: 0.9556\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.3118 - accuracy: 0.9524 - val_loss: 0.3223 - val_accuracy: 0.9556\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3102 - accuracy: 0.9524 - val_loss: 0.3205 - val_accuracy: 0.9556\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.3086 - accuracy: 0.9524 - val_loss: 0.3187 - val_accuracy: 0.9556\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.3070 - accuracy: 0.9524 - val_loss: 0.3170 - val_accuracy: 0.9556\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.3054 - accuracy: 0.9524 - val_loss: 0.3152 - val_accuracy: 0.9556\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3038 - accuracy: 0.9524 - val_loss: 0.3135 - val_accuracy: 0.9556\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3022 - accuracy: 0.9524 - val_loss: 0.3117 - val_accuracy: 0.9556\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3007 - accuracy: 0.9524 - val_loss: 0.3100 - val_accuracy: 0.9556\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.2991 - accuracy: 0.9524 - val_loss: 0.3083 - val_accuracy: 0.9556\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.2976 - accuracy: 0.9524 - val_loss: 0.3067 - val_accuracy: 0.9556\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2961 - accuracy: 0.9524 - val_loss: 0.3050 - val_accuracy: 0.9556\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2946 - accuracy: 0.9524 - val_loss: 0.3033 - val_accuracy: 0.9556\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2931 - accuracy: 0.9524 - val_loss: 0.3017 - val_accuracy: 0.9556\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2916 - accuracy: 0.9524 - val_loss: 0.3000 - val_accuracy: 0.9556\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2901 - accuracy: 0.9524 - val_loss: 0.2984 - val_accuracy: 0.9556\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2886 - accuracy: 0.9524 - val_loss: 0.2968 - val_accuracy: 0.9556\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.2871 - accuracy: 0.9524 - val_loss: 0.2952 - val_accuracy: 0.9556\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2857 - accuracy: 0.9524 - val_loss: 0.2936 - val_accuracy: 0.9556\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2842 - accuracy: 0.9524 - val_loss: 0.2920 - val_accuracy: 0.9556\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2828 - accuracy: 0.9524 - val_loss: 0.2905 - val_accuracy: 0.9556\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2814 - accuracy: 0.9524 - val_loss: 0.2889 - val_accuracy: 0.9556\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2800 - accuracy: 0.9524 - val_loss: 0.2873 - val_accuracy: 0.9556\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2786 - accuracy: 0.9524 - val_loss: 0.2857 - val_accuracy: 0.9556\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2772 - accuracy: 0.9619 - val_loss: 0.2842 - val_accuracy: 0.9556\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2758 - accuracy: 0.9619 - val_loss: 0.2826 - val_accuracy: 0.9556\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2744 - accuracy: 0.9619 - val_loss: 0.2811 - val_accuracy: 0.9556\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2730 - accuracy: 0.9619 - val_loss: 0.2796 - val_accuracy: 0.9556\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2717 - accuracy: 0.9619 - val_loss: 0.2781 - val_accuracy: 0.9556\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2703 - accuracy: 0.9714 - val_loss: 0.2766 - val_accuracy: 0.9556\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2690 - accuracy: 0.9714 - val_loss: 0.2751 - val_accuracy: 0.9556\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2676 - accuracy: 0.9714 - val_loss: 0.2736 - val_accuracy: 0.9556\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2663 - accuracy: 0.9714 - val_loss: 0.2721 - val_accuracy: 0.9556\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2650 - accuracy: 0.9714 - val_loss: 0.2706 - val_accuracy: 0.9556\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.2637 - accuracy: 0.9714 - val_loss: 0.2691 - val_accuracy: 0.9556\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2624 - accuracy: 0.9714 - val_loss: 0.2677 - val_accuracy: 0.9556\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.2611 - accuracy: 0.9714 - val_loss: 0.2662 - val_accuracy: 0.9556\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2598 - accuracy: 0.9714 - val_loss: 0.2648 - val_accuracy: 0.9556\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.2585 - accuracy: 0.9714 - val_loss: 0.2634 - val_accuracy: 0.9556\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2572 - accuracy: 0.9714 - val_loss: 0.2620 - val_accuracy: 0.9556\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2560 - accuracy: 0.9714 - val_loss: 0.2606 - val_accuracy: 0.9556\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.2547 - accuracy: 0.9714 - val_loss: 0.2592 - val_accuracy: 0.9556\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2535 - accuracy: 0.9714 - val_loss: 0.2578 - val_accuracy: 0.9556\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2522 - accuracy: 0.9714 - val_loss: 0.2564 - val_accuracy: 0.9556\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2510 - accuracy: 0.9714 - val_loss: 0.2550 - val_accuracy: 0.9556\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2498 - accuracy: 0.9714 - val_loss: 0.2536 - val_accuracy: 0.9556\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2485 - accuracy: 0.9714 - val_loss: 0.2523 - val_accuracy: 0.9556\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.2473 - accuracy: 0.9714 - val_loss: 0.2509 - val_accuracy: 0.9556\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2461 - accuracy: 0.9714 - val_loss: 0.2496 - val_accuracy: 0.9556\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2449 - accuracy: 0.9714 - val_loss: 0.2483 - val_accuracy: 0.9556\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2438 - accuracy: 0.9714 - val_loss: 0.2470 - val_accuracy: 0.9556\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2426 - accuracy: 0.9714 - val_loss: 0.2456 - val_accuracy: 0.9556\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2414 - accuracy: 0.9619 - val_loss: 0.2443 - val_accuracy: 0.9556\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.2403 - accuracy: 0.9619 - val_loss: 0.2430 - val_accuracy: 0.9556\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2391 - accuracy: 0.9619 - val_loss: 0.2418 - val_accuracy: 0.9556\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2380 - accuracy: 0.9619 - val_loss: 0.2405 - val_accuracy: 0.9556\n",
      "Epoch 291/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step - loss: 0.2368 - accuracy: 0.9619 - val_loss: 0.2392 - val_accuracy: 0.9556\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2357 - accuracy: 0.9619 - val_loss: 0.2380 - val_accuracy: 0.9556\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2346 - accuracy: 0.9619 - val_loss: 0.2367 - val_accuracy: 0.9556\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2334 - accuracy: 0.9619 - val_loss: 0.2355 - val_accuracy: 0.9556\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2323 - accuracy: 0.9619 - val_loss: 0.2342 - val_accuracy: 0.9556\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2312 - accuracy: 0.9619 - val_loss: 0.2330 - val_accuracy: 0.9556\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2301 - accuracy: 0.9619 - val_loss: 0.2318 - val_accuracy: 0.9556\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2291 - accuracy: 0.9619 - val_loss: 0.2306 - val_accuracy: 0.9556\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2280 - accuracy: 0.9619 - val_loss: 0.2295 - val_accuracy: 0.9556\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2269 - accuracy: 0.9619 - val_loss: 0.2283 - val_accuracy: 0.9556\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2258 - accuracy: 0.9619 - val_loss: 0.2271 - val_accuracy: 0.9556\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2248 - accuracy: 0.9619 - val_loss: 0.2260 - val_accuracy: 0.9556\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2237 - accuracy: 0.9619 - val_loss: 0.2248 - val_accuracy: 0.9556\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2227 - accuracy: 0.9619 - val_loss: 0.2237 - val_accuracy: 0.9556\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2217 - accuracy: 0.9619 - val_loss: 0.2225 - val_accuracy: 0.9556\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2206 - accuracy: 0.9619 - val_loss: 0.2214 - val_accuracy: 0.9556\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2196 - accuracy: 0.9619 - val_loss: 0.2202 - val_accuracy: 0.9556\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2186 - accuracy: 0.9619 - val_loss: 0.2191 - val_accuracy: 0.9556\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2176 - accuracy: 0.9619 - val_loss: 0.2180 - val_accuracy: 0.9556\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2166 - accuracy: 0.9619 - val_loss: 0.2168 - val_accuracy: 0.9556\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2156 - accuracy: 0.9619 - val_loss: 0.2157 - val_accuracy: 0.9556\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2146 - accuracy: 0.9619 - val_loss: 0.2146 - val_accuracy: 0.9556\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2137 - accuracy: 0.9619 - val_loss: 0.2134 - val_accuracy: 0.9556\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2127 - accuracy: 0.9619 - val_loss: 0.2123 - val_accuracy: 0.9556\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2117 - accuracy: 0.9619 - val_loss: 0.2112 - val_accuracy: 0.9556\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2108 - accuracy: 0.9619 - val_loss: 0.2101 - val_accuracy: 0.9556\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2098 - accuracy: 0.9619 - val_loss: 0.2090 - val_accuracy: 0.9556\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2089 - accuracy: 0.9619 - val_loss: 0.2079 - val_accuracy: 0.9556\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2079 - accuracy: 0.9619 - val_loss: 0.2069 - val_accuracy: 0.9556\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2070 - accuracy: 0.9619 - val_loss: 0.2058 - val_accuracy: 0.9556\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2061 - accuracy: 0.9619 - val_loss: 0.2048 - val_accuracy: 0.9778\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2052 - accuracy: 0.9619 - val_loss: 0.2037 - val_accuracy: 0.9778\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2043 - accuracy: 0.9619 - val_loss: 0.2027 - val_accuracy: 0.9778\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2034 - accuracy: 0.9619 - val_loss: 0.2017 - val_accuracy: 0.9778\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2025 - accuracy: 0.9619 - val_loss: 0.2007 - val_accuracy: 0.9778\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.2016 - accuracy: 0.9619 - val_loss: 0.1996 - val_accuracy: 0.9778\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2007 - accuracy: 0.9619 - val_loss: 0.1986 - val_accuracy: 0.9778\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1998 - accuracy: 0.9619 - val_loss: 0.1976 - val_accuracy: 0.9778\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1989 - accuracy: 0.9619 - val_loss: 0.1967 - val_accuracy: 0.9778\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1981 - accuracy: 0.9619 - val_loss: 0.1957 - val_accuracy: 0.9778\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1972 - accuracy: 0.9619 - val_loss: 0.1947 - val_accuracy: 0.9778\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.1963 - accuracy: 0.9619 - val_loss: 0.1937 - val_accuracy: 0.9778\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1955 - accuracy: 0.9619 - val_loss: 0.1928 - val_accuracy: 0.9778\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1947 - accuracy: 0.9619 - val_loss: 0.1918 - val_accuracy: 0.9778\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1938 - accuracy: 0.9619 - val_loss: 0.1908 - val_accuracy: 0.9778\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1930 - accuracy: 0.9619 - val_loss: 0.1899 - val_accuracy: 0.9778\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1922 - accuracy: 0.9619 - val_loss: 0.1890 - val_accuracy: 0.9778\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1913 - accuracy: 0.9619 - val_loss: 0.1880 - val_accuracy: 0.9778\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1905 - accuracy: 0.9619 - val_loss: 0.1871 - val_accuracy: 0.9778\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1897 - accuracy: 0.9619 - val_loss: 0.1862 - val_accuracy: 0.9778\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1889 - accuracy: 0.9619 - val_loss: 0.1853 - val_accuracy: 0.9778\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1881 - accuracy: 0.9619 - val_loss: 0.1844 - val_accuracy: 0.9778\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1873 - accuracy: 0.9619 - val_loss: 0.1835 - val_accuracy: 0.9778\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1866 - accuracy: 0.9619 - val_loss: 0.1826 - val_accuracy: 0.9778\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1858 - accuracy: 0.9619 - val_loss: 0.1818 - val_accuracy: 0.9778\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1850 - accuracy: 0.9619 - val_loss: 0.1809 - val_accuracy: 0.9778\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1842 - accuracy: 0.9619 - val_loss: 0.1801 - val_accuracy: 0.9778\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.1835 - accuracy: 0.9619 - val_loss: 0.1793 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1827 - accuracy: 0.9619 - val_loss: 0.1784 - val_accuracy: 0.9778\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1820 - accuracy: 0.9619 - val_loss: 0.1776 - val_accuracy: 0.9778\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1812 - accuracy: 0.9619 - val_loss: 0.1767 - val_accuracy: 0.9778\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1805 - accuracy: 0.9619 - val_loss: 0.1758 - val_accuracy: 0.9778\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1798 - accuracy: 0.9619 - val_loss: 0.1749 - val_accuracy: 0.9778\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1790 - accuracy: 0.9619 - val_loss: 0.1740 - val_accuracy: 0.9778\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1783 - accuracy: 0.9619 - val_loss: 0.1731 - val_accuracy: 0.9778\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1776 - accuracy: 0.9619 - val_loss: 0.1723 - val_accuracy: 0.9778\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1769 - accuracy: 0.9619 - val_loss: 0.1714 - val_accuracy: 0.9778\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1762 - accuracy: 0.9619 - val_loss: 0.1706 - val_accuracy: 0.9778\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1755 - accuracy: 0.9619 - val_loss: 0.1698 - val_accuracy: 0.9778\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1748 - accuracy: 0.9619 - val_loss: 0.1690 - val_accuracy: 0.9778\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1741 - accuracy: 0.9619 - val_loss: 0.1682 - val_accuracy: 0.9778\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1734 - accuracy: 0.9619 - val_loss: 0.1674 - val_accuracy: 0.9778\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1727 - accuracy: 0.9619 - val_loss: 0.1666 - val_accuracy: 0.9778\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1721 - accuracy: 0.9619 - val_loss: 0.1658 - val_accuracy: 0.9778\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1714 - accuracy: 0.9619 - val_loss: 0.1650 - val_accuracy: 0.9778\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1707 - accuracy: 0.9619 - val_loss: 0.1643 - val_accuracy: 0.9778\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1701 - accuracy: 0.9619 - val_loss: 0.1635 - val_accuracy: 0.9778\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1694 - accuracy: 0.9619 - val_loss: 0.1628 - val_accuracy: 0.9778\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1687 - accuracy: 0.9619 - val_loss: 0.1620 - val_accuracy: 0.9778\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1681 - accuracy: 0.9619 - val_loss: 0.1613 - val_accuracy: 0.9778\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1675 - accuracy: 0.9619 - val_loss: 0.1605 - val_accuracy: 0.9778\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1668 - accuracy: 0.9619 - val_loss: 0.1598 - val_accuracy: 0.9778\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1662 - accuracy: 0.9619 - val_loss: 0.1590 - val_accuracy: 0.9778\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1656 - accuracy: 0.9619 - val_loss: 0.1583 - val_accuracy: 0.9778\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1649 - accuracy: 0.9619 - val_loss: 0.1576 - val_accuracy: 0.9778\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1643 - accuracy: 0.9619 - val_loss: 0.1568 - val_accuracy: 0.9778\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1637 - accuracy: 0.9619 - val_loss: 0.1561 - val_accuracy: 0.9778\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1631 - accuracy: 0.9619 - val_loss: 0.1554 - val_accuracy: 0.9778\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1625 - accuracy: 0.9619 - val_loss: 0.1547 - val_accuracy: 0.9778\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1619 - accuracy: 0.9619 - val_loss: 0.1540 - val_accuracy: 0.9778\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1613 - accuracy: 0.9619 - val_loss: 0.1532 - val_accuracy: 0.9778\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1607 - accuracy: 0.9619 - val_loss: 0.1525 - val_accuracy: 0.9778\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1601 - accuracy: 0.9619 - val_loss: 0.1519 - val_accuracy: 0.9778\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1595 - accuracy: 0.9619 - val_loss: 0.1512 - val_accuracy: 0.9778\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1590 - accuracy: 0.9619 - val_loss: 0.1505 - val_accuracy: 0.9778\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1584 - accuracy: 0.9619 - val_loss: 0.1498 - val_accuracy: 0.9778\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1578 - accuracy: 0.9619 - val_loss: 0.1492 - val_accuracy: 0.9778\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1572 - accuracy: 0.9619 - val_loss: 0.1485 - val_accuracy: 0.9778\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1567 - accuracy: 0.9619 - val_loss: 0.1479 - val_accuracy: 0.9778\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1561 - accuracy: 0.9619 - val_loss: 0.1472 - val_accuracy: 0.9778\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.1556 - accuracy: 0.9619 - val_loss: 0.1466 - val_accuracy: 0.9778\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1550 - accuracy: 0.9619 - val_loss: 0.1459 - val_accuracy: 0.9778\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1545 - accuracy: 0.9619 - val_loss: 0.1453 - val_accuracy: 0.9778\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1539 - accuracy: 0.9619 - val_loss: 0.1447 - val_accuracy: 0.9778\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1534 - accuracy: 0.9619 - val_loss: 0.1441 - val_accuracy: 0.9778\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1529 - accuracy: 0.9619 - val_loss: 0.1435 - val_accuracy: 0.9778\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1523 - accuracy: 0.9619 - val_loss: 0.1428 - val_accuracy: 0.9778\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1518 - accuracy: 0.9619 - val_loss: 0.1422 - val_accuracy: 0.9778\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1513 - accuracy: 0.9619 - val_loss: 0.1416 - val_accuracy: 0.9778\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1508 - accuracy: 0.9619 - val_loss: 0.1410 - val_accuracy: 0.9778\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1502 - accuracy: 0.9619 - val_loss: 0.1404 - val_accuracy: 0.9778\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1497 - accuracy: 0.9619 - val_loss: 0.1398 - val_accuracy: 0.9778\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1492 - accuracy: 0.9619 - val_loss: 0.1392 - val_accuracy: 0.9778\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1487 - accuracy: 0.9619 - val_loss: 0.1386 - val_accuracy: 0.9778\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1482 - accuracy: 0.9619 - val_loss: 0.1380 - val_accuracy: 0.9778\n",
      "Epoch 406/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step - loss: 0.1477 - accuracy: 0.9619 - val_loss: 0.1374 - val_accuracy: 0.9778\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1472 - accuracy: 0.9619 - val_loss: 0.1368 - val_accuracy: 0.9778\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1467 - accuracy: 0.9619 - val_loss: 0.1362 - val_accuracy: 0.9778\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1462 - accuracy: 0.9619 - val_loss: 0.1357 - val_accuracy: 0.9778\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1458 - accuracy: 0.9619 - val_loss: 0.1351 - val_accuracy: 0.9778\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1453 - accuracy: 0.9619 - val_loss: 0.1345 - val_accuracy: 0.9778\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1448 - accuracy: 0.9619 - val_loss: 0.1340 - val_accuracy: 0.9778\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1443 - accuracy: 0.9619 - val_loss: 0.1334 - val_accuracy: 0.9778\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1439 - accuracy: 0.9619 - val_loss: 0.1329 - val_accuracy: 0.9778\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1434 - accuracy: 0.9619 - val_loss: 0.1323 - val_accuracy: 0.9778\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1429 - accuracy: 0.9619 - val_loss: 0.1318 - val_accuracy: 0.9778\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1425 - accuracy: 0.9619 - val_loss: 0.1312 - val_accuracy: 0.9778\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1420 - accuracy: 0.9619 - val_loss: 0.1307 - val_accuracy: 0.9778\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.1416 - accuracy: 0.9619 - val_loss: 0.1301 - val_accuracy: 0.9778\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1411 - accuracy: 0.9619 - val_loss: 0.1296 - val_accuracy: 0.9778\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1407 - accuracy: 0.9619 - val_loss: 0.1291 - val_accuracy: 0.9778\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1402 - accuracy: 0.9619 - val_loss: 0.1286 - val_accuracy: 0.9778\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1398 - accuracy: 0.9619 - val_loss: 0.1281 - val_accuracy: 0.9778\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1393 - accuracy: 0.9619 - val_loss: 0.1275 - val_accuracy: 0.9778\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1389 - accuracy: 0.9619 - val_loss: 0.1270 - val_accuracy: 0.9778\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1385 - accuracy: 0.9619 - val_loss: 0.1265 - val_accuracy: 0.9778\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1380 - accuracy: 0.9619 - val_loss: 0.1260 - val_accuracy: 0.9778\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1376 - accuracy: 0.9619 - val_loss: 0.1255 - val_accuracy: 0.9778\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1372 - accuracy: 0.9619 - val_loss: 0.1250 - val_accuracy: 0.9778\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1368 - accuracy: 0.9619 - val_loss: 0.1245 - val_accuracy: 0.9778\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1363 - accuracy: 0.9619 - val_loss: 0.1240 - val_accuracy: 0.9778\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1359 - accuracy: 0.9619 - val_loss: 0.1235 - val_accuracy: 0.9778\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1355 - accuracy: 0.9619 - val_loss: 0.1230 - val_accuracy: 0.9778\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.1351 - accuracy: 0.9524 - val_loss: 0.1226 - val_accuracy: 0.9778\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1347 - accuracy: 0.9524 - val_loss: 0.1221 - val_accuracy: 0.9778\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1343 - accuracy: 0.9524 - val_loss: 0.1216 - val_accuracy: 0.9778\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1339 - accuracy: 0.9524 - val_loss: 0.1211 - val_accuracy: 0.9778\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1335 - accuracy: 0.9524 - val_loss: 0.1206 - val_accuracy: 0.9778\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1331 - accuracy: 0.9524 - val_loss: 0.1202 - val_accuracy: 0.9778\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1327 - accuracy: 0.9524 - val_loss: 0.1197 - val_accuracy: 0.9778\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1323 - accuracy: 0.9524 - val_loss: 0.1193 - val_accuracy: 0.9778\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1319 - accuracy: 0.9524 - val_loss: 0.1189 - val_accuracy: 0.9778\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1315 - accuracy: 0.9524 - val_loss: 0.1184 - val_accuracy: 0.9778\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1311 - accuracy: 0.9524 - val_loss: 0.1180 - val_accuracy: 0.9778\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1307 - accuracy: 0.9524 - val_loss: 0.1175 - val_accuracy: 0.9778\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1304 - accuracy: 0.9524 - val_loss: 0.1171 - val_accuracy: 0.9778\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1300 - accuracy: 0.9524 - val_loss: 0.1166 - val_accuracy: 0.9778\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1296 - accuracy: 0.9524 - val_loss: 0.1162 - val_accuracy: 0.9778\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1292 - accuracy: 0.9524 - val_loss: 0.1158 - val_accuracy: 0.9778\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1289 - accuracy: 0.9524 - val_loss: 0.1153 - val_accuracy: 0.9778\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1285 - accuracy: 0.9524 - val_loss: 0.1149 - val_accuracy: 0.9778\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1281 - accuracy: 0.9524 - val_loss: 0.1144 - val_accuracy: 0.9778\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.1278 - accuracy: 0.9524 - val_loss: 0.1140 - val_accuracy: 0.9778\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 0.1274 - accuracy: 0.9524 - val_loss: 0.1136 - val_accuracy: 0.9778\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1271 - accuracy: 0.9524 - val_loss: 0.1131 - val_accuracy: 0.9778\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1267 - accuracy: 0.9524 - val_loss: 0.1127 - val_accuracy: 0.9778\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1264 - accuracy: 0.9524 - val_loss: 0.1123 - val_accuracy: 0.9778\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1260 - accuracy: 0.9524 - val_loss: 0.1119 - val_accuracy: 0.9778\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1257 - accuracy: 0.9524 - val_loss: 0.1115 - val_accuracy: 0.9778\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1253 - accuracy: 0.9524 - val_loss: 0.1111 - val_accuracy: 0.9778\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1250 - accuracy: 0.9524 - val_loss: 0.1107 - val_accuracy: 0.9778\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1246 - accuracy: 0.9524 - val_loss: 0.1103 - val_accuracy: 0.9778\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1243 - accuracy: 0.9524 - val_loss: 0.1099 - val_accuracy: 0.9778\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1240 - accuracy: 0.9524 - val_loss: 0.1094 - val_accuracy: 0.9778\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1236 - accuracy: 0.9524 - val_loss: 0.1090 - val_accuracy: 0.9778\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1233 - accuracy: 0.9524 - val_loss: 0.1087 - val_accuracy: 0.9778\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1230 - accuracy: 0.9524 - val_loss: 0.1083 - val_accuracy: 0.9778\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1226 - accuracy: 0.9524 - val_loss: 0.1079 - val_accuracy: 0.9778\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1223 - accuracy: 0.9524 - val_loss: 0.1075 - val_accuracy: 0.9778\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1220 - accuracy: 0.9524 - val_loss: 0.1071 - val_accuracy: 0.9778\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1217 - accuracy: 0.9524 - val_loss: 0.1067 - val_accuracy: 0.9778\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1213 - accuracy: 0.9524 - val_loss: 0.1063 - val_accuracy: 0.9778\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1210 - accuracy: 0.9524 - val_loss: 0.1060 - val_accuracy: 0.9778\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1207 - accuracy: 0.9524 - val_loss: 0.1056 - val_accuracy: 0.9778\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1204 - accuracy: 0.9524 - val_loss: 0.1052 - val_accuracy: 0.9778\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1201 - accuracy: 0.9524 - val_loss: 0.1049 - val_accuracy: 0.9778\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1198 - accuracy: 0.9524 - val_loss: 0.1045 - val_accuracy: 0.9778\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1195 - accuracy: 0.9524 - val_loss: 0.1042 - val_accuracy: 0.9778\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1192 - accuracy: 0.9524 - val_loss: 0.1038 - val_accuracy: 0.9778\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1189 - accuracy: 0.9524 - val_loss: 0.1034 - val_accuracy: 0.9778\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1186 - accuracy: 0.9524 - val_loss: 0.1031 - val_accuracy: 0.9778\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1183 - accuracy: 0.9524 - val_loss: 0.1027 - val_accuracy: 0.9778\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1180 - accuracy: 0.9524 - val_loss: 0.1023 - val_accuracy: 0.9778\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1177 - accuracy: 0.9524 - val_loss: 0.1019 - val_accuracy: 0.9778\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1174 - accuracy: 0.9524 - val_loss: 0.1016 - val_accuracy: 0.9778\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1171 - accuracy: 0.9524 - val_loss: 0.1012 - val_accuracy: 0.9778\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1168 - accuracy: 0.9524 - val_loss: 0.1008 - val_accuracy: 0.9778\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1165 - accuracy: 0.9524 - val_loss: 0.1005 - val_accuracy: 0.9778\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1162 - accuracy: 0.9524 - val_loss: 0.1001 - val_accuracy: 0.9778\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1159 - accuracy: 0.9524 - val_loss: 0.0997 - val_accuracy: 0.9778\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1157 - accuracy: 0.9524 - val_loss: 0.0994 - val_accuracy: 0.9778\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1154 - accuracy: 0.9524 - val_loss: 0.0991 - val_accuracy: 0.9778\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1151 - accuracy: 0.9524 - val_loss: 0.0987 - val_accuracy: 0.9778\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1148 - accuracy: 0.9524 - val_loss: 0.0984 - val_accuracy: 0.9778\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1146 - accuracy: 0.9524 - val_loss: 0.0981 - val_accuracy: 0.9778\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1143 - accuracy: 0.9524 - val_loss: 0.0977 - val_accuracy: 0.9778\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1140 - accuracy: 0.9524 - val_loss: 0.0974 - val_accuracy: 0.9778\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1137 - accuracy: 0.9524 - val_loss: 0.0970 - val_accuracy: 0.9778\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.1135 - accuracy: 0.9524 - val_loss: 0.0967 - val_accuracy: 0.9778\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1132 - accuracy: 0.9524 - val_loss: 0.0963 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "model = Iris()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=150, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7449c1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAFzCAYAAAAt54EyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABaEUlEQVR4nO3dd3gU1f7H8ffupleSAIFA6L0FCUWCHQRBKTZQUEDkKnasV/T+VNQrXq9dBGyAXBEQKaIgAipNegklIB1CSQgB0vvu/P4YiEYgBgiZLPm8nmee3Z05s/vdjMgnhzPn2AzDMBARERERcUN2qwsQEREREblQCrMiIiIi4rYUZkVERETEbSnMioiIiIjbUpgVEREREbelMCsiIiIibkthVkRERETclsKsiIiIiLgtD6sLKGsul4sjR44QGBiIzWazuhwRERER+QvDMEhPTyciIgK7vfi+1woXZo8cOUJkZKTVZYiIiIjI3zh48CA1a9Ystk2FC7OBgYGA+cMJCgqyuBoRERER+au0tDQiIyMLc1txKlyYPT20ICgoSGFWREREpBwryZBQ3QAmIiIiIm5LYVZERERE3JbCrIiIiIi4rQo3ZlZERESkNBiGQUFBAU6n0+pS3JKnpycOh+Oi30dhVkREROQ85eXlkZCQQFZWltWluC2bzUbNmjUJCAi4qPdRmBURERE5Dy6Xi3379uFwOIiIiMDLy0sLMZ0nwzA4duwYhw4domHDhhfVQ6swKyIiInIe8vLycLlcREZG4ufnZ3U5bqtKlSrs37+f/Pz8iwqzugFMRERE5AL83TKrUrzS6s3WVRARERERt6Uwe4kVOF2M/mUXJzPzrC5FRERE5LKjMHuJvThrK28v2MljUzZS4HRZXY6IiIhIqahTpw7vv/++1WUozF5q911VB19PB8t3J/PWTzusLkdEREQqsOuuu47hw4eXynutXbuWBx54oFTe62JYGmaXLl1Kz549iYiIwGazMXv27L89Z8mSJURHR+Pj40O9evUYN27cpS/0IjSpFsTbd0YB8OnSvXwXe9jiikRERETO7vRCECVRpUqVcjGbg6VhNjMzk6ioKEaPHl2i9vv27aNHjx5cffXVbNy4kRdeeIHHH3+cGTNmXOJKL87Nrarz0HX1AfjnjM3EHUm1uCIREREpTYZhkJVXUOabYRglrnHw4MEsWbKEDz74AJvNhs1mY+LEidhsNn766Sfatm2Lt7c3y5YtY8+ePfTu3Zvw8HACAgJo164dixYtKvJ+fx1mYLPZ+Pzzz7n11lvx8/OjYcOGzJkzp7R+xOdk6Tyz3bt3p3v37iVuP27cOGrVqlX4g2vatCnr1q3j7bff5vbbb79EVZaOZ7o2ZtuRNJbsPMYDk9Yz6+EYqgb5WF2WiIiIlILsfCfNXvqpzD9326vd8PMqWZz74IMP2LlzJy1atODVV18FIC4uDoDnnnuOt99+m3r16lGpUiUOHTpEjx49eP311/Hx8eHLL7+kZ8+e7Nixg1q1ap3zM0aOHMlbb73Ff//7Xz766CMGDBjAgQMHCA0Nvfgvew5uNWZ25cqVdO3atci+bt26sW7dOvLz8896Tm5uLmlpaUU2KzjsNj686wrqVvbncEo2901cS0ZuybrxRURERC5WcHAwXl5e+Pn5Ua1aNapVq1a4WMGrr77KjTfeSP369QkLCyMqKooHH3yQli1b0rBhQ15//XXq1av3tz2tgwcP5u6776ZBgwa88cYbZGZmsmbNmkv6vdxqBbDExETCw8OL7AsPD6egoIDk5GSqV69+xjmjRo1i5MiRZVVisYL9PJl4XztuH7uCuCNpPPTVer4Y1A4vD7f6nUJERET+wtfTwbZXu1nyuaWhbdu2RV5nZmYycuRIfvjhB44cOUJBQQHZ2dnEx8cX+z6tWrUqfO7v709gYCBJSUmlUuO5uF2K+utqEafHipxrFYkRI0aQmppauB08ePCS13gGl7Pwae0wf74Y1A5fTwfLdiXz2JQN5GvKLhEREbdms9nw8/Io8620VtHy9/cv8vrZZ59lxowZ/Pvf/2bZsmXExsbSsmVL8vKKnzff09PzjJ+Ly3Vpc45bhdlq1aqRmJhYZF9SUhIeHh6EhYWd9Rxvb2+CgoKKbGXqxF74uD3sXVK4KyqyEp/cG42Xw85PcUcZPjVWc9CKiIjIJefl5YXT6fzbdsuWLWPw4MHceuuttGzZkmrVqrF///5LX+AFcKsw27FjRxYuXFhk34IFC2jbtu0ZvwmUG4v/A8d3w//6wLJ34dRvJ9c0qsIn90bj6bAxd0sCT32zCaer5HckioiIiJyvOnXqsHr1avbv309ycvI5e00bNGjAzJkziY2NZdOmTfTv3/+S97BeKEvDbEZGBrGxscTGxgLm1FuxsbGF4zFGjBjBwIEDC9sPGzaMAwcO8NRTT7F9+3bGjx/PF198wTPPPGNF+SXT831ofQ8YLvh5JEzpB2lHALi+SVXGDIjGw25jzqYjPDF1I3kF5fM/FBEREXF/zzzzDA6Hg2bNmlGlSpVzjoF97733CAkJISYmhp49e9KtWzfatGlTxtWWjM04nwnKStnixYu5/vrrz9g/aNAgJk6cyODBg9m/fz+LFy8uPLZkyRKefPJJ4uLiiIiI4J///CfDhg0r8WempaURHBxMampq2Q05MAzYMAnmPQvOXPAOhpvegNYDwGZj/tZEHv16AwUug2saVWHcPW1KPM2GiIiIlK2cnBz27dtH3bp18fHRNJsXqrif4/nkNUvDrBUsCbOnJW2H2Q/DkQ3m6/qdocd/Iaw+i3ck8dBXG8jOd9KmViXGD25HJT+vsq1PRERE/pbCbOkorTDrVmNm3V7VpnD/QugyEhzesOdn+LgDLHyJ6+r48tXQDgT7erIhPoW+n6zk0MksqysWERERKdcUZsuawwOuGg4P/Wb2zLry4bcP4KNook/+yDcPdCA8yJudRzPo8/EKYg+mWF2xiIiISLmlMGuVyg3hnhlw9zQIrQcZR2H2QzT+vjdze9loUi2Q5Ixc+n2yknlbEqyuVkRERKRcUpi1ks0GjW+Ch1fBja+CVyAc2Ujlb2/jhyofc3e9bHILXDw8eQNjF++hgg1vFhEREflbCrPlgYc3dHoCHt8Abe8HmwOPXfN5I+EBptecThip/Gf+7zz9zSZy8v9+omMRERGRikJhtjwJqAq3vGv21Dbugc1w0i55Fiv9n+Exj9nM27iXO8at4HBKttWVioiIiJQLCrPlUZVGcPcUGDwXIq7Ay5nJ0x7fsMTnaZokfk/vD5ewYk+y1VWKiIiIWE5htjyrcxUM/QVu/wKCaxHOCd72/IRJBc8xbvznfLF8n8bRioiISJmpU6cO77//vtVlFKEwW97Z7dDyDnh0Ldz4GoZ3EM3sB5jkOYr6Pw3iv5Nmkp2ncbQiIiJSMSnMugtPH+j0OLYnNmF0eAinzYPrHJt4eu/9LH3nLg7H77W6QhEREZEypzDrbvxCsXV/E8ejazheqzsOm0G33AWEjr+SPd+8ALkZVlcoIiIi5dAnn3xCjRo1cLlcRfb36tWLQYMGsWfPHnr37k14eDgBAQG0a9eORYsWWVRtySnMuquw+oQNmcqxvt/zu0dTfMml/raPyXi7JQUbvgKNpRURESk7hgF5mWW/ncff93feeSfJycn8+uuvhftOnjzJTz/9xIABA8jIyKBHjx4sWrSIjRs30q1bN3r27El8fPyl+ImVGg+rC5CLU6XZNQQ3/I1vpoyj3e4PqJt/FOY8Qt76r/Dq/T5UbWJ1iSIiIpe//Cx4I6LsP/eFI+DlX6KmoaGh3HTTTXz99dd07twZgOnTpxMaGkrnzp1xOBxERUUVtn/99deZNWsWc+bM4dFHH70k5ZcG9cxeBrw8HfQd+Ag7bl/I28Y9ZBneeB1eiWvcVfDzq5CveWlFREQEBgwYwIwZM8jNzQVg8uTJ3HXXXTgcDjIzM3nuuedo1qwZlSpVIiAggN9//109s1J2boqqTeMab/HgpOsZeHIMN7Ielr2DsXUGth7vQMMuVpcoIiJyefL0M3tJrfjc89CzZ09cLhdz586lXbt2LFu2jHfffReAZ599lp9++om3336bBg0a4Ovryx133EFeXt6lqLzUKMxeZupW9uezx27l5e8aMX3DTF7x/JKIk/th8u3Qqh/c9Cb4hVpdpoiIyOXFZivxP/dbydfXl9tuu43Jkyeze/duGjVqRHR0NADLli1j8ODB3HrrrQBkZGSwf/9+C6stGQ0zuAz5eDr4zx2t6Hr7UHq63uHzgu44scPmafBxe9j2ndUlioiIiEUGDBjA3LlzGT9+PPfcc0/h/gYNGjBz5kxiY2PZtGkT/fv3P2Pmg/JIYfYydkd0TSY/0oWvKw3j9txX2OWqAZnH4JuB5paRZHWJIiIiUsZuuOEGQkND2bFjB/379y/c/9577xESEkJMTAw9e/akW7dutGnTxsJKS8ZmVLD1UNPS0ggODiY1NZWgoCCryykTGbkFPD9jMws2x/Ooxywe8ZiDAxf4hsBN/4FWfc1/HhEREZG/lZOTw759+6hbty4+Pj5Wl+O2ivs5nk9eU89sBRDg7cFHd1/Bv3q35iOjH71yX2eXvS5kn4RZD8CUuyA90eoyRURERM6bwmwFYbPZGNixDtOHxZAS3JTuWSN519kPp90Tds6HMR0hbrbVZYqIiIicF4XZCqZ1ZCV+eOwqrm5cnQ/ze9M9+3UO+zSE7BMwfRDM+Adkp1hdpoiIiEiJKMxWQCH+XnwxqB3PdmvMbiK5LuX/+Nq7L4bNDlu+gbExsOfXv38jEREREYspzFZQdruNR65vwOShVxIc4M8LqX3o7xxJpn8tSDsM/+sD856DvCyrSxURERE5J4XZCq5j/TDmPX4VHeqGsjKvPm2Pv8LayuZkyaz5BD69FhK3WlukiIhIOVTBJoQqdaX181OYFaoG+TB5aAcevq4+2fhw56E7ea3S6zj9wyF5J3zeGdaNB/2hFRERwdPTE4CsLP3r5cU4vUyuw+G4qPfRPLNSxMJtR3lqWizpuQU0DMhhevgkKh1ebB5sfiv0/AB8gi2tUURExGoJCQmkpKRQtWpV/Pz8sGm+9vPicrk4cuQInp6e1KpV64yf3/nkNYVZOcO+5EyG/W89O46m42k3mNx8He32fITNVQAhdeCO8VAj2uoyRURELGMYBomJiaSkpFhdituy2+3UrVsXLy+vM44pzBZDYbZksvIKGDFzC9/FHgHgsUYpPJn6JvbUeLB7wo0j4cqHtXKYiIhUaE6nk/z8fKvLcEteXl7Y7Wcf8aowWwyF2ZIzDIMvV+zn9bnbKXAZtKlq439VvsJ/z1yzQaPu0GcM+IVaW6iIiIhcVrScrZQKm83G4E51mfLAlVQJ9GZDksGVuwfye5uXweENO3+ET66FQ+utLlVEREQqKIVZ+Vvt6oQy97GraF8nlPRcJ91XNuab1uMxQupCajyM7warxmm2AxERESlzCrNSIlWDfJj8jw7ce2VtDAOe+83GP8M+wtm4J7jyYf4/4ZuBkJNqdakiIiJSgSjMSol5Ouy81qcF/761BR52G99sTaP3sQdIvfZ186aw7XPMYQcJm6wuVURERCoIhVk5bwM61Gby0A6E+nux9Ug6nX9ryvYe0yA4Ek7ug89v1CILIiIiUiYUZuWCdKgXxnePdKJJtUCSM3LpNSuX2e2nQqObwJkLPzwJM/8BuRlWlyoiIiKXMYVZuWCRoX7MeCiG7i2qke80GP79AUb6/wtn55Fgc8CW6fDZ9XB0m9WlioiIyGVKYVYuir+3Bx/3b8PwLg0BmLAynkE7OpJ+92wIrA7JO+GzGyD2a2sLFRERkcuSwqxcNLvdxvAujRh3Txv8vBws353MLd852XP7fKh/AxRkw+yH4LtHIC/L6nJFRETkMqIwK6XmphbVmfFQDDVDfDlwPIte439nYZsxcP2/wGaHjV/B550hebfVpYqIiMhlQmFWSlXT6kHMefQqOtQNJTPPyQNfbWC0sw/GvbPAvyokbYNPr4Ntc6wuVURERC4DCrNS6kL9vfhq6B8LLLy9YCePrQoi+/7FUCsG8tLhm3thwf+Bs8DqckVERMSNKczKJfHXBRZ+2JxAv6/3cfTWb6Djo2ajFR/CpF6QftTaYkVERMRtKczKJTWgQ22+GtqBSn6ebD6USq+xq9nS/Dm480vwCoADv8En18CBlVaXKiIiIm5IYVYuuStPLbDQoGoAR9NyufOTFcx1doAHFkOVJpCRCBNvhpUfa9UwEREROS8Ks1Imaof5M/PhGK5tVIWcfBePfL2BD2LBGLoIWtwOhhN+egGmD4bcdKvLFRERETehMCtlJsjHky8GtWVIp7oAvLdoJ4/P3E1Or0+h+1tg94Bts81FFpJ+t7ZYERERcQsKs1KmPBx2XurZjFG3tcTDbuP7TUfo9+kqkpoOgsHzIDDij1XDts6wulwREREp5xRmxRJ3t6/F/+43bwzbdCiVXqN/Y6ujCTy4FOpcDfmZ8O0Q+PF5KMizulwREREppxRmxTId64cx++FO1K/iT2JaDneMW8GP+wrg3tlw1ZNmo9Vj4ctbIO2IpbWKiIhI+WR5mB0zZgx169bFx8eH6Oholi1bVmz7yZMnExUVhZ+fH9WrV+e+++7j+PHjZVStlLY6lf2Z9Ugnrjl1Y9hDkzfw0eJ9GJ1fhru+Bu8gOLjanL5r31KryxUREZFyxtIwO23aNIYPH86LL77Ixo0bufrqq+nevTvx8fFnbb98+XIGDhzI/fffT1xcHNOnT2ft2rUMHTq0jCuX0hTk48n4QW25r1MdAN5ZuJPHp8aSU/8mc/qu8BaQeQwm9Ybl72n6LhERESlkMwzrkkGHDh1o06YNY8eOLdzXtGlT+vTpw6hRo85o//bbbzN27Fj27NlTuO+jjz7irbfe4uDBgyX6zLS0NIKDg0lNTSUoKOjiv4SUqq9Xx/PSd1spcBm0qhnMZwPbEu7jgh+ehM1TzUZNboFbx4F3oLXFioiIyCVxPnnNsp7ZvLw81q9fT9euXYvs79q1KytWrDjrOTExMRw6dIh58+ZhGAZHjx7l22+/5eabbz7n5+Tm5pKWllZkk/Krf4c/bgzbfCiVXqOXs+lonhleb3kPHF7w+w8w/iZIPWR1uSIiImIxy8JscnIyTqeT8PDwIvvDw8NJTEw86zkxMTFMnjyZfv364eXlRbVq1ahUqRIfffTROT9n1KhRBAcHF26RkZGl+j2k9HWsH8acR66iUbi5YljfT1YyZ3MCtB1iTt/lXwWObjWn7zq83upyRURExEKW3wBms9mKvDYM44x9p23bto3HH3+cl156ifXr1zN//nz27dvHsGHDzvn+I0aMIDU1tXAr6XAEsVatMD9mPBRD5yZVyS1w8fiUjby7YAdGzbbwj1+gajPIOAoTbobf51ldroiIiFjEsjBbuXJlHA7HGb2wSUlJZ/TWnjZq1Cg6derEs88+S6tWrejWrRtjxoxh/PjxJCQknPUcb29vgoKCimziHgJ9PPl0YFsevLYeAB/+spunv9lEXkBNGPITNLgRCrJh2j2w5VuLqxURERErWBZmvby8iI6OZuHChUX2L1y4kJiYmLOek5WVhd1etGSHwwGYPbpy+XHYbYzo3pS3bm+Fw25j5sbD3DdxDWn4wt1TIepuMJwwYyis/9LqckVERKSMWTrM4KmnnuLzzz9n/PjxbN++nSeffJL4+PjCYQMjRoxg4MCBhe179uzJzJkzGTt2LHv37uW3337j8ccfp3379kRERFj1NaQM9G0XyfjB7fD3cvDb7uP0HbeShIx86D0G2t4PGPD947Bq7N++l4iIiFw+PKz88H79+nH8+HFeffVVEhISaNGiBfPmzaN27doAJCQkFJlzdvDgwaSnpzN69GiefvppKlWqxA033MB//vMfq76ClKFrG1Vh2oMdGTJxLb8npnPrxyuYcF87mt78Dnj5w4oPYf7zZuMrH7K2WBERESkTls4zawXNM+v+Dp3MYvCEtexOyiDQ24NPBkYTUy8Mfv03LP2v2aj7f6HDA9YWKiIiIhfELeaZFblQNUP8mDEshg51Q0nPLWDwhLX8uuMYXP8iXPWU2ejHZ2Ht59YWKiIiIpecwqy4pWA/Tybd354bm4WTV+Digf+t48etidD5Jej0hNlo7tOwboK1hYqIiMglpTArbsvbw8GYAW3oGRVBvtPgka83MHPjYegyEjo+ajb6YThsmGRpnSIiInLpWHoDmMjF8nTYeb9fa3w87Exff4inp28iO9/JgK6vg8sJq8fCnMfB5oArBlhdroiIiJQyhVlxew67jf/c3go/LwdfrjzAi7O2YrfZuPumUeYctGs+he8eAbsHRPWzulwREREpRQqzclmw22280qs5ng47ny/fxwuztuDjaefW7m+ZPbTrvoDZD4FvJWjUzepyRUREpJRozKxcNmw2Gy/e3JR7r6yNYcDT32xi3tZE6PE2tLrL7KX9ZhAcXGN1qSIiIlJKFGblsmKz2RjZqzl929bEZcDjUzby845j0Hs0NLgRCrJh8p2Q9LvVpYqIiEgpUJiVy47dbmPUba3oFRVBgcvgoa82sHxvKvT9Emq0hZwU+Oo2SD1kdakiIiJykRRm5bLksNt4p28U3ZqHk+d08eD/1rE5KR8GTIfKjSDtMPzvNsg6YXWpIiIichEUZuWy5emw8+HdV9CpQRiZeU7um7CWfVnecM9MCIyA5B3wdV/Iy7S6VBEREblACrNyWfP2cDDunmha1AjieGYeA8evJslRBe6dCT6V4NBamD4YnPlWlyoiIiIXQGFWLnuBPp5MGNye2mF+HDyRzaDxa0kLagD9vwEPX9i1AOY8BoZhdakiIiJynhRmpUKoEujNpCHtqRzgxfaENB6YtI6c6m3hzonm6mCbpsCil60uU0RERM6TwqxUGLXD/Jl4X3sCvD1YtfcET06LxdmwG/T6yGzw2wewYrS1RYqIiMh5UZiVCqVFjWA+vTcaL4edH7cm8tJ3WzFa94cur5gNFrwIm6ZZWqOIiIiUnMKsVDgxDSrz/l2tsdlg8up43l+0CzoNhysfMRvMfgjiZllao4iIiJSMwqxUSD1aVufV3i0A+ODnXUxYsR+6vg6tB5jL3n57P2z7ztoiRURE5G8pzEqFde+VtRnepSEAI7/fxqTV8eb42ai7TwXaIbD9e4urFBERkeIozEqF9kTnhgy7tj4AL30Xx1drDkHvj6FVP3AVmHPQ/j7P2iJFRETknBRmpUKz2Wz886bGPHBNPQD+NXsrX689DH3GQos7zED7zUD4fa7FlYqIiMjZKMxKhWez2RjRvQn3X1UXgBdmbWHa+sNw6yfQ/DZw5ZuBVjeFiYiIlDseVhcgUh7YbDb+dXNTXIbBhN/28/zMLdhsNvre9hnYPWDLN+YY2oI8iOpndbkiIiJyisKsyCk2m42XbmmGYcDEFfv554zN2G027rh1HHh4wcavYNaD4MyFNgOtLldERERQmBUpwmaz8XLPZjhdBv9bdYBnv92Eww639vwIHN6w7guY8xgU5EL7f1hdroiISIWnMCvyFzabjZG9muM0DL5eHc/T32zCbrPR++Z3wMMHVn0M854BZx50fMTqckVERCo0hVmRs7DbbbzeuwUul8HUtQd5closdpuNnt3+DR7esPxd+OkFyM+Ga56xulwREZEKS2FW5Bzsdhtv3NoSl2HwzbpDDD8VaG/u/BJ4+sKv/4ZfXjOHHFz/AthsVpcsIiJS4WhqLpFi2O023rytFXdE18TpMnh86kZ+3JoI1z4HXUaajZa+BYteBsOwtlgREZEKSGFW5G/Y7Tb+c3srbruiBk6XwWNTNjJ/ayJcNRxu+o/Z6LcPYP7zCrQiIiJlTGFWpAQcdhv/vTOKPq0jKHAZPPr1BhbEJcKVw+CW9wEbrB4HPzwJLpfV5YqIiFQYCrMiJeSw23j7zih6RpmB9pGvN7Bo21Foex/0GQM2O6yfAN89Ai6n1eWKiIhUCAqzIufBw2Hnvb5R3NyqOvlOg4cnb+DX35OgdX+47TOwOWDT1zDzH+DMt7pcERGRy57CrMh58nDYeb9fa3q0rEae08WD/1vP4h1J0PIO6Psl2D1h6wyYPthc/lZEREQuGYVZkQvg6bDzwV1XcFNzM9A+8L/1LN15DJr2hLsmm6uF/f4DTLsH8nOsLldEROSypTArcoE8HXY+vPsKbmwWTl6Bi39MWsfyXcnQqBv0nwoevrDrJ5hyF+RlWV2uiIjIZUlhVuQieHnY+bh/G7o0rUpugYv7v1zLit3JUP8GuOdb8PSHvb/C5DshN93qckVERC47CrMiF8nLw87HA9pwQxMz0A75ci0r9xyHOlfBvbPAOwgOLIdJfSDrhNXlioiIXFYUZkVKgbeHgzED2nBtoyrk5LsYMvFUoK3VAQZ+B74hcHgdfNkTMpKsLldEROSyoTArUkp8PB18cm801zSqQna+849AW6MNDJ4HAeFwdCtM6A4pB60uV0RE5LKgMCtSinw8HXx6bzTXngq0901cw4o9yRDeDO77EYJrwfHdZqA9vsfqckVERNyewqxIKTvdQ3td4z+GHKzYnQxh9WHIjxDWAFIPwvib4Gic1eWKiIi4NYVZkUvAx9PBuHv+FGi/XMtvu5MhuCbcNx/CW0JmEky8GQ6vt7pcERERt6UwK3KJnA60158KtPefDrQBVWDw91CzHWSfhC97wf7lVpcrIiLilhRmRS4hH08H4+79I9AOmXgq0PqGwL2zoe41kJcBX90OuxZaXa6IiIjbUZgVucS8PcxAWzgP7cS15kph3gHQfzo0ugkKcmDK3RA3y+pyRURE3IrCrEgZ8PZwMPaeNnRu8sdKYct2HQNPH+j3FTS/DVz58O0Q2DjZ6nJFRETchsKsSBnx9nAw5k+BduiX61i68xg4POH2z6HNQDBc8N3DsPoTq8sVERFxCwqzImXodKDt0tQMtP+YdCrQ2h3Q80O48hGz4Y/PwdL/gmFYW7CIiEg5Z3mYHTNmDHXr1sXHx4fo6GiWLVtWbPvc3FxefPFFateujbe3N/Xr12f8+PFlVK3IxfP2cPDxgD8C7dBJ6/j19ySw2aDbv+Ha582Gv7wOC/6lQCsiIlIMS8PstGnTGD58OC+++CIbN27k6quvpnv37sTHx5/znL59+/Lzzz/zxRdfsGPHDqZMmUKTJk3KsGqRi+ft4WDMgGhubBZOXoGLB/63jp/iEs1Ae/0I6PaG2XDlaJjzKDgLrC1YRESknLIZhnXdPh06dKBNmzaMHTu2cF/Tpk3p06cPo0aNOqP9/Pnzueuuu9i7dy+hoaEX9JlpaWkEBweTmppKUFDQBdcuUhrynS6GT41l7pYEHHYb7/drTc+oCPPgxq9gzmPmONqmPeH2L8DD29qCRUREysD55DXLembz8vJYv349Xbt2LbK/a9eurFix4qznzJkzh7Zt2/LWW29Ro0YNGjVqxDPPPEN2dnZZlCxS6jwddj64qzW3XVEDp8vgiakb+Xb9IfPgFfdA30ng8ILt38PXfSE3w9qCRUREyhkPqz44OTkZp9NJeHh4kf3h4eEkJiae9Zy9e/eyfPlyfHx8mDVrFsnJyTz88MOcOHHinONmc3Nzyc3NLXydlpZWel9CpBR4OOy8fWcUXh52pq49yDPTN5FX4KJ/h1pmj+yA6TClP+xdDJN6m6/9LuxfJkRERC43lt8AZrPZirw2DOOMfae5XC5sNhuTJ0+mffv29OjRg3fffZeJEyees3d21KhRBAcHF26RkZGl/h1ELpbdbuONW1syqGNtAF6YtYUJv+0zD9a7DgbNAZ9KcHgdTLwZ0s/+C5+IiEhFY1mYrVy5Mg6H44xe2KSkpDN6a0+rXr06NWrUIDg4uHBf06ZNMQyDQ4cOnfWcESNGkJqaWrgdPHiw9L6ESCmy22280qs5D15TD4CR329j7OI95sGabeG+HyGgGiRtgy+6wom9FlYrIiJSPlgWZr28vIiOjmbhwqLr0S9cuJCYmJizntOpUyeOHDlCRsYf4wZ37tyJ3W6nZs2aZz3H29uboKCgIptIeWWz2Xi+exMe79wQgP/M/533F+3EMAwIbwb3/wQhdSDlAIy/CY7GWVuwiIiIxS4ozH755ZfMnTu38PVzzz1HpUqViImJ4cCBAyV+n6eeeorPP/+c8ePHs337dp588kni4+MZNmwYYPaqDhw4sLB9//79CQsL47777mPbtm0sXbqUZ599liFDhuDr63shX0Wk3LHZbDx1YyOe7dYYgPcX7eI/83eYgTakDgz5Cao2h4yjMKEHHFxrbcEiIiIWuqAw+8YbbxSGx5UrVzJ69GjeeustKleuzJNPPlni9+nXrx/vv/8+r776Kq1bt2bp0qXMmzeP2rXNcYMJCQlF5pwNCAhg4cKFpKSk0LZtWwYMGEDPnj358MMPL+RriJRrj1zfgP+7pRkA45bsYeT328xAG1gN7psLNdtDTgpM6gV7frG2WBEREYtc0Dyzfn5+/P7779SqVYt//vOfJCQkMGnSJOLi4rjuuus4duzYpai1VGieWXE3X606wL9mbwWgX9tI3ritJQ67DfIyYdo9ZpC1e8IdX0Cz3hZXKyIicvEu+TyzAQEBHD9+HIAFCxbQpUsXAHx8fDTnq0gpu+fK2rx9ZxR2G0xbd5DHp2wkr8AFXv5w91Ro1gdc+TB9MGz4n9XlioiIlKkLmmf2xhtvZOjQoVxxxRXs3LmTm2++GYC4uDjq1KlTmvWJCHBHdE0CvB08NmUjc7ckkJFbwLh7ovH18oY7xsMPQbBhkrn0bU4KxDxmdckiIiJl4oJ6Zj/++GM6duzIsWPHmDFjBmFhYQCsX7+eu+++u1QLFBHTTS2q88Wgdvh6Oliy8xgDx68mLScf7A7o+SHEPG42XPAv+PlVsG6lahERkTJzQWNm3ZnGzIq7W3/gBIMnrCU9p4DmEUFMGtKesABv8+Cyd+HnkebztvdDj7fBbvnaKCIiIuflko+ZnT9/PsuXLy98/fHHH9O6dWv69+/PyZMnL+QtRaSEomuHMvWBK6kc4EXckTT6frKShNRTY9WvfgpueQ+wwbovYMYQKMgt9v1ERETc2QWF2WeffZa0tDQAtmzZwtNPP02PHj3Yu3cvTz31VKkWKCJnah4RzDcPdiQi2Ic9xzK5Y+xK9iVnmgfbDjFnNrB7QNws+Op2yE6xtF4REZFL5YLC7L59+2jWzJz/csaMGdxyyy288cYbjBkzhh9//LFUCxSRs6tXJYDpD8VQr7I/h1OyuXPcSrYnmL9k0uJ2GDAdvAJh/zKY0B1SD1tbsIiIyCVwQWHWy8uLrKwsABYtWkTXrl0BCA0NLeyxFZFLr0YlX6Y92JGm1YNIzsil3ycrWX/ghHmw/g1w3zwICIekbfDFjZC03dqCRUREStkFhdmrrrqKp556itdee401a9YUTs21c+dOatasWaoFikjxqgR6M/WBK4muHUJaTgEDPl/Nom1HzYPVW8H9CyGsIaQdhvHdYP9v1hYsIiJSii4ozI4ePRoPDw++/fZbxo4dS40aNQD48ccfuemmm0q1QBH5e8G+nnx1fwduaFKVnHwXD361nmlrTy0FHVIb7l8AkR0gJxX+1wfiZltZroiISKnR1Fwil5F8p4sXZm5h+vpDADzTtRGPXN8Am80G+dkwYyj8/gNgg5vehCuHWVuwiIjIWZxPXrvgMOt0Opk9ezbbt2/HZrPRtGlTevfujcPhuKCiy4rCrFzuDMPgvz/tYMziPQAM7Fibl3s2x2G3gcsJPz4Haz83G8c8Dl1Gai5aEREpV84nr13Qcra7d++mR48eHD58mMaNG2MYBjt37iQyMpK5c+dSv379CypcRC6ezWbjuZuaUDXQm5E/bGPSygMkZ+Tybt/W+Hg6zIUUgiLMVcJWfAjpCdB7DHh4WV26iIjIebugntkePXpgGAaTJ08mNDQUgOPHj3PPPfdgt9uZO3duqRdaWtQzKxXJD5uP8OS0WPKdBlfWC+XTgW0J8vE0D8Z+DXMeA1cB1L0G+v4PfCtZWq+IiAiUwTADf39/Vq1aRcuWLYvs37RpE506dSIjI+N837LMKMxKRbNidzIP/G89GbkFNKkWyJdD2hMe5GMe3P0zfDMQ8jKgcmMY8A2E1LG0XhERkUu+nK23tzfp6eln7M/IyMDLS/9UKVKexDSofGr5W29+T0zntjEr2HPs1C+cDTrDfT9CYAQk74DPu8ChddYWLCIich4uKMzecsstPPDAA6xevRrDMDAMg1WrVjFs2DB69epV2jWKyEVqUSOYmQ/FUCfMj8Mp2dw2ZgWr9x43D1ZvBUMXQbWWkHkMJt4M2+ZYW7CIiEgJXVCY/fDDD6lfvz4dO3bEx8cHHx8fYmJiaNCgAe+//34plygipaFWmB/fPhRD68hKpGbnc+8Xa/gu9tQSt8E1zB7ahl2hIMccevDbh1CxZu4TERE3dFHzzO7evZvt27djGAbNmjWjQYMGpVnbJaExs1LR5eQ7GT41lvlxiQA8260xD19X35yL1lkA85+HtZ+ZjaPvM2c/cFzQxCciIiIX5JLcAPbUU0+VuIB33323xG3LmsKsCDhdBqPmbefz5fsAuKtdJK/1aYGnw272xq4aCz+9ABjQoAvcMQF89OdFRETKxiWZZ3bjxo0lamez2Ur6liJiEYfdxr9uaUZkqB8jv49j6tqDHE7JZsyANgT6eELHh6FSLXPFsN2LYEJ36D8NgmtaXbqIiEgRWs5WpIJbtO0oj03ZSHa+kybVAplwXzuqB/uaBw9vgCl3QcZRCAiHu76Gmm2tLVhERC57l3xqLhG5fHRpFs43D3akSqA5dVefj39j6+FU82CNNuZMB1WbmYF2Qg+InWJtwSIiIn+iMCsitKwZzKyHY2hYNYCjabncMW4F87YkmAcr1YL7F0Djm8GZC7OHwYJ/gctpbdEiIiIozIrIKTVD/JjxcAzXNqpCTr6Lhydv4INFuzAMA7wDod9XcM2zZuMVH8HXfSE7xdKaRUREFGZFpFCQjydfDGrLkE51AXhv0U4enbKR7Dwn2O1ww7/gjvHg4WveGPZ5F0jebXHVIiJSkSnMikgRHg47L/Vsxpu3tcTTYWPu5gT6fbqSxNQcs0GL22HIfAiqAcd3wWc3wK5F1hYtIiIVlsKsiJzVXe1r8dX9HQjx82TzoVR6jV7OpoMp5sGI1vDAYojsALmpMPkOWPJfcLksrFhERCoihVkROacO9cKY8+hVNAoPICk9l76frGTOpiPmwYCqMOh7iB4MGPDr6zD1bo2jFRGRMqUwKyLFigz1Y8ZDMdzQpCq5BS4en7KRUT9up8DpAg9v6PkB9BoNDm/YOR8+vQ4St1pdtoiIVBAKsyLytwJ9PPlsYFsevKYeAJ8s2cvgCWs5kZlnNmhzL9z/EwTXgpP7zBvDNn9jYcUiIlJRKMyKSIk47DZG9GjKR3dfga+ng+W7k+n50fI/FliIuAIeXAL1O0NBNsz8B8x7DgryrC1cREQuawqzInJeekZFMPuRTtQJ8+NwSja3j13BjPWHzIN+oTBgOlzznPl6zSfw5S2QdsS6gkVE5LKmMCsi561xtUC+e/SqwnG0T0/fxEvfbSWvwAV2B9zwItw9FbyD4eBqGHeVOS+tiIhIKVOYFZELEuzryecD2/JE54YATFp5gP6frSIhNdts0Lg7PPArhLeErOPw1e2waCQ4CyysWkRELjcKsyJywex2G0/e2IjPB7Yl0NuDdQdOcvOHy1my85jZIKw+DF0Ebe83Xy9/1xx2kHrYuqJFROSyojArIhetS7Nwvn/sKppHBHEiM4/BE9bw9k87zOm7PH3glnfhjgngFQjxK81hBzsXWF22iIhcBhRmRaRU1Knsz4yHYrjnyloYBoz+dTcDPl9NUtrpZXBvM2c7qB4F2Sfg6zthwf+BM9/awkVExK0pzIpIqfHxdPB6n5Z8ePcV+Hs5WL3vBD0+XMZvu5PNBmH14f6F0P4B8/WKD2FCD0iJt65oERFxawqzIlLqekVFMOexq2hSLZDkjDzu+WI17y/aidNlmKuG9fgv9J1kznZwaA2MvQq2fGt12SIi4oYUZkXkkqhfJYDZj3TirnaRGAa8v2gX936xmsTUU8MOmvU2hx3UbAe5qTDjfpg1DHLSrC1cRETcisKsiFwyPp4O3ry9Fe/1i8LX08GKPce56YOl/BSXaDYIrQv3/QjX/hNsdtg0BT65Gg6usbZwERFxGwqzInLJ3XpFTX54/Cpa1AgiJSufB/+3nhEzt5CVVwAOT7j+BTPUBteCk/th/E2w+D+ak1ZERP6WwqyIlIn6VQKY+VAnHry2HgBT1sTT86PlbD2cajaodSU8tBxa9gXDCYvfgIk9zHArIiJyDgqzIlJmvDzsjOjelMlDOxAe5M2eY5ncOuY3Plu6F5fLAJ9guP0zuO0z8A4yl8IdexVs/AoMw+ryRUSkHLIZRsX6GyItLY3g4GBSU1MJCgqyuhyRCutkZh7/nLGZBduOAhBTP4y37mhFzRC/Uw32w8wHzEAL0LAr9PwAgiKsKVhERMrM+eQ19cyKiCVC/L345N5o/n1rC3w87ebNYe8v45u1BzEMA0LqwOB50GUkOLxh1wL4+Er10oqISBHqmRURy+1LzuSZ6ZtYf+AkANc3rsKbt7ciPMjHbHBsB8x+CA6vN1+rl1ZE5LKmnlkRcSt1K/vzzYMdGdG9CV4OO7/uOEbX95byXexhs5e2SmMYsuAvvbQdYO3n4HJZXb6IiFhIPbMiUq7sPJrO099sYsupWQ66t6jGa31aUDnA22xwbAfMfhgOrzNfR3aAW96H8GbWFCwiIqXOrXpmx4wZQ926dfHx8SE6Opply5aV6LzffvsNDw8PWrdufWkLFJEy1Sg8kJkPx/Bkl0Z42G38uDWRLu8uYfq6g3/00t6/ALq/BV4B5g1in1wNP78K+dlWly8iImXM0jA7bdo0hg8fzosvvsjGjRu5+uqr6d69O/Hx8cWel5qaysCBA+ncuXMZVSoiZcnTYeeJLg2Z/UgnmlU3F1p49tvN3PPFag4czwS7Azo8CI+shsY3g6sAlr0DY2Ng7xKryxcRkTJk6TCDDh060KZNG8aOHVu4r2nTpvTp04dRo0ad87y77rqLhg0b4nA4mD17NrGxsSX+TA0zEHEv+U4XXyzfx3sLd5Jb4MLH087wLo0YelVdPBynfh/f/j3MexbSE8zXUf2h6+vgH2Zd4SIicsHcYphBXl4e69evp2vXrkX2d+3alRUrVpzzvAkTJrBnzx5efvnlEn1Obm4uaWlpRTYRcR+eDjvDrq3PT8OvIaZ+GDn5Lt788Xd6f/wbWw6dWj2saU+zl7bdUMAGm76G0W0hdoqm8RIRucxZFmaTk5NxOp2Eh4cX2R8eHk5iYuJZz9m1axfPP/88kydPxsPDo0SfM2rUKIKDgwu3yMjIi65dRMpencr+TB7agf/e0YpgX0/ijqTR++PlvPzdVlKz883Vw25+xxxPW7UZZJ+A2cNgQg84Gmd1+SIicolYfgOYzWYr8towjDP2ATidTvr378/IkSNp1KhRid9/xIgRpKamFm4HDx686JpFxBo2m40720ay6Klr6RkVgcuAL1ce4Ia3FzN93UFzSdzI9vDgUuj8Enj4QvwKGHc1zH8BcvQvMyIilxvLxszm5eXh5+fH9OnTufXWWwv3P/HEE8TGxrJkSdGbOFJSUggJCcHhcBTuc7lcGIaBw+FgwYIF3HDDDX/7uRozK3L5+G13Mi/PiWN3UgYAbWpV4tXeLWhRI9hskBIPP71gjqkFCAg3x9K2vBPO8kuziIiUD24xZtbLy4vo6GgWLlxYZP/ChQuJiYk5o31QUBBbtmwhNja2cBs2bBiNGzcmNjaWDh06lFXpIlJOdGpQmXmPX82I7k3w83KwIT6FXqOX89J3W0nNyodKtaDfV3DPDAitDxlHYeY/YOLNcHSb1eWLiEgpsHQ2g2nTpnHvvfcybtw4OnbsyKeffspnn31GXFwctWvXZsSIERw+fJhJkyad9fxXXnlFsxmICAAJqdn8e+52fthszmgQ5u/FP7s34Y42NbHbbVCQCys+gqVvQ0E22BzQYRhc+xz4VrK2eBERKcItemYB+vXrx/vvv8+rr75K69atWbp0KfPmzaN27doAJCQk/O2csyIiANWDfRndvw1fD+1Ag6oBHM/M47lvN9Pr4+Ws3nscPLzhmmfg0TXm7AeGE1Z9DB+1gXXjweW0+iuIiMgF0HK2InLZyStwMXHFPj76eTfpuQUA3NS8GiN6NKF2mL/ZaPci86aw5B3m6/AWcNMoqHuNRVWLiMhp55PXFGZF5LJ1PCOX9xbt5OvV8bgM8HTYGBxTh0dvaEiwryc4881e2V/fgJwU86Qmt5g3iYXWtbR2EZGKTGG2GAqzIhXPzqPpvD53O0t3HgMg1N+LJ7s05O72tcxVxLJOwOJRsPYLc/iBwwuufBiufhp89P8JEZGypjBbDIVZkYrr1x1J/Hvu9sKpvBpUDeDZbo3p2izcnN86abs5ldeeX8wT/KtC5/+D1gPA7ijmnUVEpDQpzBZDYVakYitwupiyJp53F+7kZFY+YM5P+8+bmtChXpi5/O3On8xQe2KPeVLVZtBlJDS8UfPTioiUAYXZYijMighAWk4+ny7Zy+fL95KT7wLghiZVee6mxjSpFgQFebD2M1jy1h/jaetcDTe+CjXaWFe4iEgFoDBbDIVZEfmzpLQcPvh5F1PXHsTpMrDZ4NbWNXjyxkZEhvpB9klY9i6s/gScueZJLe4whx+E1LG0dhGRy5XCbDEUZkXkbPYlZ/L2gh3MPbXogpfDTv8OtXj4uvpUDfIxl8b95d+weap5gsML2v3DnLvWL9TCykVELj8Ks8VQmBWR4mw+lMJ/5v/Ob7uPA+DtYeeeK2sz7Nr6VAn0hoRNsOD/YN8S8wTvIHPmgysf0kpiIiKlRGG2GAqzIlISy3cl8+7CHWyITwHAx9POwI51eOCaelT294I9P8PCV+DoFvMEn2Do+Bh0eFDTeYmIXCSF2WIozIpISRmGwdJdyby3cCexB1MA8PV0MDCmNg9eU59QXw/YPseco/bY7+ZJviEQ8zi0fwC8A6wrXkTEjSnMFkNhVkTOl2EYLN5xjPcW7WTzoVQA/LwcDI6pwz+urkeIrwPiZsHiN+H4LvMkvzDoNBzaDQUvP+uKFxFxQwqzxVCYFZELZRgGv/yexHuLdrL1cBpghtoBHWox9Op6hAd4wpbpZqg9uc88yb8KdHoC2g4BL38LqxcRcR8Ks8VQmBWRi2UYBgu3HeX9RbvYlmCGWi+HnTva1mTYNfWpVcnLnPVgyX/MWRDADLUxj0O7+xVqRUT+hsJsMRRmRaS0GIbB4p3H+PiX3aw7cBIAuw16RkXw0HX1aVLFFzZNhaX/hZQD5kl+lc2eWoVaEZFzUpgthsKsiFwKa/ad4ONfd7Nk57HCfV2aVuXh6xvQpkYAbJ5mhtqT+82DfpWh0+OnxtQq1IqI/JnCbDEUZkXkUtp6OJWxi/cwb2sCp//v2qFuKA9cU4/rG4Rg3zr9VKg9NabWL+zU8IOhmv1AROQUhdliKMyKSFnYcyyDT5bsYeaGwxS4zP/N1qviz9Cr6nFb63B8ts+AJW/9JdQ+Zq4qplArIhWcwmwxFGZFpCwlpGYz8bf9fL06nvTcAgBC/b2458raDOxQg8p758DSt+DEXvME39BToXaoFl8QkQpLYbYYCrMiYoWM3AKmrT3I+OX7OJySDYCXh53brqjB0E6RNEicbw4/OLHHPME7CNreBx0egqDqFlYuIlL2FGaLoTArIlYqcLqYH5fIZ8v2senUqmIA1zWuwuAra3JN7hLsy9+D5B3mAbsntOpr9tZWbWpN0SIiZUxhthgKsyJSHhiGwboDJ/ls6V4Wbj9aeLNYnTA/7r2yFneHbMdvzccQv+KPkxp2M6f1qh0DNps1hYuIlAGF2WIozIpIebM/OZNJKw8wff1B0nPMcbV+Xg5ua1ODB+oep9bvn8P2H4BT/7uuEW3OgNC0J9gd1hUuInKJKMwWQ2FWRMqrzNwCZm08zKSV+9l5NKNwf0z9MIa1MLjq2FTsm6aAM9c8EFwL2v8D2twLviEWVS0iUvoUZouhMCsi5Z1hGKzce5xJKw6wYFsirtMdspV8uf8Kf/oZ8/HfNAGyzVXH8PSDqLugwzCo0ti6wkVESonCbDEUZkXEnRxOyWbyqgNMXXuQE5l5AHjYbdzctBKPVN5Aw32TsSVt++OE+jeYobbBjWC3W1S1iMjFUZgthsKsiLijnHwn3286wtdr4tkYn1K4v1aIL081Okr3zO/w3j2fwnG1ofWg/YPQur/mqxURt6MwWwyFWRFxd9uOpDF1bTyzNhwuXIjBw27j7kYuHvT5mRr7vsWWm2Y29gqE1nebizBoCIKIuAmF2WIozIrI5SIrr4C5mxPO6K1tFAIv1thEp+Mz8Di5+48T6lxthtomN4PDs+wLFhEpIYXZYijMisjlaHtCGlPXxDNz4+HC6b0cNhfDIg9yr2MR4Ym/YjNcZuOAahA9GKIHQVCEdUWLiJyDwmwxFGZF5HKWnefkh81H+GbdQdbuP1m4v7FPCiPCV9MpdS6eOcnmTpvD7KVtNxTqXqOFGESk3FCYLYbCrIhUFPuSM5mx/hAzNhwiITUHAE8KuC9kM/d5/Uz11I1/NA6tD20GQusBEFDFoopFREwKs8VQmBWRisbpMlixJ5lv1x9i/tZEcgvM4QZNHQd5LnQ5V2f/jEdBltnY7gGNe5hDEOrdoOm9RMQSCrPFUJgVkYosNTufuZsT+Hb9QTacumnMn2xu91rN/X7LqJ2z/Y/GwbXM1cVaD4DgGtYULCIVksJsMRRmRURMu5MymLnhEHM2HeHQyWwAmtjiuc9nCb3sy/F1ppsNbXZo2BXaDDIfHR4WVi0iFYHCbDEUZkVEijIMg/UHTjI79jBzNydwMisfb/LoYV/NYJ8lRLn+tMKYf1Vo1Rei7oZqLawrWkQuawqzxVCYFRE5t3yni2W7jjF74xEWbjtKdr6T+rbD9HMspp/nMoKNtD8ah7c0F2RoeScEVLWsZhG5/CjMFkNhVkSkZDJzC1i47SjfxR5m6a5k7K58rrPHcptjGV0cG/HEnM8WmwMadIGou8ybxzx9rC1cRNyewmwxFGZFRM7f8Yxc5m1J4IfNCazZf4JgI51bHKu4w7GU1vY9fzT0DoYWt0JUf4hsr7lrReSCKMwWQ2FWROTiJKXn8NPWROZuSWD1vhPU4zC3OZZxq2M5EbYTfzQMrQet7oKWd0BYfesKFhG3ozBbDIVZEZHS8+dgu3ZfMu1t27nDsZSb7Gvwt+UWtjOqt8bW8g5ofpum+RKRv6UwWwyFWRGRS+NYei7z4xKZtzmBLfsO09W2hj6O34ixx+FhcxW2M2p1NINtsz7gX9m6gkWk3FKYLYbCrIjIpXcsPZeftx9lwbajbNu9hy7GKno5VtDevqOwjcvmwKh7LY5Wd0KTm8En2MKKRaQ8UZgthsKsiEjZysgtYOnOYyyISyTu921cl7+cno6VtLLvK2zjtHvirHs9Xi36QOPu4BdqXcEiYjmF2WIozIqIWCff6WLNvhMsiEtk+9aNdMhaTC/HShraDxe2cdocZEfE4Bd1K/amt0BguIUVi4gVFGaLoTArIlI+GIbB1sNpLIxLYMfWtTQ58Ss3OdbS1B5f2MaFjZTK0fhF3YpPi54QUtvCikWkrCjMFkNhVkSkfEpIzWbxjmNs3bKB0AM/0ZnVReewBY77N8TWpAchbfpgi7hC89iKXKYUZouhMCsiUv7lFjhZs+8E6zdvxWPHD0Rnr6Cd/fcisyKkelTmZGRnwqJvJbDJDeDhbWHFIlKaFGaLoTArIuJ+9iVnsmLzTtK3zqNO8mKutm0qMo9tls2XgyEdsTe9hdpX9sErMMzCakXkYinMFkNhVkTEvWXlFbB2dwKHNy4g6MAC2uWuItyWUni8wLCzy6clabW6EN7+Nmo3aI5NwxFE3IrCbDEUZkVELi+JKVnErV+Cc9sP1D2+lIbEFzm+21aLvaHXQOPuNLriWmpXDlC4FSnn3CrMjhkzhv/+978kJCTQvHlz3n//fa6++uqztp05cyZjx44lNjaW3NxcmjdvziuvvEK3bt1K/HkKsyIily+Xy2DPzq0cWzeLSgcX0ShnS5FxtseNQNY6riC52jUENO9GdNMG1AzxVbgVKWfcJsxOmzaNe++9lzFjxtCpUyc++eQTPv/8c7Zt20atWrXOaD98+HAiIiK4/vrrqVSpEhMmTODtt99m9erVXHHFFSX6TIVZEZGKIyctmfjVs+H3udQ8sQo/I6vwmMuwsdmox3rPtmREXk9E8450bFCVmiF+1hUsIoAbhdkOHTrQpk0bxo4dW7ivadOm9OnTh1GjRpXoPZo3b06/fv146aWXStReYVZEpIJy5pO7dyVJG3/Ae//PVM3aXeTwCSOApa5WxPlEU1D7Gho2bELbOiE0qBKA3a6eW5GydD55zaOMajpDXl4e69ev5/nnny+yv2vXrqxYsaJE7+FyuUhPTyc09NzLHubm5pKb+8cdr2lpaRdWsIiIuDeHJ94NryGy4TXm67Qj5P6+gLQt8wg6spxQZwZ9HCvok78Cdn/E7p0RLHO1ZLRHFM5anWherybt6oTSskYwPp4Oa7+LiBSyLMwmJyfjdDoJDy+6TGF4eDiJiYkleo933nmHzMxM+vbte842o0aNYuTIkRdVq4iIXIaCIvBuP5gq7QeDMx8OrSVvx0JydvxMwPEtNLAfoYH9CPfxEwUH7MTub8ByVwvepRXOiGiuqFuFtrVDia4dQqi/l9XfRqTCsizMnvbXQfeGYZRoIP6UKVN45ZVX+O6776hateo5240YMYKnnnqq8HVaWhqRkZEXXrCIiFx+HJ5QOwav2jF4dX0Zsk/CvmU49/xCwa5f8U7bT1vbTtradwIzyTjqw6qEpqxc3pz3Xc3IDW1Cq9phXBFZidaRITSpHoinw271txKpECwLs5UrV8bhcJzRC5uUlHRGb+1fTZs2jfvvv5/p06fTpUuXYtt6e3vj7a1VYURE5Dz4hkCzXjia9cIBcPIA7F2MsfdXXHsWE5Bzki6OjXRxbAQgNcOPNVuasmpTU6a6mrHXUYdmNULMcFurEq0jK1GjkmZNELkULL8BLDo6mjFjxhTua9asGb179z7nDWBTpkxhyJAhTJkyhT59+pz3Z+oGMBERuSguFyRuhr2L4cBvGAdWYMvLKNIk1fBjjaspq1xNWeVqxnajFqEBvlxxKtheEVmJ5jWCCfb1tOY7iJRzbjObwempucaNG0fHjh359NNP+eyzz4iLi6N27dqMGDGCw4cPM2nSJMAMsgMHDuSDDz7gtttuK3wfX19fgoODS/SZCrMiIlKqnAWQuAn2L4f9yzEOrMSWl16kSarhzzpXI9a7GrLBaMQmVz2y8aFWqB8tawTTokYwLWoE0bJGMJX8NP5WxG3CLJiLJrz11lskJCTQokUL3nvvPa65xrzTdPDgwezfv5/FixcDcN1117FkyZIz3mPQoEFMnDixRJ+nMCsiIpfUX8ItB1bCX8JtAXbiXHXY4GrIelcj1rsakUAYADVDfP8UcINpWSNYN5hJheNWYbasKcyKiEiZOh1uD66Bg6shfjWkHzmjWZItjDUFDVl/KuBuM2pTcOrWlohgH1rUCKZ5RDBNqgfStFoQNUN8Nf+tXLYUZouhMCsiIpZLPWQG29MBN2EzGM4iTfJs3my3NeC3vPrm8ARXQ07yx99bAd4eNK4WSNPqgTSpFkTT6oE0rhZEgLflExWJXDSF2WIozIqISLmTlwlHNkL8KjPgHlpjTg/2F0lekWyiMUuy6rLa2ZDdRgQGRacAqxXqVyTgNqkWRGSoHw714oobUZgthsKsiIiUey4XHN99qvf2VA9u8o4zmuV7BBLv34Kt1GNZZi2WZNTkGCFntPP2sNOgagANqwbQMDyw8LGWQq6UUwqzxVCYFRERt5R1Ag6t+yPgHl4P+VlnNMv1q0aifxO22RqwMrsWP52sztEC/7O+pZeHnfpVToXc00E3PIDaoX54aNEHsZDCbDEUZkVE5LLgLICjW+HQWnOIwuENZu+t4TqjaX5QLU4ENWWfZwM2FdRmWUZ11iV7kpN/ZlsAL4edelX8qV81gHqV/alXxZ+6lQOoV8WfIB/NjSuXnsJsMRRmRUTkspWbYS7ocDrcHtkIJ/actakRWJ2csBYk+jXid1s91uXWZM0Jf3YfyyQ733nWcwAqB3hRr3IAdQtDrj/1qgRQK9QPLw/15krpUJgthsKsiIhUKNkpkBBrzpiQsMkMu8m7gLP89e8bglEtivSQZsR7N2CbUY/YzFD2JGexLzmTpPTcc36Mw24jMsS3MNzWCfOjVpg/tUP9qBHii6eGLch5UJgthsKsiIhUeLkZ5hCF0wE3YRMc2w6ugjPbevpD1SZQtSm5oU044lmHHUSyPc2Xfcez2Jucwb5jmWTmnbs312G3EVHJh9qh/kSG+lE7zI/aoX7UCvOjdpi/phOTMyjMFkNhVkRE5CwKciFp26lweyrkHo2Dguyzt/cNharNoGpTjKpNORnQgN1GJLvTPdh7LIMDJ7KIP57FgROZ5xybe1qYv5cZbEP9qBVq9uhGhvhSI8SXakE+uhmtAlKYLYbCrIiISAk5C8wxt0nbT21x5uOJvWe90QyAwAio2tTcqjTBqNKYZJ867M/04MDxLOKPZ3LgRJb5/EQWJzLzii3BYbdRLciHmqfCbc0QP2pW8qXmqefVgn00VvcypDBbDIVZERGRi5SfDck7TwXcbX+E3dSD5z4noBpUaQSVG0OVxlC5EVRpTLpHKAdOZBP/p4AbfyKTQyezOZKSTb6z+Jhis0G1IB9qnAq4pwNvjUq+RFTyoXqwL/4axuB2FGaLoTArIiJyieSkwrEdZsA9ug2O/W6G3vSEc5/jHfynkPunx0q1cWEnKT2XwylZHDqZXbgdTsnm0MksDp/MJreg+CEMAIE+HkQE+1It2IfqwWbArR7sQ/VKf7xW4C1fFGaLoTArIiJSxnJSzRkUju0w58I9ttN8PLn/3MMV7J4QWhdC60PYqe3088AIsNsxDIPkjDwz2KacCronswtfJ6TmkJ5zlpvazuLPgTeikg/Vgv4IvOFBPlQN9CbY1xObTSumlQWF2WIozIqIiJQT+TnmmNxjO8we3NOPybvAee5pwPDwhdB6fwm5Dczn/lXMsQenZOQWkJiazZGUHBJTcziSmk1iag4JqTkkpJ5f4PXysFM10Lsw3FYN9KbqqefhQT5UDfImPNCHSn4KvRdLYbYYCrMiIiLlnMsFaYfg+B4z7B4/ve2GlANnn0LsNK9ACKkDoXXMx8KtLgRHgofXGaf8NfD+OegmpGaTlJ5LSlZ+icv3ctipEuhN1SDvouE3yIcqAd5UDvCmcqAXof5eeHs4zvOHUzEozBZDYVZERMSNOfMhJf4vQXe3+TzlIGddDOI0mx2CakJI7aJBN7SuGXZ9Q4r06v5ZTr6TY+m5JKXnkpSWQ1J6Lkf/9Hjs1OPJ8wi9AEE+HlQO9Kayvxlww/z/CLth/t5UCfSicoA3YQHe+Hs5KkyPr8JsMRRmRURELlP5OWbP7ckDcHKfOSb3z1t+VvHnewdBpdoQXBMqRZo9uacfgyMhoOo5w+5puQVOkjPyzKCblktSuvl4OvgmZ5jb8Yw8ClznF8F8PO2FwbZKgBl2wwLMHt5Qfy9C/L0I9fvjuTuHX4XZYijMioiIVECGAZnH4MRZQu7JfcXPuHCaw9sMuoVhtxYE14CgGua+oBrg5Veiclwug7ScfJIzcjmWnsfxzFyS03NJzjCfH0vPM0NvZi7J6Xlk5597hbVz8XLYCfH3JMSvaNg1Hz3NR3+vwuOh/l74eJaPYQ8Ks8VQmBUREZEz5GebPbqpB81hDKkHzWELqQch9RCkHaHYIQyn+YacCrY1zwy6wTXMmRjOMm7372TmFnA8I49jf+rZNR9zOZmVz8msPE5k5nEyM4/jmXklmrLsrOV7Ok4FXzMEB/uaj5X8PKnk50XXZuFEhpYssF+M88lrmlRNRERExNMXqjYxt7Nx5kPa4aIBNyXe3Jd62HzMy4Dsk+aWuOUcH2SDgPCzB92gmhAUYQ5ncHgWOcvf2wN/bw9qhZUsSGbnOTmRZYbbE5l5RcKuuT+/6P6sPPKdBtn5Tg6nmHP5nk2j8IAyCbPnQ2FWRERE5O84PP+4YexsDMOcT7cw3B4yH1MPndp3qnfXmQsZieZ2eP05PswG/pUhsJq5clpgNQisfurxT6/9q4Lj7FHO18tBDS9falTyLdHXMwyDjNwCM+Rm5XEi05zB4WRWPqlZeZzMyiclO7/E71eWFGZFRERELpbNBr6VzC28+dnbGAZkJv8RdNP+EnZTD5sh11Vgju/NPAacq4cXzNBb5U9hN/xPobe62QMcWN1sc47Q+0f5NgJ9PAn08Sxx7295oTArIiIiUhZsNgioYm4RV5y9jcsF2SfMG9LSE/+0nXqd8ad9hhMyk8wtcXMxn2v/I/QGhJvDGALCz/7cK+BvZ2wobxRmRURERMoLu90cYuBfGaq1PHc7lwuykosJu6dfJ5mhN+Oouf0dT78/BdyzhN6a7czayhGFWRERERF3Y7efCphVoXqrc7dzOc2hDafDbWbSqWB7lse8DHMu3tNTlp3NgG+h4Y2X4htdMIVZERERkcuV3XFqLG3437fNzTgVdv8adP/0PKjGpa/5PCnMioiIiAh4B5hbaD2rKzkvdqsLEBERERG5UAqzIiIiIuK2FGZFRERExG0pzIqIiIiI21KYFRERERG3pTArIiIiIm5LYVZERERE3JbCrIiIiIi4LYVZEREREXFbCrMiIiIi4rYUZkVERETEbXlYXUBZMwwDgLS0NIsrEREREZGzOZ3TTue24lS4MJueng5AZGSkxZWIiIiISHHS09MJDg4uto3NKEnkvYy4XC6OHDlCYGAgNputTD4zLS2NyMhIDh48SFBQUJl8ppQuXUP3puvn/nQN3Z+uofsry2toGAbp6elERERgtxc/KrbC9cza7XZq1qxpyWcHBQXpD7Cb0zV0b7p+7k/X0P3pGrq/srqGf9cje5puABMRERERt6UwKyIiIiJuS2G2DHh7e/Pyyy/j7e1tdSlygXQN3Zuun/vTNXR/uobur7xewwp3A5iIiIiIXD7UMysiIiIibkthVkRERETclsKsiIiIiLgthVkRERERcVsKs5fYmDFjqFu3Lj4+PkRHR7Ns2TKrS5JTli5dSs+ePYmIiMBmszF79uwixw3D4JVXXiEiIgJfX1+uu+464uLiirTJzc3lscceo3Llyvj7+9OrVy8OHTpUht+i4ho1ahTt2rUjMDCQqlWr0qdPH3bs2FGkja5h+TZ27FhatWpVOAF7x44d+fHHHwuP6/q5n1GjRmGz2Rg+fHjhPl3H8u2VV17BZrMV2apVq1Z43B2un8LsJTRt2jSGDx/Oiy++yMaNG7n66qvp3r078fHxVpcmQGZmJlFRUYwePfqsx9966y3effddRo8ezdq1a6lWrRo33ngj6enphW2GDx/OrFmzmDp1KsuXLycjI4NbbrkFp9NZVl+jwlqyZAmPPPIIq1atYuHChRQUFNC1a1cyMzML2+galm81a9bkzTffZN26daxbt44bbriB3r17F/5FqevnXtauXcunn35Kq1atiuzXdSz/mjdvTkJCQuG2ZcuWwmNucf0MuWTat29vDBs2rMi+Jk2aGM8//7xFFcm5AMasWbMKX7tcLqNatWrGm2++WbgvJyfHCA4ONsaNG2cYhmGkpKQYnp6extSpUwvbHD582LDb7cb8+fPLrHYxJSUlGYCxZMkSwzB0Dd1VSEiI8fnnn+v6uZn09HSjYcOGxsKFC41rr73WeOKJJwzD0J9Dd/Dyyy8bUVFRZz3mLtdPPbOXSF5eHuvXr6dr165F9nft2pUVK1ZYVJWU1L59+0hMTCxy/by9vbn22msLr9/69evJz88v0iYiIoIWLVroGlsgNTUVgNDQUEDX0N04nU6mTp1KZmYmHTt21PVzM4888gg333wzXbp0KbJf19E97Nq1i4iICOrWrctdd93F3r17Afe5fh5l8ikVUHJyMk6nk/Dw8CL7w8PDSUxMtKgqKanT1+hs1+/AgQOFbby8vAgJCTmjja5x2TIMg6eeeoqrrrqKFi1aALqG7mLLli107NiRnJwcAgICmDVrFs2aNSv8S1DXr/ybOnUqGzZsYO3atWcc05/D8q9Dhw5MmjSJRo0acfToUV5//XViYmKIi4tzm+unMHuJ2Wy2Iq8Nwzhjn5RfF3L9dI3L3qOPPsrmzZtZvnz5Gcd0Dcu3xo0bExsbS0pKCjNmzGDQoEEsWbKk8LiuX/l28OBBnnjiCRYsWICPj8852+k6ll/du3cvfN6yZUs6duxI/fr1+fLLL7nyyiuB8n/9NMzgEqlcuTIOh+OM30qSkpLO+A1Hyp/Td3IWd/2qVatGXl4eJ0+ePGcbufQee+wx5syZw6+//krNmjUL9+saugcvLy8aNGhA27ZtGTVqFFFRUXzwwQe6fm5i/fr1JCUlER0djYeHBx4eHixZsoQPP/wQDw+Pwuug6+g+/P39admyJbt27XKbP4cKs5eIl5cX0dHRLFy4sMj+hQsXEhMTY1FVUlJ169alWrVqRa5fXl4eS5YsKbx+0dHReHp6FmmTkJDA1q1bdY3LgGEYPProo8ycOZNffvmFunXrFjmua+ieDMMgNzdX189NdO7cmS1bthAbG1u4tW3blgEDBhAbG0u9evV0Hd1Mbm4u27dvp3r16u7z57BMbjOroKZOnWp4enoaX3zxhbFt2zZj+PDhhr+/v7F//36rSxPDvPt248aNxsaNGw3AePfdd42NGzcaBw4cMAzDMN58800jODjYmDlzprFlyxbj7rvvNqpXr26kpaUVvsewYcOMmjVrGosWLTI2bNhg3HDDDUZUVJRRUFBg1deqMB566CEjODjYWLx4sZGQkFC4ZWVlFbbRNSzfRowYYSxdutTYt2+fsXnzZuOFF14w7Ha7sWDBAsMwdP3c1Z9nMzAMXcfy7umnnzYWL15s7N2711i1apVxyy23GIGBgYVZxR2un8LsJfbxxx8btWvXNry8vIw2bdoUThsk1vv1118N4Ixt0KBBhmGYU5K8/PLLRrVq1Qxvb2/jmmuuMbZs2VLkPbKzs41HH33UCA0NNXx9fY1bbrnFiI+Pt+DbVDxnu3aAMWHChMI2uobl25AhQwr//1ilShWjc+fOhUHWMHT93NVfw6yuY/nWr18/o3r16oanp6cRERFh3HbbbUZcXFzhcXe4fjbDMIyy6QMWERERESldGjMrIiIiIm5LYVZERERE3JbCrIiIiIi4LYVZEREREXFbCrMiIiIi4rYUZkVERETEbSnMioiIiIjbUpgVEamgFi9ejM1mIyUlxepSREQumMKsiIiIiLgthVkRERERcVsKsyIiFjEMg7feeot69erh6+tLVFQU3377LfDHEIC5c+cSFRWFj48PHTp0YMuWLUXeY8aMGTRv3hxvb2/q1KnDO++8U+R4bm4uzz33HJGRkXh7e9OwYUO++OKLIm3Wr19P27Zt8fPzIyYmhh07dlzaLy4iUooUZkVELPKvf/2LCRMmMHbsWOLi4njyySe55557WLJkSWGbZ599lrfffpu1a9dStWpVevXqRX5+PmCG0L59+3LXXXexZcsWXnnlFf7v//6PiRMnFp4/cOBApk6dyocffsj27dsZN24cAQEBRep48cUXeeedd1i3bh0eHh4MGTKkTL6/iEhpsBmGYVhdhIhIRZOZmUnlypX55Zdf6NixY+H+oUOHkpWVxQMPPMD111/P1KlT6devHwAnTpygZs2aTJw4kb59+zJgwACOHTvGggULCs9/7rnnmDt3LnFxcezcuZPGjRuzcOFCunTpckYNixcv5vrrr2fRokV07twZgHnz5nHzzTeTnZ2Nj4/PJf4piIhcPPXMiohYYNu2beTk5HDjjTcSEBBQuE2aNIk9e/YUtvtz0A0NDaVx48Zs374dgO3bt9OpU6ci79upUyd27dqF0+kkNjYWh8PBtddeW2wtrVq1KnxevXp1AJKSki76O4qIlAUPqwsQEamIXC4XAHPnzqVGjRpFjnl7excJtH9ls9kAc8zt6een/fkf23x9fUtUi6en5xnvfbo+EZHyTj2zIiIWaNasGd7e3sTHx9OgQYMiW2RkZGG7VatWFT4/efIkO3fupEmTJoXvsXz58iLvu2LFCho1aoTD4aBly5a4XK4iY3BFRC436pkVEbFAYGAgzzzzDE8++SQul4urrrqKtLQ0VqxYQUBAALVr1wbg1VdfJSwsjPDwcF588UUqV65Mnz59AHj66adp164dr732Gv369WPlypWMHj2aMWPGAFCnTh0GDRrEkCFD+PDDD4mKiuLAgQMkJSXRt29fq766iEipUpgVEbHIa6+9RtWqVRk1ahR79+6lUqVKtGnThhdeeKHwn/nffPNNnnjiCXbt2kVUVBRz5szBy8sLgDZt2vDNN9/w0ksv8dprr1G9enVeffVVBg8eXPgZY8eO5YUXXuDhhx/m+PHj1KpVixdeeMGKrysickloNgMRkXLo9EwDJ0+epFKlSlaXIyJSbmnMrIiIiIi4LYVZEREREXFbGmYgIiIiIm5LPbMiIiIi4rYUZkVERETEbSnMioiIiIjbUpgVEREREbelMCsiIiIibkthVkRERETclsKsiIiIiLgthVkRERERcVsKsyIiIiLitv4fY5vmA6TLteUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
